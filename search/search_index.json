{
    "docs": [
        {
            "location": "/",
            "text": "UncertainData.jl\n\u00b6\n\n\n\n\nMotivation\n\u00b6\n\n\nUncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data of different types and from different sources significantly easier.\n\n\n\n\nPackage philosophy\n\u00b6\n\n\nWay too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean).\n\n\nIn this package, data values are stored as probability distributions. Individual uncertain observations may be collected in \nUncertainDatasets\n, which can be sampled according to user-provided sampling constraints. Likewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values.\n\n\n\n\nBasic workflow\n\u00b6\n\n\n\n\nDefine uncertain values\n by probability distributions.\n\n\nDefine uncertain datasets\n by gathering uncertain values.\n\n\nUse sampling constraints\n to \nconstraint the support of the distributions furnishing the uncertain values\n (i.e. apply subjective criteria to decide what is acceptable data and what is not).\n\n\nResample the the uncertain values\n or uncertain datasets.\n\n\nExtend existing algorithm\n to accept uncertain values/datasets.\n\n\nQuantify the uncertainty\n in your dataset or on whatever measure your algorithm computes.",
            "title": "UncertainData.jl"
        },
        {
            "location": "/#uncertaindatajl",
            "text": "",
            "title": "UncertainData.jl"
        },
        {
            "location": "/#motivation",
            "text": "UncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data of different types and from different sources significantly easier.",
            "title": "Motivation"
        },
        {
            "location": "/#package_philosophy",
            "text": "Way too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean).  In this package, data values are stored as probability distributions. Individual uncertain observations may be collected in  UncertainDatasets , which can be sampled according to user-provided sampling constraints. Likewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values.",
            "title": "Package philosophy"
        },
        {
            "location": "/#basic_workflow",
            "text": "Define uncertain values  by probability distributions.  Define uncertain datasets  by gathering uncertain values.  Use sampling constraints  to  constraint the support of the distributions furnishing the uncertain values  (i.e. apply subjective criteria to decide what is acceptable data and what is not).  Resample the the uncertain values  or uncertain datasets.  Extend existing algorithm  to accept uncertain values/datasets.  Quantify the uncertainty  in your dataset or on whatever measure your algorithm computes.",
            "title": "Basic workflow"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/",
            "text": "This packages facilitates working with datasets with uncertainties. The core concept of \nUncertainDatasets\n is to replace an uncertain data value with a probability distribution describing the point's uncertainty.\n\n\nThere are currently three ways of doing that: by \ntheoretical distributions\n, \ntheoretical distributions with parameters fitted to empirical data\n, or \nkernel density estimations to the distributions of empirical data\n. Check out the examples below and the documentation in the sidebar!\n\n\n\n\nUncertain values defined by theoretical distributions\n\u00b6\n\n\nFirst, load the necessary packages:\n\n\n1\nusing\n \nUncertainData\n,\n \nDistributions\n,\n \nKernelDensity\n,\n \nPlots\n\n\n\n\n\n\n\n\n\nA uniformly distributed uncertain value\n\u00b6\n\n\nNow, consider the following trivial example. We've measure a data value with a poor instrument that tells us that the value lies between \n-2\n and \n3\n. However, we but that we know nothing more about how the value is distributed on that interval. Then it may be reasonable to represent that value as a uniform distribution on \n[-2, 3]\n.\n\n\nDefine the uncertain value:\n\n\n1\n2\n3\n4\nu\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n1\n,\n \n2\n)\n\n\n\n# Plot the estimated density\n\n\nbar\n(\nu\n,\n \nlabel\n \n=\n \n\"\"\n,\n \nxlabel\n \n=\n \n\"value\"\n,\n \nylabel\n \n=\n \n\"probability density\"\n)\n\n\n\n\n\n\n\n\n\n\n\nA normally distributed uncertain value\n\u00b6\n\n\nAnother common example is to use someone else's data from a publication. Usually, these values are reported as the mean or median, with some associated uncertainty. Say we want to use an uncertain value which is normally distributed with mean \n2.1\n and standard deviation \n0.3\n.\n\n\n1\n2\n3\n4\nu\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.1\n,\n \n0.3\n)\n\n\n\n# Plot the estimated density\n\n\nbar\n(\nu\n,\n \nlabel\n \n=\n \n\"\"\n,\n \nxlabel\n \n=\n \n\"value\"\n,\n \nylabel\n \n=\n \n\"probability density\"\n)\n\n\n\n\n\n\n\n\n\n\n\nUncertain values defined by kernel density estimated distributions\n\u00b6\n\n\nOne may also be given a a distribution of numbers that's not quite normally distributed. How to represent this uncertainty? Easy: we use a kernel density estimate to the distribution.\n\n\nIn the following example, we generate some random numbers from a mixture of two normal distributions.\n\n\n1\n2\n3\n4\n5\nM\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n5\n,\n \n0.5\n),\n \nNormal\n(\n0.2\n)])\n\n\nu\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\nM\n,\n \n250\n))\n\n\n\n# Plot the estimated distribution.\n\n\nplot\n(\nu\n,\n \nxlabel\n \n=\n \n\"Value\"\n,\n \nylabel\n \n=\n \n\"Probability density\"\n)\n\n\n\n\n\n\n\n\n\n\n\nUncertain values defined by theoretical distributions fitted to empirical data\n\u00b6\n\n\nOne may also be given a dataset whose histogram looks a lot like a theoretical distribution. We may then select a theoretical distribution and fit its parameters to the empirical data.\n\n\nIn the example below, we \nresample\n the estimated distribution to obtain a histogram we can compare to the original data.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n# Take a sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n1.7\n,\n \n5.5\n),\n \n2000\n)\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\np1\n \n=\n \nhistogram\n(\nsome_sample\n,\n \nnormalize\n \n=\n \ntrue\n,\n\n    \nfc\n \n=\n \n:\nblack\n,\n \nlc\n \n=\n \n:\nblack\n,\n\n    \nlabel\n \n=\n \n\"\"\n,\n \nxlabel\n \n=\n \n\"value\"\n,\n \nylabel\n \n=\n \n\"density\"\n)\n\n\n\n# Resample the fitted theoretical distribution\n\n\np2\n \n=\n \nhistogram\n(\nresample\n(\nuv\n,\n \n10000\n),\n \nnormalize\n \n=\n \ntrue\n,\n\n    \nfc\n \n=\n \n:\nblue\n,\n \nlc\n \n=\n \n:\nblue\n,\n\n    \nlabel\n \n=\n \n\"\"\n,\n \nxlabel\n \n=\n \n\"value\"\n,\n \nylabel\n \n=\n \n\"density\"\n)\n\n\n\nplot\n(\np1\n,\n \np2\n,\n \nlayout\n \n=\n \n(\n2\n,\n \n1\n),\n \nlink\n \n=\n \n:\nx\n)\n\n\n\n\n\n\n\nAs expected, the histograms closely match (but are not exact because we estimated the distribution using a limited sample).",
            "title": "Examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/#uncertain_values_defined_by_theoretical_distributions",
            "text": "First, load the necessary packages:  1 using   UncertainData ,   Distributions ,   KernelDensity ,   Plots",
            "title": "Uncertain values defined by theoretical distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/#a_uniformly_distributed_uncertain_value",
            "text": "Now, consider the following trivial example. We've measure a data value with a poor instrument that tells us that the value lies between  -2  and  3 . However, we but that we know nothing more about how the value is distributed on that interval. Then it may be reasonable to represent that value as a uniform distribution on  [-2, 3] .  Define the uncertain value:  1\n2\n3\n4 u   =   UncertainValue ( Uniform ,   1 ,   2 )  # Plot the estimated density  bar ( u ,   label   =   \"\" ,   xlabel   =   \"value\" ,   ylabel   =   \"probability density\" )",
            "title": "A uniformly distributed uncertain value"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/#a_normally_distributed_uncertain_value",
            "text": "Another common example is to use someone else's data from a publication. Usually, these values are reported as the mean or median, with some associated uncertainty. Say we want to use an uncertain value which is normally distributed with mean  2.1  and standard deviation  0.3 .  1\n2\n3\n4 u   =   UncertainValue ( Normal ,   2.1 ,   0.3 )  # Plot the estimated density  bar ( u ,   label   =   \"\" ,   xlabel   =   \"value\" ,   ylabel   =   \"probability density\" )",
            "title": "A normally distributed uncertain value"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/#uncertain_values_defined_by_kernel_density_estimated_distributions",
            "text": "One may also be given a a distribution of numbers that's not quite normally distributed. How to represent this uncertainty? Easy: we use a kernel density estimate to the distribution.  In the following example, we generate some random numbers from a mixture of two normal distributions.  1\n2\n3\n4\n5 M   =   MixtureModel ([ Normal ( - 5 ,   0.5 ),   Normal ( 0.2 )])  u   =   UncertainValue ( UnivariateKDE ,   rand ( M ,   250 ))  # Plot the estimated distribution.  plot ( u ,   xlabel   =   \"Value\" ,   ylabel   =   \"Probability density\" )",
            "title": "Uncertain values defined by kernel density estimated distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_examples/#uncertain_values_defined_by_theoretical_distributions_fitted_to_empirical_data",
            "text": "One may also be given a dataset whose histogram looks a lot like a theoretical distribution. We may then select a theoretical distribution and fit its parameters to the empirical data.  In the example below, we  resample  the estimated distribution to obtain a histogram we can compare to the original data.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 # Take a sample from a Gamma distribution with parameters \u03b1 = 1.7 and \u03b8 = 5.5  some_sample   =   rand ( Gamma ( 1.7 ,   5.5 ),   2000 )  uv   =   UncertainValue ( Gamma ,   some_sample )  p1   =   histogram ( some_sample ,   normalize   =   true , \n     fc   =   : black ,   lc   =   : black , \n     label   =   \"\" ,   xlabel   =   \"value\" ,   ylabel   =   \"density\" )  # Resample the fitted theoretical distribution  p2   =   histogram ( resample ( uv ,   10000 ),   normalize   =   true , \n     fc   =   : blue ,   lc   =   : blue , \n     label   =   \"\" ,   xlabel   =   \"value\" ,   ylabel   =   \"density\" )  plot ( p1 ,   p2 ,   layout   =   ( 2 ,   1 ),   link   =   : x )    As expected, the histograms closely match (but are not exact because we estimated the distribution using a limited sample).",
            "title": "Uncertain values defined by theoretical distributions fitted to empirical data"
        },
        {
            "location": "/uncertain_values/uncertainvalues_overview/",
            "text": "Uncertain values may be constructed in three different ways, depending on what information you have available. You may represent an uncertain value by\n\n\n\n\ntheoretical distributions with known parameters\n\n\ntheoretical distributions with parameters fitted to empirical data\n\n\nkernel density estimates to empirical data\n\n\n\n\n\n\nExamples\n\u00b6\n\n\nIf the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.\n\n\n\n\n\n\nImplicit KDE estimate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a kernel density estimate (it is inferred\n\n\n# that KDE is wanted when no distribution is provided to the constructor).\n\n\nuv\n \n=\n \nUncertainValue\n(\nsome_sample\n)\n\n\n\n\n\n\n\n\nExplicit KDE estimate\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n\n\n# Specify that we want a kernel density estimate representation\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nIf your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.\n\n\n\n\n\n\nExample 1: fitting a normal distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nExample 2: fitting a gamma distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a gamma distribution, so that we get a\n\n\n# histogram resembling a gamma distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nIt is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean \n\u03bc = 2.2\n and standard deviation \n\u03c3 = 0.3\n.\n\n\n\n\n\n\nExample 1: theoretical normal distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# known parameters \u03bc = 2.2 and \u03c3 = 0.3\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.2\n,\n \n0.3\n)\n\n\n\n\n\n\n\n\nExample 2: theoretical gamma distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# known parameters \u03b1 = 2.1 and \u03b8 = 3.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.1\n,\n \n3.1\n)\n\n\n\n\n\n\n\n\nExample 3: theoretical binomial distribution\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical binomial distribution with\n\n\n# known parameters p = 32 and p = 0.13\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n32\n,\n \n0.13\n)",
            "title": "Quickstart"
        },
        {
            "location": "/uncertain_values/uncertainvalues_overview/#examples",
            "text": "If the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.    Implicit KDE estimate  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData ,   KernelDensity  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a kernel density estimate (it is inferred  # that KDE is wanted when no distribution is provided to the constructor).  uv   =   UncertainValue ( some_sample )     Explicit KDE estimate   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Specify that we want a kernel density estimate representation  uv   =   UncertainValue ( UnivariateKDE ,   some_sample )     If your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.    Example 1: fitting a normal distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a theoretical normal distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Normal ,   some_sample )     Example 2: fitting a gamma distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a gamma distribution, so that we get a  # histogram resembling a gamma distribution.  some_sample   =   rand ( Gamma (),   1000 )  # Uncertain value represented by a theoretical gamma distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Gamma ,   some_sample )     It is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean  \u03bc = 2.2  and standard deviation  \u03c3 = 0.3 .    Example 1: theoretical normal distribution  1\n2\n3 # Uncertain value represented by a theoretical normal distribution with  # known parameters \u03bc = 2.2 and \u03c3 = 0.3  uv   =   UncertainValue ( Normal ,   2.2 ,   0.3 )     Example 2: theoretical gamma distribution  1\n2\n3 # Uncertain value represented by a theoretical gamma distribution with  # known parameters \u03b1 = 2.1 and \u03b8 = 3.1  uv   =   UncertainValue ( Gamma ,   2.1 ,   3.1 )     Example 3: theoretical binomial distribution  1\n2\n3 # Uncertain value represented by a theoretical binomial distribution with  # known parameters p = 32 and p = 0.13  uv   =   UncertainValue ( Binomial ,   32 ,   0.13 )",
            "title": "Examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_kde/",
            "text": "When your data have an empirical distribution that doesn't follow any obvious theoretical distribution, the data may be represented by a kernel density estimate.\n\n\n\n\nExamples\n\u00b6\n\n\n\n\n\n\nImplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the implicit KDE constructor to create the uncertain value\n\n\nuv\n \n=\n \nUncertainValue\n(\nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nExplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value.\n\n\n# This constructor follows the same convention as when fitting distributions\n\n\n# to empirical data, so this is the recommended way to construct KDE estimates.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nChanging the kernel\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# that we want to use normal distributions as the kernel. The kernel can be\n\n\n# any valid kernel from Distributions.jl, and the default is to use normal\n\n\n# distributions.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nkernel\n \n=\n \nNormal\n)\n\n\n\n\n\n\n\n\nAdjusting number of points\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# the number of points we want to use for the kernel density estimate. Fast\n\n\n# Fourier transforms are used behind the scenes, so the number of points\n\n\n# should be a power of 2 (the default is 2048 points).\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nnpoints\n \n=\n \n1024\n)\n\n\n\n\n\n\n\n\n\n\nExtended example\n\u00b6\n\n\nLet's create a bimodal distribution, then sample 10000 values from it.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nDistributions\n\n\n\nn1\n \n=\n \nNormal\n(\n-\n3.0\n,\n \n1.2\n)\n\n\nn2\n \n=\n \nNormal\n(\n8.0\n,\n \n1.2\n)\n\n\nn3\n \n=\n \nNormal\n(\n0.0\n,\n \n2.5\n)\n\n\n\n# Use a mixture model to create a bimodal distribution\n\n\nM\n \n=\n \nMixtureModel\n([\nn1\n,\n \nn2\n,\n \nn3\n])\n\n\n\n# Sample the mixture model.\n\n\nsamples_empirical\n \n=\n \nrand\n(\nM\n,\n \nInt\n(\n1e4\n));\n\n\n\n\n\n\n\n\n\nIt is not obvious which distribution to fit to such data.\n\n\nA kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.\n\n\nTo create a kernel density estimate, simply call the \nUncertainValue(v::Vector{Number})\n constructor with a vector containing the sample:\n\n\n1\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\n\n\n\n\n\nThe plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.\n\n\n1\n2\n3\n4\n5\n6\n7\nusing\n \nPlots\n,\n \nStatPlots\n,\n \nUncertainData\n\n\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\ndensity\n(\nmvals\n,\n \nlabel\n \n=\n \n\"10000 mixture model (M) samples\"\n)\n\n\ndensity!\n(\nrand\n(\nuv\n,\n \nInt\n(\n1e4\n)),\n\n    \nlabel\n \n=\n \n\"10000 samples from KDE estimate to M\"\n)\n\n\nxlabel!\n(\n\"data value\"\n)\n\n\nylabel!\n(\n\"probability density\"\n)\n\n\n\n\n\n\n\n\n\n\n\nConstructor\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainValues.UncertainValue\n \u2014 \nMethod\n.\n\n\n1\n2\n3\nUncertainValue\n(\ndata\n::\nVector\n{\nT\n}\n;\n\n    \nkernel\n::\nType\n{\nD\n}\n \n=\n \nNormal\n,\n\n    \nnpoints\n::\nInt\n=\n2048\n)\n \nwhere\n \n{\nD\n \n<:\n \nDistributions.Distribution,\n \nT\n}\n\n\n\n\n\n\n\nConstruct an uncertain value by a kernel density estimate to \ndata\n.\n\n\nFast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).\n\n\nsource\n\n\n\n\nAdditional keyword arguments and examples\n\u00b6\n\n\nIf the only argument to the \nUncertainValue\n constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e. \nUncertainValue(data)\n. Gaussian kernels are used by default. The syntax \nUncertainValue(UnivariateKDE, data)\n will also work if \nKernelDensity.jl\n is loaded.",
            "title": "Kernel density estimates (KDE)"
        },
        {
            "location": "/uncertain_values/uncertainvalues_kde/#examples",
            "text": "Implicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the implicit KDE constructor to create the uncertain value  uv   =   UncertainValue ( v :: Vector )     Explicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value.  # This constructor follows the same convention as when fitting distributions  # to empirical data, so this is the recommended way to construct KDE estimates.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector )     Changing the kernel   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # that we want to use normal distributions as the kernel. The kernel can be  # any valid kernel from Distributions.jl, and the default is to use normal  # distributions.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   kernel   =   Normal )     Adjusting number of points   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # the number of points we want to use for the kernel density estimate. Fast  # Fourier transforms are used behind the scenes, so the number of points  # should be a power of 2 (the default is 2048 points).  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   npoints   =   1024 )",
            "title": "Examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_kde/#extended_example",
            "text": "Let's create a bimodal distribution, then sample 10000 values from it.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Distributions  n1   =   Normal ( - 3.0 ,   1.2 )  n2   =   Normal ( 8.0 ,   1.2 )  n3   =   Normal ( 0.0 ,   2.5 )  # Use a mixture model to create a bimodal distribution  M   =   MixtureModel ([ n1 ,   n2 ,   n3 ])  # Sample the mixture model.  samples_empirical   =   rand ( M ,   Int ( 1e4 ));     It is not obvious which distribution to fit to such data.  A kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.  To create a kernel density estimate, simply call the  UncertainValue(v::Vector{Number})  constructor with a vector containing the sample:  1 uv   =   UncertainValue ( samples_empirical )    The plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.  1\n2\n3\n4\n5\n6\n7 using   Plots ,   StatPlots ,   UncertainData  uv   =   UncertainValue ( samples_empirical )  density ( mvals ,   label   =   \"10000 mixture model (M) samples\" )  density! ( rand ( uv ,   Int ( 1e4 )), \n     label   =   \"10000 samples from KDE estimate to M\" )  xlabel! ( \"data value\" )  ylabel! ( \"probability density\" )",
            "title": "Extended example"
        },
        {
            "location": "/uncertain_values/uncertainvalues_kde/#constructor",
            "text": "#  UncertainData.UncertainValues.UncertainValue  \u2014  Method .  1\n2\n3 UncertainValue ( data :: Vector { T } ; \n     kernel :: Type { D }   =   Normal , \n     npoints :: Int = 2048 )   where   { D   <:   Distributions.Distribution,   T }    Construct an uncertain value by a kernel density estimate to  data .  Fast Fourier transforms are used in the kernel density estimation, so the number of points should be a power of 2 (default = 2048).  source",
            "title": "Constructor"
        },
        {
            "location": "/uncertain_values/uncertainvalues_kde/#additional_keyword_arguments_and_examples",
            "text": "If the only argument to the  UncertainValue  constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e.  UncertainValue(data) . Gaussian kernels are used by default. The syntax  UncertainValue(UnivariateKDE, data)  will also work if  KernelDensity.jl  is loaded.",
            "title": "Additional keyword arguments and examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/",
            "text": "It is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. For example, an author report the mean and standard deviation of a value stated to follow a normal distribution. \nUncertainData\n makes it easy to represent such values!\n\n\n\n\nSupported distributions\n\u00b6\n\n\nSupported distributions are \nUniform\n, \nNormal\n, \nGamma\n, \nBeta\n, \nBetaPrime\n, \nFrechet\n, \nBinomial\n, \nBetaBinomial\n (more distributions will be added in the future!).\n\n\n\n\nExamples\n\u00b6\n\n\n\n\n\n\nUniform\n\n\n1\n2\n# Uncertain value generated by a uniform distribution on [-5.0, 5.1].\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n-\n5.0\n,\n \n5.1\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n1\n2\n3\n# Uncertain value generated by a normal distribution with parameters \u03bc = -2 and\n\n\n# \u03c3 = 0.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n2\n,\n \n0.5\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n# Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2\n\n\n# and \u03b8 = 3.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.2\n,\n \n3\n)\n\n\n\n\n\n\n\n\nBeta\n\n\n1\n2\n3\n# Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5\n\n\n# and \u03b2 = 3.5\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.5\n,\n \n3.5\n)\n\n\n\n\n\n\n\n\nBetaPrime\n\n\n1\n2\n3\n# Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7\n\n\n# and \u03b2 = 3.2\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.7\n,\n \n3.2\n)\n\n\n\n\n\n\n\n\nFr\u00e9chet\n\n\n1\n2\n3\n# Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1\n\n\n# and \u03b8 = 4\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n2.1\n,\n \n4\n)\n\n\n\n\n\n\n\n\nBinomial\n\n\n1\n2\n3\n# Uncertain value generated by binomial distribution with n = 28 trials and\n\n\n# probability p = 0.2 of success in individual trials.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n28\n,\n \n0.2\n)\n\n\n\n\n\n\n\n\nBetaBinomial\n\n\n1\n2\n3\n# Creates an uncertain value generated by a beta-binomial distribution with\n\n\n# n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBetaBinomial\n,\n \n28\n,\n \n3.3\n,\n \n4.4\n)\n\n\n\n\n\n\n\n\n\n\nConstructors\n\u00b6\n\n\nThere are two constructors that creates uncertain values represented by theoretical distributions. Parameters are provided to the constructor in the same order as for constructing the equivalent distributions in \nDistributions.jl\n.\n\n\nUncertain values represented by theoretical distributions may be constructed using the two-parameter or three-parameter constructors \nUncertainValue(d::Type{D}, a<:Number, b<:Number)\n or \nUncertainValue(d::Type{D}, a<:Number, b<:Number, c<:Number)\n (see below).\n\n\n\n\nTwo-parameter distributions\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainValues.UncertainValue\n \u2014 \nMethod\n.\n\n\n1\n2\nUncertainValue\n(\ndistribution\n::\nType\n{\nD\n}\n,\n \na\n::\nT1\n,\n \nb\n::\nT2\n;\n\n    \nkwargs\n...)\n \nwhere\n \n{\nT1<:Number,\n \nT2\n \n<:\n \nNumber,\n \nD<:Distribution\n}\n\n\n\n\n\n\n\nConstructor for two-parameter distributions\n\n\nUncertainValue\ns are currently implemented for the following two-parameter distributions: \nUniform\n, \nNormal\n, \nBinomial\n, \nBeta\n, \nBetaPrime\n, \nGamma\n, and \nFrechet\n.\n\n\nArguments\n\n\n\n\na\n, \nb\n: Generic parameters whose meaning varies depending   on what \ndistribution\n is provided. See the list below.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions.jl\n.\n\n\n\n\nPrecisely what  \na\n and \nb\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue(Normal, \u03bc, \u03c3)\n returns an \nUncertainScalarNormallyDistributed\n instance.\n\n\nUncertainValue(Uniform, lower, upper)\n returns an \nUncertainScalarUniformlyDistributed\n instance.\n\n\nUncertainValue(Beta, \u03b1, \u03b2)\n returns an \nUncertainScalarBetaDistributed\n instance.\n\n\nUncertainValue(BetaPrime, \u03b1, \u03b2)\n returns an \nUncertainScalarBetaPrimeDistributed\n instance.\n\n\nUncertainValue(Gamma, \u03b1, \u03b8)\n returns an \nUncertainScalarGammaDistributed\n instance.\n\n\nUncertainValue(Frechet, \u03b1, \u03b8)\n returns an \nUncertainScalarFrechetDistributed\n instance.\n\n\nUncertainValue(Binomial, n, p)\n returns an \nUncertainScalarBinomialDistributed\n instance.\n\n\n\n\nKeyword arguments\n\n\n\n\nn\u03c3\n: If \ndistribution <: Distributions.Normal\n, then how many standard   deviations away from \n\u03bc\n does \nlower\n and \nupper\n (i.e. both, because   they are the same distance away from \n\u03bc\n) represent?\n\n\ntolerance\n: A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   (\nupper - lower > threshold\n is required).\n\n\ntrunc_lower\n: Lower truncation bound for distributions with infinite   support. Defaults to \n-Inf\n.\n\n\ntrunc_upper\n: Upper truncation bound for distributions with infinite   support. Defaults to \nInf\n.\n\n\n\n\nExamples\n\n\nNormal distribution\n\n\nNormal distributions are formed by using the constructor \nUncertainValue(\u03bc, \u03c3, Normal; kwargs...)\n. This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n# A normal distribution with mean = 2.3 and standard deviation 0.3.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n)\n\n\n\n# A normal distribution with mean 2.3 and standard deviation 0.3/2.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n,\n \nn\u03c3\n \n=\n \n2\n)\n\n\n\n# A normal distribution with mean 2.3 and standard deviation = 0.3,\n\n\ntruncated\n \nto\n \nthe\n \ninterval\n \n`[1, 3]`\n.\n\n\nUncertainValue\n(\n2.3\n,\n \n0.3\n,\n \nNormal\n,\n \ntrunc_lower\n \n=\n \n1.0\n,\n \ntrunc_upper\n \n=\n \n3.0\n)\n\n\n\n\n\n\n\nUniform distribution\n\n\nUniform distributions are formed using the \nUncertainValue(lower, upper, Uniform)\n constructor.\n\n\n1\n2\n#  A uniform distribution on `[2, 3]`\n\n\nUncertainValue\n(\n-\n2\n,\n \n3\n,\n \nUniform\n)\n\n\n\n\n\n\n\nsource\n\n\n\n\nThree-parameter distributions\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainValues.UncertainValue\n \u2014 \nMethod\n.\n\n\n1\n2\nUncertainValue\n(\ndistribution\n::\nType\n{\nD\n}\n,\n \na\n::\nT1\n,\n \nb\n::\nT2\n,\n \nc\n::\nT3\n;\n\n    \nkwargs\n...)\n \nwhere\n \n{\nT1<:Number,\n \nT2<:Number,\n \nT3<:Number,\n \nD<:Distribution\n}\n\n\n\n\n\n\n\nConstructor for three-parameter distributions\n\n\nCurrently implemented distributions are \nBetaBinomial\n.\n\n\nArguments\n\n\n\n\na\n, \nb\n, \nc\n: Generic parameters whose meaning varies depending   on what \ndistribution\n is provided. See the list below.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions.jl\n.\n\n\n\n\nPrecisely what \na\n, \nb\n and \nc\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue(BetaBinomial, n, \u03b1, \u03b2)\n returns an \nUncertainScalarBetaBinomialDistributed\n instance.\n\n\n\n\nKeyword arguments\n\n\n\n\nn\u03c3\n: If \ndistribution <: Distributions.Normal\n, then how many standard   deviations away from \n\u03bc\n does \nlower\n and \nupper\n (i.e. both, because   they are the same distance away from \n\u03bc\n) represent?\n\n\ntolerance\n: A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   (\nupper - lower > threshold\n is required).\n\n\ntrunc_lower\n: Lower truncation bound for distributions with infinite   support. Defaults to \n-Inf\n.\n\n\ntrunc_upper\n: Upper truncation bound for distributions with infinite   support. Defaults to \nInf\n.\n\n\n\n\nExamples\n\n\nBetaBinomial distribution\n\n\nNormal distributions are formed by using the constructor \nUncertainValue(\u03bc, \u03c3, Normal; kwargs...)\n. This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).\n\n\n1\n2\n3\n# A beta binomial distribution with n = 100 trials and parameters \u03b1 = 2.3 and\n\n\n# \u03b2 = 5\n\n\nUncertainValue\n(\n100\n,\n \n2.3\n,\n \n5\n,\n \nBetaBinomial\n)\n\n\n\n\n\n\n\nsource",
            "title": "Theoretical distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#supported_distributions",
            "text": "Supported distributions are  Uniform ,  Normal ,  Gamma ,  Beta ,  BetaPrime ,  Frechet ,  Binomial ,  BetaBinomial  (more distributions will be added in the future!).",
            "title": "Supported distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#examples",
            "text": "Uniform  1\n2 # Uncertain value generated by a uniform distribution on [-5.0, 5.1].  uv   =   UncertainValue ( Uniform ,   - 5.0 ,   5.1 )     Normal  1\n2\n3 # Uncertain value generated by a normal distribution with parameters \u03bc = -2 and  # \u03c3 = 0.5.  uv   =   UncertainValue ( Normal ,   - 2 ,   0.5 )     Gamma  1\n2\n3 # Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2  # and \u03b8 = 3.  uv   =   UncertainValue ( Gamma ,   2.2 ,   3 )     Beta  1\n2\n3 # Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5  # and \u03b2 = 3.5  uv   =   UncertainValue ( Beta ,   1.5 ,   3.5 )     BetaPrime  1\n2\n3 # Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7  # and \u03b2 = 3.2  uv   =   UncertainValue ( Beta ,   1.7 ,   3.2 )     Fr\u00e9chet  1\n2\n3 # Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1  # and \u03b8 = 4  uv   =   UncertainValue ( Beta ,   2.1 ,   4 )     Binomial  1\n2\n3 # Uncertain value generated by binomial distribution with n = 28 trials and  # probability p = 0.2 of success in individual trials.  uv   =   UncertainValue ( Binomial ,   28 ,   0.2 )     BetaBinomial  1\n2\n3 # Creates an uncertain value generated by a beta-binomial distribution with  # n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.  uv   =   UncertainValue ( BetaBinomial ,   28 ,   3.3 ,   4.4 )",
            "title": "Examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#constructors",
            "text": "There are two constructors that creates uncertain values represented by theoretical distributions. Parameters are provided to the constructor in the same order as for constructing the equivalent distributions in  Distributions.jl .  Uncertain values represented by theoretical distributions may be constructed using the two-parameter or three-parameter constructors  UncertainValue(d::Type{D}, a<:Number, b<:Number)  or  UncertainValue(d::Type{D}, a<:Number, b<:Number, c<:Number)  (see below).",
            "title": "Constructors"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#two-parameter_distributions",
            "text": "#  UncertainData.UncertainValues.UncertainValue  \u2014  Method .  1\n2 UncertainValue ( distribution :: Type { D } ,   a :: T1 ,   b :: T2 ; \n     kwargs ...)   where   { T1<:Number,   T2   <:   Number,   D<:Distribution }    Constructor for two-parameter distributions  UncertainValue s are currently implemented for the following two-parameter distributions:  Uniform ,  Normal ,  Binomial ,  Beta ,  BetaPrime ,  Gamma , and  Frechet .  Arguments   a ,  b : Generic parameters whose meaning varies depending   on what  distribution  is provided. See the list below.  distribution : A valid univariate distribution from  Distributions.jl .   Precisely what   a  and  b  are depends on which distribution is provided.   UncertainValue(Normal, \u03bc, \u03c3)  returns an  UncertainScalarNormallyDistributed  instance.  UncertainValue(Uniform, lower, upper)  returns an  UncertainScalarUniformlyDistributed  instance.  UncertainValue(Beta, \u03b1, \u03b2)  returns an  UncertainScalarBetaDistributed  instance.  UncertainValue(BetaPrime, \u03b1, \u03b2)  returns an  UncertainScalarBetaPrimeDistributed  instance.  UncertainValue(Gamma, \u03b1, \u03b8)  returns an  UncertainScalarGammaDistributed  instance.  UncertainValue(Frechet, \u03b1, \u03b8)  returns an  UncertainScalarFrechetDistributed  instance.  UncertainValue(Binomial, n, p)  returns an  UncertainScalarBinomialDistributed  instance.   Keyword arguments   n\u03c3 : If  distribution <: Distributions.Normal , then how many standard   deviations away from  \u03bc  does  lower  and  upper  (i.e. both, because   they are the same distance away from  \u03bc ) represent?  tolerance : A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   ( upper - lower > threshold  is required).  trunc_lower : Lower truncation bound for distributions with infinite   support. Defaults to  -Inf .  trunc_upper : Upper truncation bound for distributions with infinite   support. Defaults to  Inf .   Examples  Normal distribution  Normal distributions are formed by using the constructor  UncertainValue(\u03bc, \u03c3, Normal; kwargs...) . This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).  1\n2\n3\n4\n5\n6\n7\n8\n9 # A normal distribution with mean = 2.3 and standard deviation 0.3.  UncertainValue ( 2.3 ,   0.3 ,   Normal )  # A normal distribution with mean 2.3 and standard deviation 0.3/2.  UncertainValue ( 2.3 ,   0.3 ,   Normal ,   n\u03c3   =   2 )  # A normal distribution with mean 2.3 and standard deviation = 0.3,  truncated   to   the   interval   `[1, 3]` .  UncertainValue ( 2.3 ,   0.3 ,   Normal ,   trunc_lower   =   1.0 ,   trunc_upper   =   3.0 )    Uniform distribution  Uniform distributions are formed using the  UncertainValue(lower, upper, Uniform)  constructor.  1\n2 #  A uniform distribution on `[2, 3]`  UncertainValue ( - 2 ,   3 ,   Uniform )    source",
            "title": "Two-parameter distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_theoreticaldistributions/#three-parameter_distributions",
            "text": "#  UncertainData.UncertainValues.UncertainValue  \u2014  Method .  1\n2 UncertainValue ( distribution :: Type { D } ,   a :: T1 ,   b :: T2 ,   c :: T3 ; \n     kwargs ...)   where   { T1<:Number,   T2<:Number,   T3<:Number,   D<:Distribution }    Constructor for three-parameter distributions  Currently implemented distributions are  BetaBinomial .  Arguments   a ,  b ,  c : Generic parameters whose meaning varies depending   on what  distribution  is provided. See the list below.  distribution : A valid univariate distribution from  Distributions.jl .   Precisely what  a ,  b  and  c  are depends on which distribution is provided.   UncertainValue(BetaBinomial, n, \u03b1, \u03b2)  returns an  UncertainScalarBetaBinomialDistributed  instance.   Keyword arguments   n\u03c3 : If  distribution <: Distributions.Normal , then how many standard   deviations away from  \u03bc  does  lower  and  upper  (i.e. both, because   they are the same distance away from  \u03bc ) represent?  tolerance : A threshold determining how symmetric the uncertainties   must be in order to allow the construction of  Normal distribution   ( upper - lower > threshold  is required).  trunc_lower : Lower truncation bound for distributions with infinite   support. Defaults to  -Inf .  trunc_upper : Upper truncation bound for distributions with infinite   support. Defaults to  Inf .   Examples  BetaBinomial distribution  Normal distributions are formed by using the constructor  UncertainValue(\u03bc, \u03c3, Normal; kwargs...) . This gives a normal distribution with mean \u03bc and standard deviation \u03c3/n\u03c3 (n\u03c3 must be given as a keyword argument).  1\n2\n3 # A beta binomial distribution with n = 100 trials and parameters \u03b1 = 2.3 and  # \u03b2 = 5  UncertainValue ( 100 ,   2.3 ,   5 ,   BetaBinomial )    source",
            "title": "Three-parameter distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_fitted/",
            "text": "For data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution.\n\n\n\n\nExamples\n\u00b6\n\n\n\n\n\n\nUniform\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nUniform\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Define an uncertain value by fitting a uniform distribution to the sample.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted normal distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted gamma distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nIn these examples we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. In real applications, make sure to always visually investigate the histogram of your data!\n\n\n\n\nBeware: fitting distributions may lead to nonsensical results!\n\u00b6\n\n\nIn a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted beta distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\nThis is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.\n\n\nIf the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.\n\n\n\n\nConstructor\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainValues.UncertainValue\n \u2014 \nMethod\n.\n\n\n1\n2\nUncertainValue(empiricaldata::AbstractVector{T},\n    d::Type{D}) where {D <: Distribution}\n\n\n\n\n\n\nConstructor for empirical distributions.\n\n\nFit a distribution of type \nd\n to the data and use that as the representation of the empirical distribution. Calls \nDistributions.fit\n behind the scenes.\n\n\nArguments\n\n\n\n\nempiricaldata\n: The data for which to fit the \ndistribution\n.\n\n\ndistribution\n: A valid univariate distribution from \nDistributions.jl\n.\n\n\n\n\nsource",
            "title": "Fit theoretical distributions"
        },
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#examples",
            "text": "Uniform   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Uniform ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Define an uncertain value by fitting a uniform distribution to the sample.  uv   =   UncertainValue ( Uniform ,   some_sample )     Normal   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Represent the uncertain value by a fitted normal distribution.  uv   =   UncertainValue ( Normal ,   some_sample )     Gamma  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted gamma distribution.  uv   =   UncertainValue ( Gamma ,   some_sample )     In these examples we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. In real applications, make sure to always visually investigate the histogram of your data!",
            "title": "Examples"
        },
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#beware_fitting_distributions_may_lead_to_nonsensical_results",
            "text": "In a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted beta distribution.  uv   =   UncertainValue ( Beta ,   some_sample )    This is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.  If the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.",
            "title": "Beware: fitting distributions may lead to nonsensical results!"
        },
        {
            "location": "/uncertain_values/uncertainvalues_fitted/#constructor",
            "text": "#  UncertainData.UncertainValues.UncertainValue  \u2014  Method .  1\n2 UncertainValue(empiricaldata::AbstractVector{T},\n    d::Type{D}) where {D <: Distribution}   Constructor for empirical distributions.  Fit a distribution of type  d  to the data and use that as the representation of the empirical distribution. Calls  Distributions.fit  behind the scenes.  Arguments   empiricaldata : The data for which to fit the  distribution .  distribution : A valid univariate distribution from  Distributions.jl .   source",
            "title": "Constructor"
        },
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/",
            "text": "If dealing with several uncertain values, it may be useful to represent them as an \nUncertainDataset\n. This way, one may trivially, for example, compute statistics for a dataset consisting of samples with different types of uncertainties.\n\n\n\n\nExample\n\u00b6\n\n\nLet's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the \ni\ni\n-th observation has standard deviation \n\\sigma_i \\in [0.3, 0.5]\n\\sigma_i \\in [0.3, 0.5]\n.\n\n\nRepresenting these data as an \nUncertainDataset\n is done as follows:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nUncertainData\n,\n \nDistributions\n,\n \nPlots\n\n\n\n# Create a random walk of 55 steps\n\n\nn\n \n=\n \n55\n\n\nrw\n \n=\n \ncumsum\n(\nrand\n(\nNormal\n(),\n \nn\n))\n\n\n\n# Represent each value of the random walk as an uncertain value and\n\n\n# collect them in an UncertainDataset\n\n\ndist\n \n=\n \nUniform\n(\n0.3\n,\n \n0.5\n)\n\n\nuncertainvals\n \n=\n \n[\nUncertainValue\n(\nNormal\n,\n \nrw\n[\ni\n],\n \nrand\n(\ndist\n))\n \nfor\n \ni\n \n=\n \n1\n:\nn\n]\n\n\nD\n \n=\n \nUncertainDataset\n(\nuncertainvals\n)\n\n\n\n\n\n\n\nWe may then resample the dataset by calling \nresample(D)\n. This will \nresample each uncertain value\n in the dataset. Alternatively, \nresample(D, n)\n resamples \nn\n times and returns a \nn\n-element vector of resampled realizations.\n\n\nLet's resample the uncertain dataset 100 times and plot the realisations.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nPlots\n\n\n\n# Initialise plot\n\n\np\n \n=\n \nplot\n(\nlegend\n \n=\n \nfalse\n,\n \nxlabel\n \n=\n \n\"time step\"\n,\n \nylabel\n \n=\n \n\"value\"\n)\n\n\n\n# Plot the mean of the dataset\n\n\nplot!\n(\nmean\n.\n(\nD\n),\n \nlabel\n \n=\n \n\"mean\"\n,\n \nlc\n \n=\n \n:\nblue\n,\n \nlw\n \n=\n \n3\n)\n\n\n\n# Resample the dataset 100 times, add a line to the plot at each iteration\n\n\nfor\n \ni\n \n=\n \n1\n:\n100\n\n    \nplot!\n(\np\n,\n \nresample\n(\nD\n),\n \nlw\n \n=\n \n0.4\n,\n \nl\u03b1\n \n=\n \n0.2\n,\n \nlc\n \n=\n \n:\nblack\n)\n\n\nend\n\n\np\n\n\n\n\n\n\n\n\n\n\n\nExample 2: mixing different types of uncertain values\n\u00b6\n\n\nMixing different types of uncertain values also works. Let's create a dataset of uncertain values constructed in different ways.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nUncertainData\n,\n \nDistributions\n,\n \nPlots\n\n\n\n# Theoretical distributions\n\n\no1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n0.5\n)\n\n\no2\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2\n,\n \n0.3\n)\n\n\no3\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n0\n,\n \n4\n)\n\n\n\n# Theoretical distributions fitted to data\n\n\no4\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nrand\n(\nUniform\n(),\n \n100\n))\n\n\no5\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nrand\n(\nGamma\n(\n2\n,\n \n3\n),\n \n5000\n))\n\n\n\n# Kernel density estimated distributions for some more complex data.\n\n\nM1\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n5\n,\n \n0.5\n),\n \nGamma\n(\n2\n,\n \n5\n),\n \nNormal\n(\n12\n,\n \n0.2\n)])\n\n\nM2\n \n=\n \nMixtureModel\n([\nNormal\n(\n-\n2\n,\n \n0.1\n),\n \nNormal\n(\n1\n,\n \n0.2\n)])\n\n\no6\n \n=\n \nUncertainValue\n(\nrand\n(\nM1\n,\n \n1000\n))\n\n\no7\n \n=\n \nUncertainValue\n(\nrand\n(\nM2\n,\n \n1000\n))\n\n\n\nD\n \n=\n \nUncertainDataset\n([\no1\n,\n \no2\n,\n \no3\n,\n \no4\n,\n \no5\n,\n \no6\n,\n \no7\n])\n\n\n\n\n\n\n\nNow, plot the uncertain dataset.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nPlots\n\n\n# Initialise the plot\n\n\np\n \n=\n \nplot\n(\nlegend\n \n=\n \nfalse\n,\n \nxlabel\n \n=\n \n\"time step\"\n,\n \nylabel\n \n=\n \n\"value\"\n)\n\n\n\n# Plot the mean of the dataset\n\n\nplot!\n([\nmedian\n(\nD\n[\ni\n])\n \nfor\n \ni\n \n=\n \n1\n:\nlength\n(\nD\n)],\n \nlabel\n \n=\n \n\"mean\"\n,\n \nlc\n \n=\n \n:\nblue\n,\n \nlw\n \n=\n \n3\n)\n\n\n\nfor\n \ni\n \n=\n \n1\n:\n200\n\n    \nplot!\n(\np\n,\n \nresample\n(\nD\n),\n \nlw\n \n=\n \n0.4\n,\n \nl\u03b1\n \n=\n \n0.1\n,\n \nlc\n \n=\n \n:\nblack\n)\n\n\nend\n\n\n\np",
            "title": "Overview"
        },
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#example",
            "text": "Let's create a random walk and pretend it represents fluctuations in the mean of an observed dataset. Assume that each data point is normally distributed, and that the  i i -th observation has standard deviation  \\sigma_i \\in [0.3, 0.5] \\sigma_i \\in [0.3, 0.5] .  Representing these data as an  UncertainDataset  is done as follows:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   UncertainData ,   Distributions ,   Plots  # Create a random walk of 55 steps  n   =   55  rw   =   cumsum ( rand ( Normal (),   n ))  # Represent each value of the random walk as an uncertain value and  # collect them in an UncertainDataset  dist   =   Uniform ( 0.3 ,   0.5 )  uncertainvals   =   [ UncertainValue ( Normal ,   rw [ i ],   rand ( dist ))   for   i   =   1 : n ]  D   =   UncertainDataset ( uncertainvals )    We may then resample the dataset by calling  resample(D) . This will  resample each uncertain value  in the dataset. Alternatively,  resample(D, n)  resamples  n  times and returns a  n -element vector of resampled realizations.  Let's resample the uncertain dataset 100 times and plot the realisations.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Plots  # Initialise plot  p   =   plot ( legend   =   false ,   xlabel   =   \"time step\" ,   ylabel   =   \"value\" )  # Plot the mean of the dataset  plot! ( mean . ( D ),   label   =   \"mean\" ,   lc   =   : blue ,   lw   =   3 )  # Resample the dataset 100 times, add a line to the plot at each iteration  for   i   =   1 : 100 \n     plot! ( p ,   resample ( D ),   lw   =   0.4 ,   l\u03b1   =   0.2 ,   lc   =   : black )  end  p",
            "title": "Example"
        },
        {
            "location": "/uncertain_datasets/uncertain_datasets_overview/#example_2_mixing_different_types_of_uncertain_values",
            "text": "Mixing different types of uncertain values also works. Let's create a dataset of uncertain values constructed in different ways.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   UncertainData ,   Distributions ,   Plots  # Theoretical distributions  o1   =   UncertainValue ( Normal ,   0 ,   0.5 )  o2   =   UncertainValue ( Normal ,   2 ,   0.3 )  o3   =   UncertainValue ( Uniform ,   0 ,   4 )  # Theoretical distributions fitted to data  o4   =   UncertainValue ( Uniform ,   rand ( Uniform (),   100 ))  o5   =   UncertainValue ( Gamma ,   rand ( Gamma ( 2 ,   3 ),   5000 ))  # Kernel density estimated distributions for some more complex data.  M1   =   MixtureModel ([ Normal ( - 5 ,   0.5 ),   Gamma ( 2 ,   5 ),   Normal ( 12 ,   0.2 )])  M2   =   MixtureModel ([ Normal ( - 2 ,   0.1 ),   Normal ( 1 ,   0.2 )])  o6   =   UncertainValue ( rand ( M1 ,   1000 ))  o7   =   UncertainValue ( rand ( M2 ,   1000 ))  D   =   UncertainDataset ([ o1 ,   o2 ,   o3 ,   o4 ,   o5 ,   o6 ,   o7 ])    Now, plot the uncertain dataset.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Plots  # Initialise the plot  p   =   plot ( legend   =   false ,   xlabel   =   \"time step\" ,   ylabel   =   \"value\" )  # Plot the mean of the dataset  plot! ([ median ( D [ i ])   for   i   =   1 : length ( D )],   label   =   \"mean\" ,   lc   =   : blue ,   lw   =   3 )  for   i   =   1 : 200 \n     plot! ( p ,   resample ( D ),   lw   =   0.4 ,   l\u03b1   =   0.1 ,   lc   =   : black )  end  p",
            "title": "Example 2: mixing different types of uncertain values"
        },
        {
            "location": "/sampling_constraints/available_constraints/",
            "text": "The following sampling constraints are available:\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateStd\n \u2014 \nType\n.\n\n\n1\nTruncateStd(n\u03c3::Int)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at \nn\u03c3\n (\nn\n standard deviations).\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateMinimum\n \u2014 \nType\n.\n\n\n1\nTruncateMinimum(min::Number)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated below at some specified minimum value.\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateMaximum\n \u2014 \nType\n.\n\n\n1\nTruncateMaximum(max::Number)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated above at some specified maximum value.\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateRange\n \u2014 \nType\n.\n\n\n1\nTruncateRange(min::Number, max::Number)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at some range \n[min, max]\n.\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateLowerQuantile\n \u2014 \nType\n.\n\n\n1\nTruncateLowerQuantile(lower_quantile::Float64)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated below at some quantile.\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateUpperQuantile\n \u2014 \nType\n.\n\n\n1\nTruncateUpperQuantile(upper_quantile::Float64)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated above at some quantile.\n\n\nsource\n\n\n#\n\n\nUncertainData.SamplingConstraints.TruncateQuantiles\n \u2014 \nType\n.\n\n\n1\nTruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64)\n\n\n\n\n\n\nA constraint indicating that the distribution furnishing an uncertain value should be truncated at some quantile quantile \n(lower_quantile, upper_quantile)\n.\n\n\nsource",
            "title": "Available constraints"
        },
        {
            "location": "/sampling_constraints/constrain_uncertain_values/",
            "text": "constrain\n\u00b6\n\n\n#\n\n\nUncertainData.SamplingConstraints.constrain\n \u2014 \nMethod\n.\n\n\n1\nconstrain(uv::AbstractUncertainValue, constraint::SamplingConstraint)\n\n\n\n\n\n\nApply the \nconstraint\n and truncate the support of the distribution furnishing the uncertain value \nuv\n. Returns a constrained uncertain value.\n\n\nsource\n\n\n\n\nExamples\n\u00b6\n\n\n\n\n\n\nTheoretical distribution\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nUncertainData\n,\n \nDistributions\n\n\n\n# Define an uncertain value furnished by a theoretical distribution\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1\n,\n \n0.5\n)\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n0.5\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n1.5\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n0.5\n,\n \n1.5\n))\n\n\n\n\n\n\n\n\nTheoretical distribution with fitted parameters\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\nusing\n \nUncertainData\n,\n \nDistributions\n\n\n\n# Define an uncertain value furnished by a theoretical distribution with\n\n\n# parameters fitted to empirical data\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n-\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n0.5\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n1.5\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n0.5\n,\n \n1.5\n))\n\n\n\n\n\n\n\n\nKernel density estimated distribution\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n# Define an uncertain value furnished by a kernel density estimate to the\n\n\n# distribution of the empirical data\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nrand\n(\nUniform\n(\n10\n,\n \n15\n),\n \n1000\n))\n\n\n\n# Constrain the support of the furnishing distribution using various\n\n\n# constraints\n\n\nuvc_lq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nuvc_uq\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateUpperQuantile\n(\n0.8\n))\n\n\nuvc_q\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateQuantiles\n(\n0.2\n,\n \n0.8\n))\n\n\nuvc_min\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMinimum\n(\n13\n))\n\n\nuvc_max\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateMaximum\n(\n13\n))\n\n\nuvc_range\n \n=\n \nconstrain\n(\nuv\n,\n \nTruncateRange\n(\n11\n,\n \n12\n))",
            "title": "Constraining uncertain values"
        },
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#constrain",
            "text": "#  UncertainData.SamplingConstraints.constrain  \u2014  Method .  1 constrain(uv::AbstractUncertainValue, constraint::SamplingConstraint)   Apply the  constraint  and truncate the support of the distribution furnishing the uncertain value  uv . Returns a constrained uncertain value.  source",
            "title": "constrain"
        },
        {
            "location": "/sampling_constraints/constrain_uncertain_values/#examples",
            "text": "Theoretical distribution   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   UncertainData ,   Distributions  # Define an uncertain value furnished by a theoretical distribution  uv   =   UncertainValue ( Normal ,   1 ,   0.5 )  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 0.5 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 1.5 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 0.5 ,   1.5 ))     Theoretical distribution with fitted parameters   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14 using   UncertainData ,   Distributions  # Define an uncertain value furnished by a theoretical distribution with  # parameters fitted to empirical data  uv   =   UncertainValue ( Normal ,   rand ( Normal ( - 1 ,   0.2 ),   1000 ))  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 0.5 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 1.5 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 0.5 ,   1.5 ))     Kernel density estimated distribution   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 # Define an uncertain value furnished by a kernel density estimate to the  # distribution of the empirical data  uv   =   UncertainValue ( UnivariateKDE ,   rand ( Uniform ( 10 ,   15 ),   1000 ))  # Constrain the support of the furnishing distribution using various  # constraints  uvc_lq   =   constrain ( uv ,   TruncateLowerQuantile ( 0.2 ))  uvc_uq   =   constrain ( uv ,   TruncateUpperQuantile ( 0.8 ))  uvc_q   =   constrain ( uv ,   TruncateQuantiles ( 0.2 ,   0.8 ))  uvc_min   =   constrain ( uv ,   TruncateMinimum ( 13 ))  uvc_max   =   constrain ( uv ,   TruncateMaximum ( 13 ))  uvc_range   =   constrain ( uv ,   TruncateRange ( 11 ,   12 ))",
            "title": "Examples"
        },
        {
            "location": "/resampling/resampling_uncertain_values/",
            "text": "Without constraints\n\u00b6\n\n\nUncertain values may be resampled by drawing random number from the distributions furnishing them.\n\n\n\n\nresample(uv::AbstractUncertainValue)\n samples the uncertain value once,   drawing values from the entire support of the probability distribution   furnishing it.\n\n\nresample(uv::AbstractUncertainValuen, n::Int)\n samples the uncertain value   \nn\n times, drawing values from the entire support of the probability   distribution furnishing it.\n\n\n\n\n\n\n\n\nResample once\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\nresample\n(\nuv_theoretical\n)\n\n\nresample\n(\nuv_theoretical_fitted\n)\n\n\nresample\n(\nuv_kde\n)\n\n\n\n\n\n\n\n\nResample n times\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\nn\n \n=\n \n500\n\n\nresample\n(\nuv_theoretical\n,\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nn\n)\n\n\n\n\n\n\n\n\n\n\nWith constraints\n\u00b6\n\n\nResampling can also be performed with constraints.\n\n\n\n\nresample(uv::AbstractUncertainValue, constraint::SamplingConstraint)\n   samples the uncertain value once, drawing from a restricted   range of the support of the the probability distribution furnishing it.\n\n\nresample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int)\n   samples the uncertain value \nn\n times, drawing values from a restricted   range of the support of the the probability distribution furnishing it.\n\n\n\n\nAvailable sampling constraints are:\n\n\n\n\nTruncateStd(n\u03c3::Int)\n\n\nTruncateMinimum(min::Number)\n\n\nTruncateMaximum(max::Number)\n\n\nTruncateRange(min::Number, max::Number)\n\n\nTruncateLowerQuantile(lower_quantile::Float64)\n\n\nTruncateUpperQuantile(upper_quantile::Float64)\n\n\nTruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64)\n\n\n\n\nFor full documentation of the constraints, see the available constraints in the menu.\n\n\n\n\n\n\nLower quantile\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must be higher than the 0.2-th quantile of the distribution\n\n\n# furnishing the value.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateLowerQuantile\n(\n0.2\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateLowerQuantile\n(\n0.2\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateLowerQuantile\n(\n0.2\n))\n\n\n\n\n\n\n\n\nUpper quantile\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value  with the restriction that the sampled\n\n\n# values must be lower than the 0.95-th quantile of the distribution\n\n\n# furnishing the value.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateUpperQuantile\n(\n0.95\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateUpperQuantile\n(\n0.95\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateUpperQuantile\n(\n0.95\n))\n\n\n\n\n\n\n\n\nQuantile range\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must be within the (0.025, 0.975) quantile range.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateQuantiles\n(\n0.025\n,\n \n0.975\n))\n\n\n\n\n\n\n\n\nMinimum\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values have -2 as a lower bound.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMinimum\n(\n-\n2\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMinimum\n(\n-\n2\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMinimum\n(\n-\n2\n))\n\n\n\n\n\n\n\n\nMaximum\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values have 3 as an upper bound.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMaximum\n(\n3\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMaximum\n(\n3\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMaximum\n(\n3\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateMaximum\n(\n3\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateMaximum\n(\n3\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateMaximum\n(\n3\n))\n\n\n\n\n\n\n\n\nRange\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some uncertain values\n\n\nuv_theoretical\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n4\n,\n \n0.2\n)\n\n\nuv_theoretical_fitted\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nrand\n(\nNormal\n(\n1\n,\n \n0.2\n),\n \n1000\n))\n\n\nuv_kde\n \n=\n \nUncertainValue\n(\nrand\n(\nGamma\n(\n4\n,\n \n5\n),\n \n1000\n))\n\n\n\n# Resample the uncertain value with the restriction that the sampled\n\n\n# values must have values on the interval [-1, 1]. We first sample once,\n\n\n# then 50 times.\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\nresample\n(\nuv_kde\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))\n\n\n\nn\n \n=\n \n100\n\n\nresample\n(\nuv_theoretical\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n),\n \nn\n)\n\n\nresample\n(\nuv_theoretical_fitted\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n),\n \nn\n)\n\n\nresample\n(\nuv_kde\n,\n \nTruncateRange\n(\n-\n1\n,\n \n1\n))",
            "title": "Resampling uncertain values"
        },
        {
            "location": "/resampling/resampling_uncertain_values/#without_constraints",
            "text": "Uncertain values may be resampled by drawing random number from the distributions furnishing them.   resample(uv::AbstractUncertainValue)  samples the uncertain value once,   drawing values from the entire support of the probability distribution   furnishing it.  resample(uv::AbstractUncertainValuen, n::Int)  samples the uncertain value    n  times, drawing values from the entire support of the probability   distribution furnishing it.     Resample once   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  resample ( uv_theoretical )  resample ( uv_theoretical_fitted )  resample ( uv_kde )     Resample n times   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  n   =   500  resample ( uv_theoretical ,   n )  resample ( uv_theoretical_fitted ,   n )  resample ( uv_kde ,   n )",
            "title": "Without constraints"
        },
        {
            "location": "/resampling/resampling_uncertain_values/#with_constraints",
            "text": "Resampling can also be performed with constraints.   resample(uv::AbstractUncertainValue, constraint::SamplingConstraint)    samples the uncertain value once, drawing from a restricted   range of the support of the the probability distribution furnishing it.  resample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int)    samples the uncertain value  n  times, drawing values from a restricted   range of the support of the the probability distribution furnishing it.   Available sampling constraints are:   TruncateStd(n\u03c3::Int)  TruncateMinimum(min::Number)  TruncateMaximum(max::Number)  TruncateRange(min::Number, max::Number)  TruncateLowerQuantile(lower_quantile::Float64)  TruncateUpperQuantile(upper_quantile::Float64)  TruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64)   For full documentation of the constraints, see the available constraints in the menu.    Lower quantile   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must be higher than the 0.2-th quantile of the distribution  # furnishing the value.  resample ( uv_theoretical ,   TruncateLowerQuantile ( 0.2 ))  resample ( uv_theoretical_fitted ,   TruncateLowerQuantile ( 0.2 ))  resample ( uv_kde ,   TruncateLowerQuantile ( 0.2 ))  n   =   100  resample ( uv_theoretical ,   TruncateLowerQuantile ( 0.2 ),   n )  resample ( uv_theoretical_fitted ,   TruncateLowerQuantile ( 0.2 ),   n )  resample ( uv_kde ,   TruncateLowerQuantile ( 0.2 ))     Upper quantile   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value  with the restriction that the sampled  # values must be lower than the 0.95-th quantile of the distribution  # furnishing the value.  resample ( uv_theoretical ,   TruncateUpperQuantile ( 0.95 ))  resample ( uv_theoretical_fitted ,   TruncateUpperQuantile ( 0.95 ))  resample ( uv_kde ,   TruncateUpperQuantile ( 0.95 ))  n   =   100  resample ( uv_theoretical ,   TruncateUpperQuantile ( 0.95 ),   n )  resample ( uv_theoretical_fitted ,   TruncateUpperQuantile ( 0.95 ),   n )  resample ( uv_kde ,   TruncateUpperQuantile ( 0.95 ))     Quantile range   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must be within the (0.025, 0.975) quantile range.  resample ( uv_theoretical ,   TruncateQuantiles ( 0.025 ,   0.975 ))  resample ( uv_theoretical_fitted ,   TruncateQuantiles ( 0.025 ,   0.975 ))  resample ( uv_kde ,   TruncateQuantiles ( 0.025 ,   0.975 ))  n   =   100  resample ( uv_theoretical ,   TruncateQuantiles ( 0.025 ,   0.975 ),   n )  resample ( uv_theoretical_fitted ,   TruncateQuantiles ( 0.025 ,   0.975 ),   n )  resample ( uv_kde ,   TruncateQuantiles ( 0.025 ,   0.975 ))     Minimum   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values have -2 as a lower bound.  resample ( uv_theoretical ,   TruncateMinimum ( - 2 ))  resample ( uv_theoretical_fitted ,   TruncateMinimum ( - 2 ))  resample ( uv_kde ,   TruncateMinimum ( - 2 ))  n   =   100  resample ( uv_theoretical ,   TruncateMinimum ( - 2 ),   n )  resample ( uv_theoretical_fitted ,   TruncateMinimum ( - 2 ),   n )  resample ( uv_kde ,   TruncateMinimum ( - 2 ))     Maximum   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values have 3 as an upper bound.  resample ( uv_theoretical ,   TruncateMaximum ( 3 ))  resample ( uv_theoretical_fitted ,   TruncateMaximum ( 3 ))  resample ( uv_kde ,   TruncateMaximum ( 3 ))  n   =   100  resample ( uv_theoretical ,   TruncateMaximum ( 3 ),   n )  resample ( uv_theoretical_fitted ,   TruncateMaximum ( 3 ),   n )  resample ( uv_kde ,   TruncateMaximum ( 3 ))     Range   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 using   Distributions ,   UncertainData  # Generate some uncertain values  uv_theoretical   =   UncertainValue ( Normal ,   4 ,   0.2 )  uv_theoretical_fitted   =   UncertainValue ( Normal ,   rand ( Normal ( 1 ,   0.2 ),   1000 ))  uv_kde   =   UncertainValue ( rand ( Gamma ( 4 ,   5 ),   1000 ))  # Resample the uncertain value with the restriction that the sampled  # values must have values on the interval [-1, 1]. We first sample once,  # then 50 times.  resample ( uv_theoretical ,   TruncateRange ( - 1 ,   1 ))  resample ( uv_theoretical_fitted ,   TruncateRange ( - 1 ,   1 ))  resample ( uv_kde ,   TruncateRange ( - 1 ,   1 ))  n   =   100  resample ( uv_theoretical ,   TruncateRange ( - 1 ,   1 ),   n )  resample ( uv_theoretical_fitted ,   TruncateRange ( - 1 ,   1 ),   n )  resample ( uv_kde ,   TruncateRange ( - 1 ,   1 ))",
            "title": "With constraints"
        },
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/",
            "text": "This package implements most of the statistical algorithms in \nStatsBase\n for uncertain values and uncertain datasets.\n\n\nThe syntax for calling the algorithms is the same as in \nStatsBase\n, but the functions here accept an additional positional argument \nn\n, which controls how many times the uncertain values are resampled to compute the statistics.\n\n\n\n\nStatistics of single uncertain values\n\u00b6\n\n\n#\n\n\nStatistics.mean\n \u2014 \nMethod\n.\n\n\n1\nmean(uv::AbstractUncertainValue, n::Int)\n\n\n\n\n\n\nCompute the mean of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n#\n\n\nStatistics.median\n \u2014 \nMethod\n.\n\n\n1\nmedian(uv::AbstractUncertainValue, n::Int)\n\n\n\n\n\n\nCompute the median of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n1\nmiddle(uv::AbstractUncertainValue, n::Int)\n\n\n\n\n\n\n#\n\n\nStatistics.std\n \u2014 \nMethod\n.\n\n\n1\nstd(uv::AbstractUncertainValue, n::Int)\n\n\n\n\n\n\nCompute the standard deviation of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n#\n\n\nStatistics.var\n \u2014 \nMethod\n.\n\n\n1\nvariance(uv::AbstractUncertainValue, n::Int)\n\n\n\n\n\n\nCompute the variance of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n#\n\n\nStatistics.quantile\n \u2014 \nMethod\n.\n\n\n1\nquantile(uv::AbstractUncertainValue, q, n::Int)\n\n\n\n\n\n\nCompute the quantile(s) \nq\n of an uncertain value over an \nn\n-draw sample of it.\n\n\nsource\n\n\n\n\nStatistics on datasets of uncertain values\n\u00b6\n\n\nThe following statistics are available for uncertain datasets (collections of uncertain values).\n\n\n#\n\n\nStatistics.mean\n \u2014 \nMethod\n.\n\n\n1\nmean(d::UncertainDataset, n::Int)\n\n\n\n\n\n\nComputes the element-wise mean of a dataset of uncertain values. Takes the mean of an \nn\n-draw sample for each element.\n\n\nsource\n\n\n#\n\n\nStatistics.median\n \u2014 \nMethod\n.\n\n\n1\nmedian(d::UncertainDataset, n::Int)\n\n\n\n\n\n\nComputes the element-wise median of a dataset of uncertain values. Takes the median of an \nn\n-draw sample for each element.\n\n\nsource\n\n\n1\nmiddle(d::UncertainDataset, n::Int)\n\n\n\n\n\n\n#\n\n\nStatistics.std\n \u2014 \nMethod\n.\n\n\n1\nstd\n(\nd\n::\nUncertainDataset\n,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n\n\n\n\n\n\n\nComputes the element-wise standard deviation of a dataset of uncertain values. Takes the standard deviation of an \nn\n-draw sample for each element.\n\n\nsource\n\n\n#\n\n\nStatistics.var\n \u2014 \nMethod\n.\n\n\n1\nvar\n(\nd\n::\nUncertainDataset\n,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n\n\n\n\n\n\n\nComputes the element-wise sample variance of a dataset of uncertain values. Takes the sample variance of an \nn\n-draw sample for each element.\n\n\nsource\n\n\n#\n\n\nStatistics.quantile\n \u2014 \nMethod\n.\n\n\n1\nquantile\n(\nd\n::\nUncertainDataset\n,\n \np\n,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n\n\n\n\n\n\n\nCompute element-wise quantile(s) \np\nof a dataset consisting of uncertain values. Takes the quantiles of an \nn\n-draw sample for each element.\n\n\nsource\n\n\n#\n\n\nStatistics.cov\n \u2014 \nMethod\n.\n\n\n1\ncov\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n\n\n\n\n\n\n\nCompute the covariance between two \nUncertainDataset\ns by realising both datasets \nn\n times.\n\n\nsource\n\n\n#\n\n\nStatistics.cor\n \u2014 \nMethod\n.\n\n\n1\ncor\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n \nn\n::\nInt\n;\n \nkwargs\n...)\n\n\n\n\n\n\n\nCompute the Pearson correlation between two \nUncertainDataset\ns by realising both datasets \nn\n times.\n\n\nsource",
            "title": "Core statistics"
        },
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/#statistics_of_single_uncertain_values",
            "text": "#  Statistics.mean  \u2014  Method .  1 mean(uv::AbstractUncertainValue, n::Int)   Compute the mean of an uncertain value over an  n -draw sample of it.  source  #  Statistics.median  \u2014  Method .  1 median(uv::AbstractUncertainValue, n::Int)   Compute the median of an uncertain value over an  n -draw sample of it.  source  1 middle(uv::AbstractUncertainValue, n::Int)   #  Statistics.std  \u2014  Method .  1 std(uv::AbstractUncertainValue, n::Int)   Compute the standard deviation of an uncertain value over an  n -draw sample of it.  source  #  Statistics.var  \u2014  Method .  1 variance(uv::AbstractUncertainValue, n::Int)   Compute the variance of an uncertain value over an  n -draw sample of it.  source  #  Statistics.quantile  \u2014  Method .  1 quantile(uv::AbstractUncertainValue, q, n::Int)   Compute the quantile(s)  q  of an uncertain value over an  n -draw sample of it.  source",
            "title": "Statistics of single uncertain values"
        },
        {
            "location": "/uncertain_statistics/core_stats/core_statistics/#statistics_on_datasets_of_uncertain_values",
            "text": "The following statistics are available for uncertain datasets (collections of uncertain values).  #  Statistics.mean  \u2014  Method .  1 mean(d::UncertainDataset, n::Int)   Computes the element-wise mean of a dataset of uncertain values. Takes the mean of an  n -draw sample for each element.  source  #  Statistics.median  \u2014  Method .  1 median(d::UncertainDataset, n::Int)   Computes the element-wise median of a dataset of uncertain values. Takes the median of an  n -draw sample for each element.  source  1 middle(d::UncertainDataset, n::Int)   #  Statistics.std  \u2014  Method .  1 std ( d :: UncertainDataset ,   n :: Int ;   kwargs ...)    Computes the element-wise standard deviation of a dataset of uncertain values. Takes the standard deviation of an  n -draw sample for each element.  source  #  Statistics.var  \u2014  Method .  1 var ( d :: UncertainDataset ,   n :: Int ;   kwargs ...)    Computes the element-wise sample variance of a dataset of uncertain values. Takes the sample variance of an  n -draw sample for each element.  source  #  Statistics.quantile  \u2014  Method .  1 quantile ( d :: UncertainDataset ,   p ,   n :: Int ;   kwargs ...)    Compute element-wise quantile(s)  p of a dataset consisting of uncertain values. Takes the quantiles of an  n -draw sample for each element.  source  #  Statistics.cov  \u2014  Method .  1 cov ( d1 :: UncertainDataset ,   d2 :: UncertainDataset ,   n :: Int ;   kwargs ...)    Compute the covariance between two  UncertainDataset s by realising both datasets  n  times.  source  #  Statistics.cor  \u2014  Method .  1 cor ( d1 :: UncertainDataset ,   d2 :: UncertainDataset ,   n :: Int ;   kwargs ...)    Compute the Pearson correlation between two  UncertainDataset s by realising both datasets  n  times.  source",
            "title": "Statistics on datasets of uncertain values"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/",
            "text": "In addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from \nHypothesisTests.jl\n. This allows us to perform hypothesis testing on ensemble realisations of the data.\n\n\n\n\nImplemented hypothesis tests\n\u00b6\n\n\nThe following hypothesis tests are implemented for uncertain data types.\n\n\n\n\nOne sample t-test\n.\n\n\nEqual variance t-test\n.\n\n\nUnequal variance t-test\n.\n\n\nExact Kolmogorov-Smirnov test\n.\n\n\nApproximate two-sample Kolmogorov-Smirnov test\n.\n\n\nOne-sample Anderson\u2013Darling test\n.\n\n\nJarque-Bera test\n.\n\n\n\n\n\n\nTerminology\n\u00b6\n\n\nPooled statistics\n are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.\n\n\nElement-wise statistics\n are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.",
            "title": "Overview"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/#implemented_hypothesis_tests",
            "text": "The following hypothesis tests are implemented for uncertain data types.   One sample t-test .  Equal variance t-test .  Unequal variance t-test .  Exact Kolmogorov-Smirnov test .  Approximate two-sample Kolmogorov-Smirnov test .  One-sample Anderson\u2013Darling test .  Jarque-Bera test .",
            "title": "Implemented hypothesis tests"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/hypothesis_tests_overview/#terminology",
            "text": "Pooled statistics  are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.  Element-wise statistics  are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.",
            "title": "Terminology"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.OneSampleTTest\n \u2014 \nType\n.\n\n\n1\n2\nOneSampleTTest\n(\nd\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n1000\n;\n\n    \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nOneSampleTTest\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc0\n. \nn\n indicates the number of draws during resampling.\n\n\nsource\n\n\nExample:\n\n\n1\n2\n3\n4\n5\n6\n# Normally distributed uncertain observation with mean = 2.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.1\n,\n \n0.2\n)\n\n\n\n# Perform a one-sample t-test to test the null hypothesis that\n\n\n# the sample comes from a distribution with mean \u03bc0\n\n\nOneSampleTTest\n(\nuv\n,\n \n1000\n,\n \n\u03bc0\n \n=\n \n2.1\n)\n\n\n\n\n\n\n\nWhich gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n# Which results in\n\n\nOne\n \nsample\n \nt\n-\ntest\n\n\n-----------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n2.1\n\n    \npoint\n \nestimate\n:\n          \n2.1031909275381566\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n2.091\n,\n \n2.1154\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6089\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n    \nt\n-\nstatistic\n:\n              \n0.5117722099885472\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n999\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.00623505433839\n\n\n\n\n\n\n\nThus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample \ndoes\n in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleTTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nOneSampleTTest\n\n\n\n\n\n\n\nFirst, sample \nn\n draws of each uncertain value in each dataset, pooling the draws from the elements of \nd1\n and the draws from the elements of \nd2\n separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in \nd1\n and \nd2\n come from a distribution with mean \n\u03bc0\n against the alternative hypothesis that the distribution does not have mean \n\u03bc0\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleTTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nVector\n{\nOneSampleTTest\n}\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc0\n for uncertain value in \nd\n.\n\n\nn\n indicates the number of draws during resampling.\n\n\nsource",
            "title": "One sample t-test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#regular_test",
            "text": "#  HypothesisTests.OneSampleTTest  \u2014  Type .  1\n2 OneSampleTTest ( d :: AbstractUncertainValue ,   n :: Int   =   1000 ; \n     \u03bc0 :: Real   =   0 )   - >   OneSampleTTest    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc0  against the alternative hypothesis that its distribution does not have mean  \u03bc0 .  n  indicates the number of draws during resampling.  source  Example:  1\n2\n3\n4\n5\n6 # Normally distributed uncertain observation with mean = 2.1  uv   =   UncertainValue ( Normal ,   2.1 ,   0.2 )  # Perform a one-sample t-test to test the null hypothesis that  # the sample comes from a distribution with mean \u03bc0  OneSampleTTest ( uv ,   1000 ,   \u03bc0   =   2.1 )    Which gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 # Which results in  One   sample   t - test  -----------------  Population   details : \n     parameter   of   interest :     Mean \n     value   under   h_0 :           2.1 \n     point   estimate :            2.1031909275381566 \n     95 %   confidence   interval :   ( 2.091 ,   2.1154 )  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6089  Details : \n     number   of   observations :     1000 \n     t - statistic :                0.5117722099885472 \n     degrees   of   freedom :         999 \n     empirical   standard   error :   0.00623505433839    Thus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample  does  in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.OneSampleTTestPooled  \u2014  Function .  1\n2\n3 OneSampleTTestPooled ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   OneSampleTTest    First, sample  n  draws of each uncertain value in each dataset, pooling the draws from the elements of  d1  and the draws from the elements of  d2  separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in  d1  and  d2  come from a distribution with mean  \u03bc0  against the alternative hypothesis that the distribution does not have mean  \u03bc0 .  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/one_sample_t_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.OneSampleTTestElementWise  \u2014  Function .  1\n2\n3 OneSampleTTestElementWise ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   Vector { OneSampleTTest }    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc0  against the alternative hypothesis that its distribution does not have mean  \u03bc0  for uncertain value in  d .  n  indicates the number of draws during resampling.  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.EqualVarianceTTest\n \u2014 \nType\n.\n\n\n1\n2\nEqualVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nThis function performs a two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\nExample\n\n\nLet's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.\n\n\nWe expect the test to reject this null-hypothesis, because we've created two very different distributions.\n\n\n1\n2\n3\n4\n5\nuv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1.2\n,\n \n0.3\n)\n\n\nuv2\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n3\n)\n\n\n\n# EqualVarianceTTest on 1000 draws for each variable\n\n\nEqualVarianceTTest\n(\nuv1\n,\n \nuv2\n,\n \n1000\n)\n\n\n\n\n\n\n\nThe output is:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nTwo\n \nsample\n \nt\n-\ntest\n \n(\nequal\n \nvariance\n)\n\n\n----------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n \ndifference\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0\n\n    \npoint\n \nestimate\n:\n          \n-\n4.782470406651697\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n-\n5.0428\n,\n \n-\n4.5222\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n<\n1e-99\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n[\n1000\n,\n1000\n]\n\n    \nt\n-\nstatistic\n:\n              \n-\n36.03293014520585\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n1998\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.1327249931487462\n\n\n\n\n\n\n\nThe test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.EqualVarianceTTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. Gather all \ns1[i]\n in a pooled sample \nS1\n, and all \ns2[i]\n in a pooled sample \nS2\n.\n\n\nPerform a two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.EqualVarianceTTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nVector\n{\nEqualVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(s1[i], s2[i])\n. Specifically:\n\n\nPerforms an pairwise two-sample t-test of the null hypothesis that \ns1[i]\n and \ns2[i]\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource",
            "title": "Equal variance t-test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#regular_test",
            "text": "#  HypothesisTests.EqualVarianceTTest  \u2014  Type .  1\n2 EqualVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   EqualVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  This function performs a two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source  Example  Let's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.  We expect the test to reject this null-hypothesis, because we've created two very different distributions.  1\n2\n3\n4\n5 uv1   =   UncertainValue ( Normal ,   1.2 ,   0.3 )  uv2   =   UncertainValue ( Gamma ,   2 ,   3 )  # EqualVarianceTTest on 1000 draws for each variable  EqualVarianceTTest ( uv1 ,   uv2 ,   1000 )    The output is:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 Two   sample   t - test   ( equal   variance )  ----------------------------------  Population   details : \n     parameter   of   interest :     Mean   difference \n     value   under   h_0 :           0 \n     point   estimate :            - 4.782470406651697 \n     95 %   confidence   interval :   ( - 5.0428 ,   - 4.5222 )  Test   summary : \n     outcome   with   95 %   confidence :   reject   h_0 \n     two - sided   p - value :             < 1e-99  Details : \n     number   of   observations :     [ 1000 , 1000 ] \n     t - statistic :                - 36.03293014520585 \n     degrees   of   freedom :         1998 \n     empirical   standard   error :   0.1327249931487462    The test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.EqualVarianceTTestPooled  \u2014  Function .  1\n2 EqualVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   EqualVarianceTTest    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. Gather all  s1[i]  in a pooled sample  S1 , and all  s2[i]  in a pooled sample  S2 .  Perform a two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/equal_variance_t_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.EqualVarianceTTestElementWise  \u2014  Function .  1\n2 EqualVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   Vector { EqualVarianceTTest }    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  (s1[i], s2[i]) . Specifically:  Performs an pairwise two-sample t-test of the null hypothesis that  s1[i]  and  s2[i]  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.UnequalVarianceTTest\n \u2014 \nType\n.\n\n\n1\n2\nUnequalVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nPerform an unequal variance two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.UnequalVarianceTTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. Gather all \ns1[i]\n in a pooled sample \nS1\n, and all \ns2[i]\n in a pooled sample \nS2\n.\n\n\nThis function performs an unequal variance two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.UnequalVarianceTTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc0\n::\nReal\n \n=\n \n0\n)\n \n-\n>\n \nVector\n{\nUnequalVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(s1[i], s2[i])\n. Specifically:\n\n\nPerforms an pairwise unequal variance two-sample t-test of the null hypothesis that \ns1[i]\n and \ns2[i]\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nThis test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:\n\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n\nsource",
            "title": "Unequal variance t-test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#regular_test",
            "text": "#  HypothesisTests.UnequalVarianceTTest  \u2014  Type .  1\n2 UnequalVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   UnequalVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  Perform an unequal variance two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.UnequalVarianceTTestPooled  \u2014  Function .  1\n2 UnequalVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   UnequalVarianceTTest    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. Gather all  s1[i]  in a pooled sample  S1 , and all  s2[i]  in a pooled sample  S2 .  This function performs an unequal variance two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/unequal_variance_t_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.UnequalVarianceTTestElementWise  \u2014  Function .  1\n2 UnequalVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc0 :: Real   =   0 )   - >   Vector { UnequalVarianceTTest }    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  (s1[i], s2[i]) . Specifically:  Performs an pairwise unequal variance two-sample t-test of the null hypothesis that  s1[i]  and  s2[i]  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  This test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:   \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}  \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}   source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.ExactOneSampleKSTest\n \u2014 \nType\n.\n\n\n1\n2\nExactOneSampleKSTest(uv::AbstractUncertainValue,\n    d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest\n\n\n\n\n\n\nPerform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\nExample\n\n\nWe'll test whether the uncertain value \nuv = UncertainValue(Gamma, 2, 4)\n comes from the theoretical distribution \nGamma(2, 4)\n. Of course, we expect the test to confirm this, because we're using the exact same distribution.\n\n\n1\n2\n3\n4\n5\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n4\n)\n\n\n\n# Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the\n\n\n# uncertain value.\n\n\nExactOneSampleKSTest\n(\nuv\n,\n \nGamma\n(\n2\n,\n \n4\n),\n \n1000\n)\n\n\n\n\n\n\n\nThat gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nExact\n \none\n \nsample\n \nKolmogorov\n-\nSmirnov\n \ntest\n\n\n----------------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nSupremum\n \nof\n \nCDF\n \ndifferences\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0.0\n\n    \npoint\n \nestimate\n:\n          \n0.0228345021301449\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6655\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n\n\n\n\n\n\nAs expected, the test can't reject the hypothesis that the uncertain value \nuv\n comes from the theoretical distribution \nGamma(2, 4)\n, precisely because it does.\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.ExactOneSampleKSTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestPooled(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestElementWise(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -> Vector{ExactOneSampleKSTest}\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource",
            "title": "Exact Kolmogorov-Smirnov test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#regular_test",
            "text": "#  HypothesisTests.ExactOneSampleKSTest  \u2014  Type .  1\n2 ExactOneSampleKSTest(uv::AbstractUncertainValue,\n    d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest   Perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source  Example  We'll test whether the uncertain value  uv = UncertainValue(Gamma, 2, 4)  comes from the theoretical distribution  Gamma(2, 4) . Of course, we expect the test to confirm this, because we're using the exact same distribution.  1\n2\n3\n4\n5 uv   =   UncertainValue ( Gamma ,   2 ,   4 )  # Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the  # uncertain value.  ExactOneSampleKSTest ( uv ,   Gamma ( 2 ,   4 ),   1000 )    That gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 Exact   one   sample   Kolmogorov - Smirnov   test  ----------------------------------------  Population   details : \n     parameter   of   interest :     Supremum   of   CDF   differences \n     value   under   h_0 :           0.0 \n     point   estimate :            0.0228345021301449  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6655  Details : \n     number   of   observations :     1000    As expected, the test can't reject the hypothesis that the uncertain value  uv  comes from the theoretical distribution  Gamma(2, 4) , precisely because it does.",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.ExactOneSampleKSTestPooled  \u2014  Function .  1\n2 ExactOneSampleKSTestPooled(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest   First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise  \u2014  Function .  1\n2 ExactOneSampleKSTestElementWise(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -> Vector{ExactOneSampleKSTest}   First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/",
            "text": "Pooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestPooled(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -> ApproximateTwoSampleKSTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nd1\n, then separately draw \nn\n realisations of each uncertain value in \nd2\n. Then, pool all realisations for \nd1\n together and all realisations of \nd2\n together.\n\n\nOn the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the \nd1\n value pool represents the same distribution as the distribution furnishing the \nd2\n value pool, against the alternative hypothesis that the furnishing distributions are different.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestElementWise(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -> Vector{ApproximateTwoSampleKSTest}\n\n\n\n\n\n\nAssuming \nd1\n and \nd2\n contain the same number of uncertain observations, draw \nn\n realisations of each uncertain value in \nd1\n, then separately and separately draw \nn\n realisations of each uncertain value in \nd2\n.\n\n\nThen, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in \nd1\n and \nd2\n come from the same distribution against the alternative hypothesis that the (element-wise) values in  \nd1\n and \nd2\n come from different distributions.\n\n\nThe test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with \nn\n draws for the \ni\ni\n-ith pair of uncertain values.\n\n\nsource",
            "title": "Approximate two-sample Kolmogorov-Smirnov test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled  \u2014  Function .  1\n2 ApproximateTwoSampleKSTestPooled(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -> ApproximateTwoSampleKSTest   First, draw  n  realisations of each uncertain value in  d1 , then separately draw  n  realisations of each uncertain value in  d2 . Then, pool all realisations for  d1  together and all realisations of  d2  together.  On the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the  d1  value pool represents the same distribution as the distribution furnishing the  d2  value pool, against the alternative hypothesis that the furnishing distributions are different.  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise  \u2014  Function .  1\n2 ApproximateTwoSampleKSTestElementWise(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -> Vector{ApproximateTwoSampleKSTest}   Assuming  d1  and  d2  contain the same number of uncertain observations, draw  n  realisations of each uncertain value in  d1 , then separately and separately draw  n  realisations of each uncertain value in  d2 .  Then, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in  d1  and  d2  come from the same distribution against the alternative hypothesis that the (element-wise) values in   d1  and  d2  come from different distributions.  The test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with  n  draws for the  i i -ith pair of uncertain values.  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.JarqueBeraTest\n \u2014 \nType\n.\n\n\n1\nJarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -> JarqueBeraTest\n\n\n\n\n\n\nCompute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.\n\n\nsource\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.JarqueBeraTestPooled\n \u2014 \nFunction\n.\n\n\n1\nJarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -> JarqueBeraTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.JarqueBeraTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nOneSampleADTestElementWise(ud::UncertainDataset,\n    n::Int = 1000) -> Vector{JarqueBeraTest}\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.\n\n\nsource",
            "title": "Jarque-Bera test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#regular_test",
            "text": "#  HypothesisTests.JarqueBeraTest  \u2014  Type .  1 JarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -> JarqueBeraTest   Compute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.  source",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.JarqueBeraTestPooled  \u2014  Function .  1 JarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -> JarqueBeraTest   First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/jarque_bera_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.JarqueBeraTestElementWise  \u2014  Function .  1\n2 OneSampleADTestElementWise(ud::UncertainDataset,\n    n::Int = 1000) -> Vector{JarqueBeraTest}   First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.MannWhitneyUTest\n \u2014 \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue,\n    n::Int = 1000) -> MannWhitneyUTest\n\n\n\n\n\n\nLet \ns1\n and \ns2\n be samples of \nn\n realisations from the distributions furnishing the uncertain values \nd1\n and \nd2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns1\n is greater than an observation drawn from the same population as \ns2\n is equal to the probability that an observation drawn from the same population as \ns2\n is greater than an observation drawn from the same population as \ns1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.MannWhitneyUTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -> MannWhitneyUTest\n\n\n\n\n\n\nLet \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1[i]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n.  Next, gather the samples for all \ns_{1_{i}}\ns_{1_{i}}\n in a pooled sample \nS_1\nS_1\n.  Do the same for the second uncertain dataset \nd2\n, yielding the pooled sample  \nS_2\nS_2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \nS_1\nS_1\n is greater than an observation drawn from the same population as \nS_2\nS_2\n is equal to the probability that an observation drawn from the same population as \nS_2\nS_2\n is greater than an observation drawn from the same population as \nS_1\nS_1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.MannWhitneyUTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -> Vector{MannWhitneyUTest}\n\n\n\n\n\n\nAssume \nd1\n and \nd2\n consist of the same number of uncertain values. Let \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1[i]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n. Let \ns_{2_{i}}\ns_{2_{i}}\n be the corresponding sample for \nd2[i]\n. This function\n\n\nPerform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n is greater than an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is equal to the probability that an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is greater than an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource",
            "title": "Mann-Whitney u-test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#regular_test",
            "text": "#  HypothesisTests.MannWhitneyUTest  \u2014  Function .  1\n2 MannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue,\n    n::Int = 1000) -> MannWhitneyUTest   Let  s1  and  s2  be samples of  n  realisations from the distributions furnishing the uncertain values  d1  and  d2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s1  is greater than an observation drawn from the same population as  s2  is equal to the probability that an observation drawn from the same population as  s2  is greater than an observation drawn from the same population as  s1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.MannWhitneyUTestPooled  \u2014  Function .  1\n2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -> MannWhitneyUTest   Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1[i] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 .  Next, gather the samples for all  s_{1_{i}} s_{1_{i}}  in a pooled sample  S_1 S_1 .  Do the same for the second uncertain dataset  d2 , yielding the pooled sample   S_2 S_2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  S_1 S_1  is greater than an observation drawn from the same population as  S_2 S_2  is equal to the probability that an observation drawn from the same population as  S_2 S_2  is greater than an observation drawn from the same population as  S_1 S_1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/mann_whitney_u_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.MannWhitneyUTestElementWise  \u2014  Function .  1\n2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -> Vector{MannWhitneyUTest}   Assume  d1  and  d2  consist of the same number of uncertain values. Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1[i] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 . Let  s_{2_{i}} s_{2_{i}}  be the corresponding sample for  d2[i] . This function  Perform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  is greater than an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is equal to the probability that an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is greater than an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source",
            "title": "Element-wise test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/",
            "text": "Regular test\n\u00b6\n\n\n#\n\n\nHypothesisTests.OneSampleADTest\n \u2014 \nType\n.\n\n\n1\n2\nOneSampleADTest(uv::UncertainValue, d::UnivariateDistribution,\n    n::Int = 1000) -> OneSampleADTest\n\n\n\n\n\n\nPerform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nPooled test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleADTestPooled\n \u2014 \nFunction\n.\n\n\n1\n2\nOneSampleADTestPooled(ud::UncertainDataset, d::UnivariateDistribution,\n    n::Int = 1000)) -> OneSampleADTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then perform a one-sample Anderson\u2013Darling test of the null hypothesis that the pooled values comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nElement-wise test\n\u00b6\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleADTestElementWise\n \u2014 \nFunction\n.\n\n\n1\n2\nOneSampleADTestElementWise(ud::UncertainDataset, d::UnivariateDistribution,\n    n::Int = 1000)) -> Vector{OneSampleADTest}\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample Anderson\u2013Darling test of the null hypothesis that each value pool comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource",
            "title": "Anderson-Darling test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#regular_test",
            "text": "#  HypothesisTests.OneSampleADTest  \u2014  Type .  1\n2 OneSampleADTest(uv::UncertainValue, d::UnivariateDistribution,\n    n::Int = 1000) -> OneSampleADTest   Perform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source",
            "title": "Regular test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#pooled_test",
            "text": "#  UncertainData.UncertainStatistics.OneSampleADTestPooled  \u2014  Function .  1\n2 OneSampleADTestPooled(ud::UncertainDataset, d::UnivariateDistribution,\n    n::Int = 1000)) -> OneSampleADTest   First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then perform a one-sample Anderson\u2013Darling test of the null hypothesis that the pooled values comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source",
            "title": "Pooled test"
        },
        {
            "location": "/uncertain_statistics/hypothesistests/anderson_darling_test/#element-wise_test",
            "text": "#  UncertainData.UncertainStatistics.OneSampleADTestElementWise  \u2014  Function .  1\n2 OneSampleADTestElementWise(ud::UncertainDataset, d::UnivariateDistribution,\n    n::Int = 1000)) -> Vector{OneSampleADTest}   First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample Anderson\u2013Darling test of the null hypothesis that each value pool comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source",
            "title": "Element-wise test"
        },
        {
            "location": "/implementing_algorithms_for_uncertaindata/",
            "text": "Extending existing algorithms for uncertain data types\n\u00b6\n\n\nDo you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the \nAbstractUncertainValue\n and \nAbstractUncertainDataset\n types, along with a \nSamplingConstraints\n specifying how the uncertain values are should be resampled.\n\n\nA basic function skeleton could be\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# Some algorithm computing a statistic for a scalar-valued vector\n\n\nfunction\n \nmyalgorithm\n(\ndataset\n::\nVector\n{\nT\n};\n \nkwargs\n...\n)\n \nwhere\n \nT\n\n    \n# some algorithm returning a single-valued statistic\n\n\nend\n\n\n\n# Applying the algorithm to an ensemble of realisations from\n\n\n# an uncertain dataset, given a sampling constraint.\n\n\nfunction\n \nmyalgorithm\n(\nd\n::\nUncertainDataset\n,\n \nconstraint\n::\nC\n;\n\n        \nn_ensemble_realisations\n \n=\n \n100\n,\n \nkwargs\n...\n)\n\n        \nwhere\n \n{\nC\n \n<:\n \nSamplingConstraint\n}\n\n\n    \nensemble_stats\n \n=\n \nzeros\n(\nn_ensemble_realisations\n)\n\n\n    \nfor\n \ni\n \nin\n \n1\n:\nn_ensemble_realisations\n\n        \nensemble_stats\n[\ni\n]\n \n=\n \nmyalgorithm\n(\nresample\n(\nd\n,\n \nconstraint\n);\n \nkwargs\n...\n)\n\n    \nend\n\n\n    \nreturn\n \nensemble_stats\n\n\nend",
            "title": "Implementing algorithms for uncertain data"
        },
        {
            "location": "/implementing_algorithms_for_uncertaindata/#extending_existing_algorithms_for_uncertain_data_types",
            "text": "Do you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the  AbstractUncertainValue  and  AbstractUncertainDataset  types, along with a  SamplingConstraints  specifying how the uncertain values are should be resampled.  A basic function skeleton could be   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 # Some algorithm computing a statistic for a scalar-valued vector  function   myalgorithm ( dataset :: Vector { T };   kwargs ... )   where   T \n     # some algorithm returning a single-valued statistic  end  # Applying the algorithm to an ensemble of realisations from  # an uncertain dataset, given a sampling constraint.  function   myalgorithm ( d :: UncertainDataset ,   constraint :: C ; \n         n_ensemble_realisations   =   100 ,   kwargs ... ) \n         where   { C   <:   SamplingConstraint } \n\n     ensemble_stats   =   zeros ( n_ensemble_realisations ) \n\n     for   i   in   1 : n_ensemble_realisations \n         ensemble_stats [ i ]   =   myalgorithm ( resample ( d ,   constraint );   kwargs ... ) \n     end \n\n     return   ensemble_stats  end",
            "title": "Extending existing algorithms for uncertain data types"
        }
    ]
}