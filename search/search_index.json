{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"UncertainData.jl Motivation UncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data significantly easier. Probabilistic representation of uncertain observations Way too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean). Uncertain values and datasets of uncertain values In this package, data values are stored as probability distributions. Individual uncertain observations may be collected in UncertainDatasets , which can be sampled according to user-provided sampling constraints. Likewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values. Basic workflow Creating uncertain values Uncertain values are created by using the UncertainValue constructor. There are currently three ways to construct uncertain values: Estimating the distribution of your data using kernel density estimation. Fitting a distribution to empirical data (if you know roughly what type of distribution is appropriate). Specifying a probability distribution with known parameters (if you want to represent data found in the literature, for example normally distributed values with some standard deviation). Resampling Uncertain values may be resampled using the resample(uv::UncertainValue) function, which has methods for all the different types of uncertain values.","title":"Home"},{"location":"#uncertaindatajl","text":"","title":"UncertainData.jl"},{"location":"#motivation","text":"UncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data significantly easier.","title":"Motivation"},{"location":"#probabilistic-representation-of-uncertain-observations","text":"Way too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean).","title":"Probabilistic representation of uncertain observations"},{"location":"#uncertain-values-and-datasets-of-uncertain-values","text":"In this package, data values are stored as probability distributions. Individual uncertain observations may be collected in UncertainDatasets , which can be sampled according to user-provided sampling constraints. Likewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values.","title":"Uncertain values and datasets of uncertain values"},{"location":"#basic-workflow","text":"","title":"Basic workflow"},{"location":"#creating-uncertain-values","text":"Uncertain values are created by using the UncertainValue constructor. There are currently three ways to construct uncertain values: Estimating the distribution of your data using kernel density estimation. Fitting a distribution to empirical data (if you know roughly what type of distribution is appropriate). Specifying a probability distribution with known parameters (if you want to represent data found in the literature, for example normally distributed values with some standard deviation).","title":"Creating uncertain values"},{"location":"#resampling","text":"Uncertain values may be resampled using the resample(uv::UncertainValue) function, which has methods for all the different types of uncertain values.","title":"Resampling"},{"location":"ensemble_statistics/","text":"Uncertain statistics Core statistics This package implements most of the statistical algorithms in StatsBase for uncertain values and uncertain datasets. The syntax for calling the algorithms is the same as in StatsBase , but the functions here accept an additional positional argument n , which controls how many times the uncertain values are resampled to compute the statistics. The default number of times to resample is n = 1000 . Statistics of single uncertain values mean(d::AbstractUncertainValue, n::Int = 1000) . Computes the mean of an uncertain value. median(d::AbstractUncertainValue, n::Int = 1000) . Computes the median of an uncertain value. middle(d::AbstractUncertainValue, n::Int = 1000) . Computes the middle of an uncertain value. std(d::AbstractUncertainValue, n::Int = 1000) . Computes the standard deviation of an uncertain value. var(d::AbstractUncertainValue, n::Int = 1000) . Computes the variance of an uncertain value. quantile(d::AbstractUncertainValue, p, n::Int = 1000) . Computes the p -th quantile(s) of an uncertain value. Statistics on datasets of uncertain values The following statistics are available for uncertain datasets (collections of uncertain values). mean(d::UncertainDataset ). Computes the element-wise mean of a dataset of uncertain values. median(d::UncertainDataset ). Computes the element-wise median of a dataset of uncertain values. middle(d::UncertainDataset ). Computes the element-wise middle of a dataset of uncertain values. std(d::UncertainDataset ). Computes the element-wise standard deviation of a dataset of uncertain values. var(d::UncertainDataset ). Computes the element-wise variance of a dataset of uncertain values. quantile(d::UncertainDataset, p, n::Int = 1000) . Computes the element-wise p -th quantile(s) of a dataset of uncertain values. cor(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values. cov(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values.","title":"Core statistics"},{"location":"ensemble_statistics/#uncertain-statistics","text":"","title":"Uncertain statistics"},{"location":"ensemble_statistics/#core-statistics","text":"This package implements most of the statistical algorithms in StatsBase for uncertain values and uncertain datasets. The syntax for calling the algorithms is the same as in StatsBase , but the functions here accept an additional positional argument n , which controls how many times the uncertain values are resampled to compute the statistics. The default number of times to resample is n = 1000 .","title":"Core statistics"},{"location":"ensemble_statistics/#statistics-of-single-uncertain-values","text":"mean(d::AbstractUncertainValue, n::Int = 1000) . Computes the mean of an uncertain value. median(d::AbstractUncertainValue, n::Int = 1000) . Computes the median of an uncertain value. middle(d::AbstractUncertainValue, n::Int = 1000) . Computes the middle of an uncertain value. std(d::AbstractUncertainValue, n::Int = 1000) . Computes the standard deviation of an uncertain value. var(d::AbstractUncertainValue, n::Int = 1000) . Computes the variance of an uncertain value. quantile(d::AbstractUncertainValue, p, n::Int = 1000) . Computes the p -th quantile(s) of an uncertain value.","title":"Statistics of single uncertain values"},{"location":"ensemble_statistics/#statistics-on-datasets-of-uncertain-values","text":"The following statistics are available for uncertain datasets (collections of uncertain values). mean(d::UncertainDataset ). Computes the element-wise mean of a dataset of uncertain values. median(d::UncertainDataset ). Computes the element-wise median of a dataset of uncertain values. middle(d::UncertainDataset ). Computes the element-wise middle of a dataset of uncertain values. std(d::UncertainDataset ). Computes the element-wise standard deviation of a dataset of uncertain values. var(d::UncertainDataset ). Computes the element-wise variance of a dataset of uncertain values. quantile(d::UncertainDataset, p, n::Int = 1000) . Computes the element-wise p -th quantile(s) of a dataset of uncertain values. cor(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values. cov(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values.","title":"Statistics on datasets of uncertain values"},{"location":"implementing_algorithms_for_uncertaindata/","text":"Extending existing algorithms for uncertain data types Do you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the AbstractUncertainValue and AbstractUncertainDataset types, along with a SamplingConstraints specifying how the uncertain values are should be resampled. A basic function skeleton could be 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Some algorithm computing a statistic for a scalar-valued vector function myalgorithm ( dataset :: Vector { T }; kwargs ... ) where T # some algorithm returning a single-valued statistic end # Applying the algorithm to an ensemble of realisations from # an uncertain dataset, given a sampling constraint. function myalgorithm ( d :: UncertainDataset , constraint :: C ; n_ensemble_realisations = 100 , kwargs ... ) where { C <: SamplingConstraint } ensemble_stats = zeros ( n_ensemble_realisations ) for i in 1 : n_ensemble_realisations ensemble_stats [ i ] = myalgorithm ( resample ( d , constraint ); kwargs ... ) end return ensemble_stats end","title":"Implementing algorithms for uncertain data"},{"location":"implementing_algorithms_for_uncertaindata/#extending-existing-algorithms-for-uncertain-data-types","text":"Do you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the AbstractUncertainValue and AbstractUncertainDataset types, along with a SamplingConstraints specifying how the uncertain values are should be resampled. A basic function skeleton could be 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Some algorithm computing a statistic for a scalar-valued vector function myalgorithm ( dataset :: Vector { T }; kwargs ... ) where T # some algorithm returning a single-valued statistic end # Applying the algorithm to an ensemble of realisations from # an uncertain dataset, given a sampling constraint. function myalgorithm ( d :: UncertainDataset , constraint :: C ; n_ensemble_realisations = 100 , kwargs ... ) where { C <: SamplingConstraint } ensemble_stats = zeros ( n_ensemble_realisations ) for i in 1 : n_ensemble_realisations ensemble_stats [ i ] = myalgorithm ( resample ( d , constraint ); kwargs ... ) end return ensemble_stats end","title":"Extending existing algorithms for uncertain data types"},{"location":"resampling/","text":"Resampling Without constraints Regular resampling is done by drawing random number from the entire probability distributions furnishing the uncertain values. With constraints The following syntax is used to resample uncertain values. resample(uv::AbstractUncertainValue, constraint::SamplingConstraint) . Resample the uncertain value once within the restrictions imposed by the sampling constraint. resample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int) . Resample the uncertain value n times within the restrictions imposed by the sampling constraint. Sampling constraints The following sampling constraints are available: TruncateStd(n\u03c3::Int) . Truncate the distribution furnishing the uncertain data point(s) at n times the standard deviation of the distribution. TruncateMinimum(min<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some minimum value. TruncateMaximum(max<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some maximum value. TruncateRange(min<:Number, max<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some range. TruncateLowerQuantile(lower_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some lower quantile of the distribution. TruncateUpperQuantile(upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some upper quantile of the distribution. TruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at a lower_quantile and an upper_quantile of the distribution. Examples Let uv = UncertainValue(Normal, 1, 0.2) . One may, for example, impose the following sampling constraints: resample(uv, TruncateLowerQuantile(0.2)) . Resamples uv 100 times, drawing values strictly larger than the 0.2-th quantile of the distribution furnishing the uncertain data point. resample(uv, TruncateStd(1), 100) . Resamples uv 100 times, drawing values falling within one standard deviation of the distribution furnishing the uncertain value. resample(uv, TruncateRange(-0.5, 1), 100) . Resamples uv 100 times, drawing values from the distribution furnishing the uncertain value within the interval [-0.5, 1] .","title":"Resampling"},{"location":"resampling/#resampling","text":"","title":"Resampling"},{"location":"resampling/#without-constraints","text":"Regular resampling is done by drawing random number from the entire probability distributions furnishing the uncertain values.","title":"Without constraints"},{"location":"resampling/#with-constraints","text":"The following syntax is used to resample uncertain values. resample(uv::AbstractUncertainValue, constraint::SamplingConstraint) . Resample the uncertain value once within the restrictions imposed by the sampling constraint. resample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int) . Resample the uncertain value n times within the restrictions imposed by the sampling constraint.","title":"With constraints"},{"location":"resampling/#sampling-constraints","text":"The following sampling constraints are available: TruncateStd(n\u03c3::Int) . Truncate the distribution furnishing the uncertain data point(s) at n times the standard deviation of the distribution. TruncateMinimum(min<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some minimum value. TruncateMaximum(max<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some maximum value. TruncateRange(min<:Number, max<:Number) . Truncate the distribution furnishing the uncertain data point(s) at some range. TruncateLowerQuantile(lower_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some lower quantile of the distribution. TruncateUpperQuantile(upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some upper quantile of the distribution. TruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at a lower_quantile and an upper_quantile of the distribution.","title":"Sampling constraints"},{"location":"resampling/#examples","text":"Let uv = UncertainValue(Normal, 1, 0.2) . One may, for example, impose the following sampling constraints: resample(uv, TruncateLowerQuantile(0.2)) . Resamples uv 100 times, drawing values strictly larger than the 0.2-th quantile of the distribution furnishing the uncertain data point. resample(uv, TruncateStd(1), 100) . Resamples uv 100 times, drawing values falling within one standard deviation of the distribution furnishing the uncertain value. resample(uv, TruncateRange(-0.5, 1), 100) . Resamples uv 100 times, drawing values from the distribution furnishing the uncertain value within the interval [-0.5, 1] .","title":"Examples"},{"location":"uncertainvalues_fitted/","text":"Uncertain values from fitted distributions For data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution. Examples In the following examples, we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. Uniform 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Uniform () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Define an uncertain value by fitting a uniform distribution to the sample. uv = UncertainValue ( Uniform , some_sample ) Normal 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Represent the uncertain value by a fitted normal distribution. uv = UncertainValue ( Normal , some_sample ) Gamma 1 2 3 4 5 6 7 8 using Distributions , UncertainData # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1, # \u03b8 = 5.2. some_sample = rand ( Gamma ( 2.1 , 5.2 ), 1000 ) # Represent the uncertain value by a fitted gamma distribution. uv = UncertainValue ( Gamma , some_sample ) Supported distributions Supported distributions are Uniform , Normal , Gamma , Beta , BetaPrime , Frechet , Binomial , BetaBinomial . Beware: fitting distributions may lead to nonsensical results! In a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution. 1 2 3 4 5 6 7 8 using Distributions , UncertainData # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1, # \u03b8 = 5.2. some_sample = rand ( Gamma ( 2.1 , 5.2 ), 1000 ) # Represent the uncertain value by a fitted beta distribution. uv = UncertainValue ( Beta , some_sample ) This is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data. If the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value. Constructor To construct uncertain values represented by empirical distributions, use the following constructor. 1 2 UncertainValue ( d :: Type { D }, empiricaldata ) where { D <: Distributions . Distribution } This will fit a distribution of type d to the data and keep that as the representation of the empirical distribution. Calls Distributions.fit behind the scenes.","title":"Fitted distributions"},{"location":"uncertainvalues_fitted/#uncertain-values-from-fitted-distributions","text":"For data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution.","title":"Uncertain values from fitted distributions"},{"location":"uncertainvalues_fitted/#examples","text":"In the following examples, we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits. Uniform 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Uniform () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Define an uncertain value by fitting a uniform distribution to the sample. uv = UncertainValue ( Uniform , some_sample ) Normal 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Represent the uncertain value by a fitted normal distribution. uv = UncertainValue ( Normal , some_sample ) Gamma 1 2 3 4 5 6 7 8 using Distributions , UncertainData # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1, # \u03b8 = 5.2. some_sample = rand ( Gamma ( 2.1 , 5.2 ), 1000 ) # Represent the uncertain value by a fitted gamma distribution. uv = UncertainValue ( Gamma , some_sample )","title":"Examples"},{"location":"uncertainvalues_fitted/#supported-distributions","text":"Supported distributions are Uniform , Normal , Gamma , Beta , BetaPrime , Frechet , Binomial , BetaBinomial .","title":"Supported distributions"},{"location":"uncertainvalues_fitted/#beware-fitting-distributions-may-lead-to-nonsensical-results","text":"In a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution. 1 2 3 4 5 6 7 8 using Distributions , UncertainData # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1, # \u03b8 = 5.2. some_sample = rand ( Gamma ( 2.1 , 5.2 ), 1000 ) # Represent the uncertain value by a fitted beta distribution. uv = UncertainValue ( Beta , some_sample ) This is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data. If the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.","title":"Beware: fitting distributions may lead to nonsensical results!"},{"location":"uncertainvalues_fitted/#constructor","text":"To construct uncertain values represented by empirical distributions, use the following constructor. 1 2 UncertainValue ( d :: Type { D }, empiricaldata ) where { D <: Distributions . Distribution } This will fit a distribution of type d to the data and keep that as the representation of the empirical distribution. Calls Distributions.fit behind the scenes.","title":"Constructor"},{"location":"uncertainvalues_kde/","text":"Uncertain value from KDE estimate 1 UncertainValue(::UnivariateKDE, ::Vector) Representing uncertain values by a kernel density estimate is appropriate when data have an empirical distribution that doesn't follow any obvious theoretical distribution. To visualize this, let's create a bimodal distribution, then sample 10000 values from it. 1 2 3 4 5 6 7 8 9 10 11 using Distributions n1 = Normal ( - 3.0 , 1.2 ) n2 = Normal ( 8.0 , 1.2 ) n3 = Normal ( 0.0 , 2.5 ) # Use a mixture model to create a bimodal distribution M = MixtureModel ([ n1 , n2 , n3 ]) # Sample the mixture model. samples_empirical = rand ( M , Int ( 1e4 )); It is not obvious which distribution to fit to such data. A kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values. To create a kernel density estimate, simply call the UncertainValue(v::Vector{Number}) constructor with a vector containing the sample: 1 uv = UncertainValue ( samples_empirical ) The plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate. 1 2 3 4 5 6 7 using Plots , StatPlots , UncertainData uv = UncertainValue ( samples_empirical ) density ( mvals , label = \"10000 mixture model (M) samples\" ) density! ( rand ( uv , Int ( 1e4 )), label = \"10000 samples from KDE estimate to M\" ) xlabel! ( \"data value\" ) ylabel! ( \"probability density\" ) Additional keyword arguments and examples If the only argument to the UncertainValue constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e. UncertainValue(data) . Gaussian kernels are used by default. The syntax UncertainValue(UnivariateKDE, data) will also work if KernelDensity.jl is loaded. Implicit KDE constructor 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the implicit KDE constructor to create the uncertain value uv = UncertainValue ( v :: Vector ) Explicit KDE constructor 1 2 3 4 5 6 7 8 9 10 11 12 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value. # This constructor follows the same convention as when fitting distributions # to empirical data, so this is the recommended way to construct KDE estimates. uv = UncertainValue ( UnivariateKDE , v :: Vector ) Changing the kernel 1 2 3 4 5 6 7 8 9 10 11 12 13 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value, specifying # that we want to use normal distributions as the kernel. The kernel can be # any valid kernel from Distributions.jl, and the default is to use normal # distributions. uv = UncertainValue ( UnivariateKDE , v :: Vector ; kernel = Normal ) Adjusting number of points 1 2 3 4 5 6 7 8 9 10 11 12 13 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value, specifying # the number of points we want to use for the kernel density estimate. Fast # Fourier transforms are used behind the scenes, so the number of points # should be a power of 2 (the default is 2048 points). uv = UncertainValue ( UnivariateKDE , v :: Vector ; npoints = 1024 )","title":"Kernel density estimates (KDE)"},{"location":"uncertainvalues_kde/#uncertain-value-from-kde-estimate","text":"1 UncertainValue(::UnivariateKDE, ::Vector) Representing uncertain values by a kernel density estimate is appropriate when data have an empirical distribution that doesn't follow any obvious theoretical distribution. To visualize this, let's create a bimodal distribution, then sample 10000 values from it. 1 2 3 4 5 6 7 8 9 10 11 using Distributions n1 = Normal ( - 3.0 , 1.2 ) n2 = Normal ( 8.0 , 1.2 ) n3 = Normal ( 0.0 , 2.5 ) # Use a mixture model to create a bimodal distribution M = MixtureModel ([ n1 , n2 , n3 ]) # Sample the mixture model. samples_empirical = rand ( M , Int ( 1e4 )); It is not obvious which distribution to fit to such data. A kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values. To create a kernel density estimate, simply call the UncertainValue(v::Vector{Number}) constructor with a vector containing the sample: 1 uv = UncertainValue ( samples_empirical ) The plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate. 1 2 3 4 5 6 7 using Plots , StatPlots , UncertainData uv = UncertainValue ( samples_empirical ) density ( mvals , label = \"10000 mixture model (M) samples\" ) density! ( rand ( uv , Int ( 1e4 )), label = \"10000 samples from KDE estimate to M\" ) xlabel! ( \"data value\" ) ylabel! ( \"probability density\" )","title":"Uncertain value from KDE estimate"},{"location":"uncertainvalues_kde/#additional-keyword-arguments-and-examples","text":"If the only argument to the UncertainValue constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e. UncertainValue(data) . Gaussian kernels are used by default. The syntax UncertainValue(UnivariateKDE, data) will also work if KernelDensity.jl is loaded. Implicit KDE constructor 1 2 3 4 5 6 7 8 9 10 using Distributions , UncertainData # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the implicit KDE constructor to create the uncertain value uv = UncertainValue ( v :: Vector ) Explicit KDE constructor 1 2 3 4 5 6 7 8 9 10 11 12 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value. # This constructor follows the same convention as when fitting distributions # to empirical data, so this is the recommended way to construct KDE estimates. uv = UncertainValue ( UnivariateKDE , v :: Vector ) Changing the kernel 1 2 3 4 5 6 7 8 9 10 11 12 13 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value, specifying # that we want to use normal distributions as the kernel. The kernel can be # any valid kernel from Distributions.jl, and the default is to use normal # distributions. uv = UncertainValue ( UnivariateKDE , v :: Vector ; kernel = Normal ) Adjusting number of points 1 2 3 4 5 6 7 8 9 10 11 12 13 using Distributions , UncertainData , KernelDensity # Create a normal distribution d = Normal () # Draw a 1000-point sample from the distribution. some_sample = rand ( d , 1000 ) # Use the explicit KDE constructor to create the uncertain value, specifying # the number of points we want to use for the kernel density estimate. Fast # Fourier transforms are used behind the scenes, so the number of points # should be a power of 2 (the default is 2048 points). uv = UncertainValue ( UnivariateKDE , v :: Vector ; npoints = 1024 )","title":"Additional keyword arguments and examples"},{"location":"uncertainvalues_overview/","text":"Uncertain value representations Uncertain values may be constructed in three different ways, depending on what information you have available. Kernel density estimates to the observed data If the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution. The UncertainValue(empiricaldata::Vector) constructor returns an uncertain value represented by a kernel density estimate to the empirical distribution. Kernel density estimate of empirical distribution 1 2 3 4 5 6 7 8 9 10 11 12 using Distributions , UncertainData # Generate some random data from a normal distribution, so that we get a # histogram resembling a normal distribution. some_sample = rand ( Normal (), 1000 ) # Uncertain value represented by a kernel density estimate uv = UncertainValue ( some_sample ) # The following is equivalent using KernelDensity # needed to get access to the UnivarateKDE type uv = UncertainValue ( UnivariateKDE , some_sample ) Theoretical distributions with fitted parameters If your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data. The UncertainValue(d::Type{D}, empiricaldata::Vector) where {D <: Distribution} constructor fits a distribution of type d to empiricaldata . Example 1: fitting a normal distribution 1 2 3 4 5 6 7 8 9 using Distributions , UncertainData # Generate some random data from a normal distribution, so that we get a # histogram resembling a normal distribution. some_sample = rand ( Normal (), 1000 ) # Uncertain value represented by a theoretical normal distribution with # parameters fitted to the data. uv = UncertainValue ( Normal , some_sample ) Example 2: fitting a gamma distribution 1 2 3 4 5 6 7 8 9 using Distributions , UncertainData # Generate some random data from a gamma distribution, so that we get a # histogram resembling a gamma distribution. some_sample = rand ( Gamma (), 1000 ) # Uncertain value represented by a theoretical gamma distribution with # parameters fitted to the data. uv = UncertainValue ( Gamma , some_sample ) Theoretical distributions with known parameters It is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean \u03bc = 0 and standard deviation \u03c3 = 0.3 . 1 2 3 # Uncertain value represented by a theoretical normal distribution with # known parameters \u03bc = 0 and \u03c3 = 0.3 uv = UncertainValue ( Normal , 0 , 0.3 ) Generic two-parameter constructor The generic two-parameter constructor returns an uncertain value represented by a distribution of type d with parameters a and b (which, of course, have different meanings depending on which distribution is provided). Valid distributions are Normal , Uniform , Beta , BetaPrime , Gamma , Frechet and Binomial . 1 UncertainValue ( d :: Type { D }, a <: Number , b <: Number ) For example, Example 1 1 2 3 # Uncertain value represented by a theoretical gamma distribution with # known parameters \u03b1 = 2.1 and \u03b8 = 3.1 uv = UncertainValue ( Gamma , 2.1 , 3.1 ) Example 2 1 2 3 # Uncertain value represented by a theoretical binomial distribution with # known parameters p = 32 and p = 0.13 uv = UncertainValue ( Binomial , 32 , 0.13 ) Combined with a valid two-parameter distribution, the a and b parameter syntax translates into: UncertainValue(Normal, \u03bc, \u03c3) UncertainValue(Uniform, lower, upper) UncertainValue(Beta, \u03b1, \u03b2) UncertainValue(BetaPrime, \u03b1, \u03b2) UncertainValue(Gamma, \u03b1, \u03b8) UncertainValue(Frechet, \u03b1, \u03b8) UncertainValue(Binomial, n, p) Generic three-parameter constructor The three-parameter constructor works similarly for three-parameter distributions: 1 UncertainValue(d::Type{D}, a<:Number, b<:Number, c<:Number) Combined with a valid two-parameter distribution, the a , b and c parameter syntax translates into: UncertainValue(BetaBinomial, n, \u03b1, \u03b2)","title":"Overview"},{"location":"uncertainvalues_overview/#uncertain-value-representations","text":"Uncertain values may be constructed in three different ways, depending on what information you have available.","title":"Uncertain value representations"},{"location":"uncertainvalues_overview/#kernel-density-estimates-to-the-observed-data","text":"If the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution. The UncertainValue(empiricaldata::Vector) constructor returns an uncertain value represented by a kernel density estimate to the empirical distribution. Kernel density estimate of empirical distribution 1 2 3 4 5 6 7 8 9 10 11 12 using Distributions , UncertainData # Generate some random data from a normal distribution, so that we get a # histogram resembling a normal distribution. some_sample = rand ( Normal (), 1000 ) # Uncertain value represented by a kernel density estimate uv = UncertainValue ( some_sample ) # The following is equivalent using KernelDensity # needed to get access to the UnivarateKDE type uv = UncertainValue ( UnivariateKDE , some_sample )","title":"Kernel density estimates to the observed data"},{"location":"uncertainvalues_overview/#theoretical-distributions-with-fitted-parameters","text":"If your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data. The UncertainValue(d::Type{D}, empiricaldata::Vector) where {D <: Distribution} constructor fits a distribution of type d to empiricaldata . Example 1: fitting a normal distribution 1 2 3 4 5 6 7 8 9 using Distributions , UncertainData # Generate some random data from a normal distribution, so that we get a # histogram resembling a normal distribution. some_sample = rand ( Normal (), 1000 ) # Uncertain value represented by a theoretical normal distribution with # parameters fitted to the data. uv = UncertainValue ( Normal , some_sample ) Example 2: fitting a gamma distribution 1 2 3 4 5 6 7 8 9 using Distributions , UncertainData # Generate some random data from a gamma distribution, so that we get a # histogram resembling a gamma distribution. some_sample = rand ( Gamma (), 1000 ) # Uncertain value represented by a theoretical gamma distribution with # parameters fitted to the data. uv = UncertainValue ( Gamma , some_sample )","title":"Theoretical distributions with fitted parameters"},{"location":"uncertainvalues_overview/#theoretical-distributions-with-known-parameters","text":"It is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean \u03bc = 0 and standard deviation \u03c3 = 0.3 . 1 2 3 # Uncertain value represented by a theoretical normal distribution with # known parameters \u03bc = 0 and \u03c3 = 0.3 uv = UncertainValue ( Normal , 0 , 0.3 )","title":"Theoretical distributions with known parameters"},{"location":"uncertainvalues_overview/#generic-two-parameter-constructor","text":"The generic two-parameter constructor returns an uncertain value represented by a distribution of type d with parameters a and b (which, of course, have different meanings depending on which distribution is provided). Valid distributions are Normal , Uniform , Beta , BetaPrime , Gamma , Frechet and Binomial . 1 UncertainValue ( d :: Type { D }, a <: Number , b <: Number ) For example, Example 1 1 2 3 # Uncertain value represented by a theoretical gamma distribution with # known parameters \u03b1 = 2.1 and \u03b8 = 3.1 uv = UncertainValue ( Gamma , 2.1 , 3.1 ) Example 2 1 2 3 # Uncertain value represented by a theoretical binomial distribution with # known parameters p = 32 and p = 0.13 uv = UncertainValue ( Binomial , 32 , 0.13 ) Combined with a valid two-parameter distribution, the a and b parameter syntax translates into: UncertainValue(Normal, \u03bc, \u03c3) UncertainValue(Uniform, lower, upper) UncertainValue(Beta, \u03b1, \u03b2) UncertainValue(BetaPrime, \u03b1, \u03b2) UncertainValue(Gamma, \u03b1, \u03b8) UncertainValue(Frechet, \u03b1, \u03b8) UncertainValue(Binomial, n, p)","title":"Generic two-parameter constructor"},{"location":"uncertainvalues_overview/#generic-three-parameter-constructor","text":"The three-parameter constructor works similarly for three-parameter distributions: 1 UncertainValue(d::Type{D}, a<:Number, b<:Number, c<:Number) Combined with a valid two-parameter distribution, the a , b and c parameter syntax translates into: UncertainValue(BetaBinomial, n, \u03b1, \u03b2)","title":"Generic three-parameter constructor"},{"location":"uncertainvalues_theoreticaldistributions/","text":"Uncertain values from theoretical distributions It is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. Perhaps the authors report the mean and standard deviation of a value stated to follow a normal distribution. UncertainData makes it easy to represent such values! Supported distributions Uncertain values may be constructed from theoretical distribution using any of the following distributions (more distributions will be added in the future!). Uniform 1 2 # Uncertain value generated by a uniform distribution on [-5.0, 5.1]. uv = UncertainValue ( Uniform , - 5.0 , 5.1 ) Normal 1 2 3 # Uncertain value generated by a normal distribution with parameters \u03bc = -2 and # \u03c3 = 0.5. uv = UncertainValue ( Normal , - 2 , 0.5 ) Gamma 1 2 3 # Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2 # and \u03b8 = 3. uv = UncertainValue ( Gamma , 2.2 , 3 ) Beta 1 2 3 # Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5 # and \u03b2 = 3.5 uv = UncertainValue ( Beta , 1.5 , 3.5 ) BetaPrime 1 2 3 # Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7 # and \u03b2 = 3.2 uv = UncertainValue ( Beta , 1.7 , 3.2 ) Fr\u00e9chet 1 2 3 # Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1 # and \u03b8 = 4 uv = UncertainValue ( Beta , 2.1 , 4 ) Binomial 1 2 3 # Uncertain value generated by binomial distribution with n = 28 trials and # probability p = 0.2 of success in individual trials. uv = UncertainValue ( Binomial , 28 , 0.2 ) BetaBinomial 1 2 3 # Creates an uncertain value generated by a beta-binomial distribution with # n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5. uv = UncertainValue ( BetaBinomial , 28 , 3.3 , 4.4 ) Constructors In this package, there are two constructors that creates uncertain values represented by theoretical distributions. The order the parameters are provided to the constructor is the same as for constructing the equivalent distributions in Distributions.jl . Two-parameter distributions 1 2 UncertainValue ( d :: Type { D }, a <: Number , b <: Number ) where { D <: Distributions . Distribution } Creates an uncertain value consisting of a two-parameter distribution of type d with parameters a and b . Precisely what a and b are depends on which distribution is provided. UncertainValue(Normal, \u03bc, \u03c3) creates an UncertainScalarNormallyDistributed instance. UncertainValue(Uniform, lower, upper) creates an UncertainScalarUniformlyDistributed instance. UncertainValue(Beta, \u03b1, \u03b2) creates an UncertainScalarBetaDistributed instance. UncertainValue(BetaPrime, \u03b1, \u03b2) creates an UncertainScalarBetaPrimeDistributed instance. UncertainValue(Gamma, \u03b1, \u03b8) creates an UncertainScalarGammaDistributed instance. UncertainValue(Frechet, \u03b1, \u03b8) creates an UncertainScalarFrechetDistributed instance. UncertainValue(Binomial, n, p) creates an UncertainScalarBinomialDistributed instance. Three-parameter distributions 1 2 UncertainValue ( d :: Type { D }, a <: Number , b <: Number , c <: Number ) where { D <: Distributions . Distribution } Creates an uncertain value consisting of a three-parameter distribution of type d with parameters a , b and c . Precisely what a , b and c are depends on which distribution is provided. UncertainValue(BetaBinomial, n, \u03b1, \u03b2) creates an UncertainScalarBetaBinomialDistributed instance.","title":"Theoretical distributions"},{"location":"uncertainvalues_theoreticaldistributions/#uncertain-values-from-theoretical-distributions","text":"It is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. Perhaps the authors report the mean and standard deviation of a value stated to follow a normal distribution. UncertainData makes it easy to represent such values!","title":"Uncertain values from theoretical distributions"},{"location":"uncertainvalues_theoreticaldistributions/#supported-distributions","text":"Uncertain values may be constructed from theoretical distribution using any of the following distributions (more distributions will be added in the future!). Uniform 1 2 # Uncertain value generated by a uniform distribution on [-5.0, 5.1]. uv = UncertainValue ( Uniform , - 5.0 , 5.1 ) Normal 1 2 3 # Uncertain value generated by a normal distribution with parameters \u03bc = -2 and # \u03c3 = 0.5. uv = UncertainValue ( Normal , - 2 , 0.5 ) Gamma 1 2 3 # Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2 # and \u03b8 = 3. uv = UncertainValue ( Gamma , 2.2 , 3 ) Beta 1 2 3 # Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5 # and \u03b2 = 3.5 uv = UncertainValue ( Beta , 1.5 , 3.5 ) BetaPrime 1 2 3 # Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7 # and \u03b2 = 3.2 uv = UncertainValue ( Beta , 1.7 , 3.2 ) Fr\u00e9chet 1 2 3 # Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1 # and \u03b8 = 4 uv = UncertainValue ( Beta , 2.1 , 4 ) Binomial 1 2 3 # Uncertain value generated by binomial distribution with n = 28 trials and # probability p = 0.2 of success in individual trials. uv = UncertainValue ( Binomial , 28 , 0.2 ) BetaBinomial 1 2 3 # Creates an uncertain value generated by a beta-binomial distribution with # n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5. uv = UncertainValue ( BetaBinomial , 28 , 3.3 , 4.4 )","title":"Supported distributions"},{"location":"uncertainvalues_theoreticaldistributions/#constructors","text":"In this package, there are two constructors that creates uncertain values represented by theoretical distributions. The order the parameters are provided to the constructor is the same as for constructing the equivalent distributions in Distributions.jl .","title":"Constructors"},{"location":"uncertainvalues_theoreticaldistributions/#two-parameter-distributions","text":"1 2 UncertainValue ( d :: Type { D }, a <: Number , b <: Number ) where { D <: Distributions . Distribution } Creates an uncertain value consisting of a two-parameter distribution of type d with parameters a and b . Precisely what a and b are depends on which distribution is provided. UncertainValue(Normal, \u03bc, \u03c3) creates an UncertainScalarNormallyDistributed instance. UncertainValue(Uniform, lower, upper) creates an UncertainScalarUniformlyDistributed instance. UncertainValue(Beta, \u03b1, \u03b2) creates an UncertainScalarBetaDistributed instance. UncertainValue(BetaPrime, \u03b1, \u03b2) creates an UncertainScalarBetaPrimeDistributed instance. UncertainValue(Gamma, \u03b1, \u03b8) creates an UncertainScalarGammaDistributed instance. UncertainValue(Frechet, \u03b1, \u03b8) creates an UncertainScalarFrechetDistributed instance. UncertainValue(Binomial, n, p) creates an UncertainScalarBinomialDistributed instance.","title":"Two-parameter distributions"},{"location":"uncertainvalues_theoreticaldistributions/#three-parameter-distributions","text":"1 2 UncertainValue ( d :: Type { D }, a <: Number , b <: Number , c <: Number ) where { D <: Distributions . Distribution } Creates an uncertain value consisting of a three-parameter distribution of type d with parameters a , b and c . Precisely what a , b and c are depends on which distribution is provided. UncertainValue(BetaBinomial, n, \u03b1, \u03b2) creates an UncertainScalarBetaBinomialDistributed instance.","title":"Three-parameter distributions"},{"location":"hypothesistests/anderson_darling_test/","text":"One-sample Anderson-Darling test # HypothesisTests.OneSampleADTest \u2014 Type . 1 OneSampleADTest(uv::UncertainValue, d::UnivariateDistribution) -> OneSampleADTest Perform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of n realisations of the uncertain value uv comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source","title":"Anderson darling test"},{"location":"hypothesistests/anderson_darling_test/#one-sample-anderson-darling-test","text":"# HypothesisTests.OneSampleADTest \u2014 Type . 1 OneSampleADTest(uv::UncertainValue, d::UnivariateDistribution) -> OneSampleADTest Perform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of n realisations of the uncertain value uv comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source","title":"One-sample Anderson-Darling test"},{"location":"hypothesistests/approximate_twosample_kolmogorov_smirnov_test/","text":"Pooled approximate two-sample Kolmogorov-Smirnov test # UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled \u2014 Function . 1 2 ApproximateTwoSampleKSTestPooled(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> ApproximateTwoSampleKSTest First, draw n realisations of each uncertain value in d1 , then separately draw n realisations of each uncertain value in d2 . Then, pool all realisations for d1 together and all realisations of d2 together. On the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the d1 value pool represents the same distribution as the distribution furnishing the d2 value pool, against the alternative hypothesis that the furnishing distributions are different. source Element-wise approximate two-sample Kolmogorov-Smirnov test # UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise \u2014 Function . 1 2 ApproximateTwoSampleKSTestElementWise(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> Vector{ApproximateTwoSampleKSTest} Assuming d1 and d2 contain the same number of uncertain observations, draw n realisations of each uncertain value in d1 , then separately and separately draw n realisations of each uncertain value in d2 . Then, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in d1 and d2 come from the same distribution against the alternative hypothesis that the (element-wise) values in d1 and d2 come from different distributions. The test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with n draws for the i i -ith pair of uncertain values. source","title":"Approximate two-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#pooled-approximate-two-sample-kolmogorov-smirnov-test","text":"# UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled \u2014 Function . 1 2 ApproximateTwoSampleKSTestPooled(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> ApproximateTwoSampleKSTest First, draw n realisations of each uncertain value in d1 , then separately draw n realisations of each uncertain value in d2 . Then, pool all realisations for d1 together and all realisations of d2 together. On the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the d1 value pool represents the same distribution as the distribution furnishing the d2 value pool, against the alternative hypothesis that the furnishing distributions are different. source","title":"Pooled approximate two-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#element-wise-approximate-two-sample-kolmogorov-smirnov-test","text":"# UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise \u2014 Function . 1 2 ApproximateTwoSampleKSTestElementWise(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> Vector{ApproximateTwoSampleKSTest} Assuming d1 and d2 contain the same number of uncertain observations, draw n realisations of each uncertain value in d1 , then separately and separately draw n realisations of each uncertain value in d2 . Then, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in d1 and d2 come from the same distribution against the alternative hypothesis that the (element-wise) values in d1 and d2 come from different distributions. The test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with n draws for the i i -ith pair of uncertain values. source","title":"Element-wise approximate two-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/equal_variance_t_test/","text":"Equal variance t-test # HypothesisTests.EqualVarianceTTest \u2014 Type . 1 2 EqualVarianceTTest ( d1 :: AbstractUncertainValue , d2 :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > EqualVarianceTTest Consider two samples s1 and s2 , each consisting of n random draws from the distributions furnishing d1 and d2 , respectively. This function performs a two-sample t-test of the null hypothesis that s1 and s2 come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source Example Let's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances. We expect the test to reject this null-hypothesis, because we've created two very different distributions. 1 2 3 4 5 uv1 = UncertainValue ( Normal , 1.2 , 0.3 ) uv2 = UncertainValue ( Gamma , 2 , 3 ) # EqualVarianceTTest on 1000 draws for each variable EqualVarianceTTest ( uv1 , uv2 , 1000 ) The output is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Two sample t - test ( equal variance ) ---------------------------------- Population details : parameter of interest : Mean difference value under h_0 : 0 point estimate : - 4.782470406651697 95 % confidence interval : ( - 5.0428 , - 4.5222 ) Test summary : outcome with 95 % confidence : reject h_0 two - sided p - value : < 1e-99 Details : number of observations : [ 1000 , 1000 ] t - statistic : - 36.03293014520585 degrees of freedom : 1998 empirical standard error : 0.1327249931487462 The test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances. Pooled equal variance t-test # UncertainData.UncertainStatistics.EqualVarianceTTestPooled \u2014 Function . 1 2 EqualVarianceTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > EqualVarianceTTest Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. Gather all s1[i] in a pooled sample S1 , and all s2[i] in a pooled sample S2 . Perform a two-sample t-test of the null hypothesis that S1 and S2 come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source Element-wise equal variance t-test # UncertainData.UncertainStatistics.EqualVarianceTTestElementWise \u2014 Function . 1 2 EqualVarianceTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { EqualVarianceTTest } Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. This function performs an elementwise EqualVarianceTTest on the pairs (s1[i], s2[i]) . Specifically: Performs an pairwise two-sample t-test of the null hypothesis that s1[i] and s2[i] come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source","title":"Equal variance t-test"},{"location":"hypothesistests/equal_variance_t_test/#equal-variance-t-test","text":"# HypothesisTests.EqualVarianceTTest \u2014 Type . 1 2 EqualVarianceTTest ( d1 :: AbstractUncertainValue , d2 :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > EqualVarianceTTest Consider two samples s1 and s2 , each consisting of n random draws from the distributions furnishing d1 and d2 , respectively. This function performs a two-sample t-test of the null hypothesis that s1 and s2 come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source Example Let's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances. We expect the test to reject this null-hypothesis, because we've created two very different distributions. 1 2 3 4 5 uv1 = UncertainValue ( Normal , 1.2 , 0.3 ) uv2 = UncertainValue ( Gamma , 2 , 3 ) # EqualVarianceTTest on 1000 draws for each variable EqualVarianceTTest ( uv1 , uv2 , 1000 ) The output is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Two sample t - test ( equal variance ) ---------------------------------- Population details : parameter of interest : Mean difference value under h_0 : 0 point estimate : - 4.782470406651697 95 % confidence interval : ( - 5.0428 , - 4.5222 ) Test summary : outcome with 95 % confidence : reject h_0 two - sided p - value : < 1e-99 Details : number of observations : [ 1000 , 1000 ] t - statistic : - 36.03293014520585 degrees of freedom : 1998 empirical standard error : 0.1327249931487462 The test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.","title":"Equal variance t-test"},{"location":"hypothesistests/equal_variance_t_test/#pooled-equal-variance-t-test","text":"# UncertainData.UncertainStatistics.EqualVarianceTTestPooled \u2014 Function . 1 2 EqualVarianceTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > EqualVarianceTTest Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. Gather all s1[i] in a pooled sample S1 , and all s2[i] in a pooled sample S2 . Perform a two-sample t-test of the null hypothesis that S1 and S2 come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source","title":"Pooled equal variance t-test"},{"location":"hypothesistests/equal_variance_t_test/#element-wise-equal-variance-t-test","text":"# UncertainData.UncertainStatistics.EqualVarianceTTestElementWise \u2014 Function . 1 2 EqualVarianceTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { EqualVarianceTTest } Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. This function performs an elementwise EqualVarianceTTest on the pairs (s1[i], s2[i]) . Specifically: Performs an pairwise two-sample t-test of the null hypothesis that s1[i] and s2[i] come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances. source","title":"Element-wise equal variance t-test"},{"location":"hypothesistests/exact_kolmogorov_smirnov_test/","text":"Exact one-sample Kolmogorov-Smirnov test # HypothesisTests.ExactOneSampleKSTest \u2014 Type . 1 2 ExactOneSampleKSTest(uv::AbstractUncertainValue, d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest Perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of n realisations of the uncertain value uv comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source Example We'll test whether the uncertain value uv = UncertainValue(Gamma, 2, 4) comes from the theoretical distribution Gamma(2, 4) . Of course, we expect the test to confirm this, because we're using the exact same distribution. 1 2 3 4 5 uv = UncertainValue ( Gamma , 2 , 4 ) # Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the # uncertain value. ExactOneSampleKSTest ( uv , Gamma ( 2 , 4 ), 1000 ) That gives the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 Exact one sample Kolmogorov - Smirnov test ---------------------------------------- Population details : parameter of interest : Supremum of CDF differences value under h_0 : 0.0 point estimate : 0.0228345021301449 Test summary : outcome with 95 % confidence : fail to reject h_0 two - sided p - value : 0.6655 Details : number of observations : 1000 As expected, the test can't reject the hypothesis that the uncertain value uv comes from the theoretical distribution Gamma(2, 4) , precisely because it does. Pooled exact one-sample Kolmogorov-Smirnov test # UncertainData.UncertainStatistics.ExactOneSampleKSTestPooled \u2014 Function . 1 2 ExactOneSampleKSTestPooled(ud::UncertainDataset, d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest First, draw n realisations of each uncertain value in ud and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source Element-wise exact one-sample Kolmogorov-Smirnov test # UncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise \u2014 Function . 1 2 ExactOneSampleKSTestElementWise(ud::UncertainDataset, d::UnivariateDistribution, n::Int = 1000) -> Vector{ExactOneSampleKSTest} First, draw n realisations of each uncertain value in ud , keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source","title":"Exact Kolmogorov-Smirnov test"},{"location":"hypothesistests/exact_kolmogorov_smirnov_test/#exact-one-sample-kolmogorov-smirnov-test","text":"# HypothesisTests.ExactOneSampleKSTest \u2014 Type . 1 2 ExactOneSampleKSTest(uv::AbstractUncertainValue, d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest Perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of n realisations of the uncertain value uv comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source Example We'll test whether the uncertain value uv = UncertainValue(Gamma, 2, 4) comes from the theoretical distribution Gamma(2, 4) . Of course, we expect the test to confirm this, because we're using the exact same distribution. 1 2 3 4 5 uv = UncertainValue ( Gamma , 2 , 4 ) # Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the # uncertain value. ExactOneSampleKSTest ( uv , Gamma ( 2 , 4 ), 1000 ) That gives the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 Exact one sample Kolmogorov - Smirnov test ---------------------------------------- Population details : parameter of interest : Supremum of CDF differences value under h_0 : 0.0 point estimate : 0.0228345021301449 Test summary : outcome with 95 % confidence : fail to reject h_0 two - sided p - value : 0.6655 Details : number of observations : 1000 As expected, the test can't reject the hypothesis that the uncertain value uv comes from the theoretical distribution Gamma(2, 4) , precisely because it does.","title":"Exact one-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/exact_kolmogorov_smirnov_test/#pooled-exact-one-sample-kolmogorov-smirnov-test","text":"# UncertainData.UncertainStatistics.ExactOneSampleKSTestPooled \u2014 Function . 1 2 ExactOneSampleKSTestPooled(ud::UncertainDataset, d::UnivariateDistribution, n::Int = 1000) -> ExactOneSampleKSTest First, draw n realisations of each uncertain value in ud and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source","title":"Pooled exact one-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/exact_kolmogorov_smirnov_test/#element-wise-exact-one-sample-kolmogorov-smirnov-test","text":"# UncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise \u2014 Function . 1 2 ExactOneSampleKSTestElementWise(ud::UncertainDataset, d::UnivariateDistribution, n::Int = 1000) -> Vector{ExactOneSampleKSTest} First, draw n realisations of each uncertain value in ud , keeping one pool of values for each uncertain value. Then, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution d against the alternative hypothesis that the sample is not drawn from d . source","title":"Element-wise exact one-sample Kolmogorov-Smirnov test"},{"location":"hypothesistests/hypothesis_tests_overview/","text":"Hypothesis tests In addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from HypothesisTests.jl . This allows us to perform hypothesis testing on ensemble realisations of the data. Implemented hypothesis tests The following hypothesis tests are implemented for uncertain data types. One sample t-test . Equal variance t-test . Unequal variance t-test . Exact Kolmogorov-Smirnov test . Approximate two-sample Kolmogorov-Smirnov test . One-sample Anderson\u2013Darling test . Jarque-Bera test . Terminology Pooled statistics are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic. Element-wise statistics are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.","title":"Overview"},{"location":"hypothesistests/hypothesis_tests_overview/#hypothesis-tests","text":"In addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from HypothesisTests.jl . This allows us to perform hypothesis testing on ensemble realisations of the data.","title":"Hypothesis tests"},{"location":"hypothesistests/hypothesis_tests_overview/#implemented-hypothesis-tests","text":"The following hypothesis tests are implemented for uncertain data types. One sample t-test . Equal variance t-test . Unequal variance t-test . Exact Kolmogorov-Smirnov test . Approximate two-sample Kolmogorov-Smirnov test . One-sample Anderson\u2013Darling test . Jarque-Bera test .","title":"Implemented hypothesis tests"},{"location":"hypothesistests/hypothesis_tests_overview/#terminology","text":"Pooled statistics are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic. Element-wise statistics are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.","title":"Terminology"},{"location":"hypothesistests/jarque_bera_test/","text":"Jarque-Bera test # HypothesisTests.JarqueBeraTest \u2014 Type . 1 JarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -> JarqueBeraTest Compute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed. source Pooled Jarque-Bera test # UncertainData.UncertainStatistics.JarqueBeraTestPooled \u2014 Function . 1 JarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -> JarqueBeraTest First, draw n realisations of each uncertain value in ud and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed. source Element-wise Jarque-Bera test # UncertainData.UncertainStatistics.JarqueBeraTestElementWise \u2014 Function . 1 2 OneSampleADTestElementWise(ud::UncertainDataset, n::Int = 1000) -> Vector{JarqueBeraTest} First, draw n realisations of each uncertain value in ud , keeping one pool of values for each uncertain value. Then, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed. source","title":"Jarque-Bera test"},{"location":"hypothesistests/jarque_bera_test/#jarque-bera-test","text":"# HypothesisTests.JarqueBeraTest \u2014 Type . 1 JarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -> JarqueBeraTest Compute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed. source","title":"Jarque-Bera test"},{"location":"hypothesistests/jarque_bera_test/#pooled-jarque-bera-test","text":"# UncertainData.UncertainStatistics.JarqueBeraTestPooled \u2014 Function . 1 JarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -> JarqueBeraTest First, draw n realisations of each uncertain value in ud and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed. source","title":"Pooled Jarque-Bera test"},{"location":"hypothesistests/jarque_bera_test/#element-wise-jarque-bera-test","text":"# UncertainData.UncertainStatistics.JarqueBeraTestElementWise \u2014 Function . 1 2 OneSampleADTestElementWise(ud::UncertainDataset, n::Int = 1000) -> Vector{JarqueBeraTest} First, draw n realisations of each uncertain value in ud , keeping one pool of values for each uncertain value. Then, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed. source","title":"Element-wise Jarque-Bera test"},{"location":"hypothesistests/mann_whitney_u_test/","text":"Mann-Whitney u-test # HypothesisTests.MannWhitneyUTest \u2014 Function . 1 2 MannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue, n::Int = 1000) -> MannWhitneyUTest Let s1 and s2 be samples of n realisations from the distributions furnishing the uncertain values d1 and d2 . Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as s1 is greater than an observation drawn from the same population as s2 is equal to the probability that an observation drawn from the same population as s2 is greater than an observation drawn from the same population as s1 against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source Pooled Mann-Whitney u-test # UncertainData.UncertainStatistics.MannWhitneyUTestPooled \u2014 Function . 1 2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> MannWhitneyUTest Let s_{1_{i}} s_{1_{i}} be a sample of n realisations of the distribution furnishing the uncertain value d1[i] , where i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N] and N N is the number of uncertain values in d1 . Next, gather the samples for all s_{1_{i}} s_{1_{i}} in a pooled sample S_1 S_1 . Do the same for the second uncertain dataset d2 , yielding the pooled sample S_2 S_2 . Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as S_1 S_1 is greater than an observation drawn from the same population as S_2 S_2 is equal to the probability that an observation drawn from the same population as S_2 S_2 is greater than an observation drawn from the same population as S_1 S_1 against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source Element-wise Mann-Whitney u-test # UncertainData.UncertainStatistics.MannWhitneyUTestElementWise \u2014 Function . 1 2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> Vector{MannWhitneyUTest} Assume d1 and d2 consist of the same number of uncertain values. Let s_{1_{i}} s_{1_{i}} be a sample of n realisations of the distribution furnishing the uncertain value d1[i] , where i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N] and N N is the number of uncertain values in d1 . Let s_{2_{i}} s_{2_{i}} be the corresponding sample for d2[i] . This function Perform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as s_{1_{i}} s_{1_{i}} is greater than an observation drawn from the same population as s_{2_{i}} s_{2_{i}} is equal to the probability that an observation drawn from the same population as s_{2_{i}} s_{2_{i}} is greater than an observation drawn from the same population as s_{1_{i}} s_{1_{i}} against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source","title":"Mann-Whitney u-test"},{"location":"hypothesistests/mann_whitney_u_test/#mann-whitney-u-test","text":"# HypothesisTests.MannWhitneyUTest \u2014 Function . 1 2 MannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue, n::Int = 1000) -> MannWhitneyUTest Let s1 and s2 be samples of n realisations from the distributions furnishing the uncertain values d1 and d2 . Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as s1 is greater than an observation drawn from the same population as s2 is equal to the probability that an observation drawn from the same population as s2 is greater than an observation drawn from the same population as s1 against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source","title":"Mann-Whitney u-test"},{"location":"hypothesistests/mann_whitney_u_test/#pooled-mann-whitney-u-test","text":"# UncertainData.UncertainStatistics.MannWhitneyUTestPooled \u2014 Function . 1 2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> MannWhitneyUTest Let s_{1_{i}} s_{1_{i}} be a sample of n realisations of the distribution furnishing the uncertain value d1[i] , where i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N] and N N is the number of uncertain values in d1 . Next, gather the samples for all s_{1_{i}} s_{1_{i}} in a pooled sample S_1 S_1 . Do the same for the second uncertain dataset d2 , yielding the pooled sample S_2 S_2 . Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as S_1 S_1 is greater than an observation drawn from the same population as S_2 S_2 is equal to the probability that an observation drawn from the same population as S_2 S_2 is greater than an observation drawn from the same population as S_1 S_1 against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source","title":"Pooled Mann-Whitney u-test"},{"location":"hypothesistests/mann_whitney_u_test/#element-wise-mann-whitney-u-test","text":"# UncertainData.UncertainStatistics.MannWhitneyUTestElementWise \u2014 Function . 1 2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) -> Vector{MannWhitneyUTest} Assume d1 and d2 consist of the same number of uncertain values. Let s_{1_{i}} s_{1_{i}} be a sample of n realisations of the distribution furnishing the uncertain value d1[i] , where i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N] and N N is the number of uncertain values in d1 . Let s_{2_{i}} s_{2_{i}} be the corresponding sample for d2[i] . This function Perform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as s_{1_{i}} s_{1_{i}} is greater than an observation drawn from the same population as s_{2_{i}} s_{2_{i}} is equal to the probability that an observation drawn from the same population as s_{2_{i}} s_{2_{i}} is greater than an observation drawn from the same population as s_{1_{i}} s_{1_{i}} against the alternative hypothesis that these probabilities are not equal. The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, MannWhitneyUTest performs an exact Mann-Whitney U test. In all other cases, MannWhitneyUTest performs an approximate Mann-Whitney U test. source","title":"Element-wise Mann-Whitney u-test"},{"location":"hypothesistests/one_sample_t_test/","text":"One-sample t-test # HypothesisTests.OneSampleTTest \u2014 Type . 1 2 OneSampleTTest ( d :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > OneSampleTTest Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \u03bc0 against the alternative hypothesis that its distribution does not have mean \u03bc0 . n indicates the number of draws during resampling. source Example: 1 2 3 4 5 6 # Normally distributed uncertain observation with mean = 2.1 uv = UncertainValue ( Normal , 2.1 , 0.2 ) # Perform a one-sample t-test to test the null hypothesis that # the sample comes from a distribution with mean \u03bc0 OneSampleTTest ( uv , 1000 , \u03bc0 = 2.1 ) Which gives the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Which results in One sample t - test ----------------- Population details : parameter of interest : Mean value under h_0 : 2.1 point estimate : 2.1031909275381566 95 % confidence interval : ( 2.091 , 2.1154 ) Test summary : outcome with 95 % confidence : fail to reject h_0 two - sided p - value : 0.6089 Details : number of observations : 1000 t - statistic : 0.5117722099885472 degrees of freedom : 999 empirical standard error : 0.00623505433839 Thus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample does in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1. Pooled one-sample t-test # UncertainData.UncertainStatistics.OneSampleTTestPooled \u2014 Function . 1 2 3 OneSampleTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > OneSampleTTest First, sample n draws of each uncertain value in each dataset, pooling the draws from the elements of d1 and the draws from the elements of d2 separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in d1 and d2 come from a distribution with mean \u03bc0 against the alternative hypothesis that the distribution does not have mean \u03bc0 . source Element-wise one-sample t-test # UncertainData.UncertainStatistics.OneSampleTTestElementWise \u2014 Function . 1 2 3 OneSampleTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { OneSampleTTest } Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \u03bc0 against the alternative hypothesis that its distribution does not have mean \u03bc0 for uncertain value in d . n indicates the number of draws during resampling. source","title":"One sample t-test"},{"location":"hypothesistests/one_sample_t_test/#one-sample-t-test","text":"# HypothesisTests.OneSampleTTest \u2014 Type . 1 2 OneSampleTTest ( d :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > OneSampleTTest Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \u03bc0 against the alternative hypothesis that its distribution does not have mean \u03bc0 . n indicates the number of draws during resampling. source Example: 1 2 3 4 5 6 # Normally distributed uncertain observation with mean = 2.1 uv = UncertainValue ( Normal , 2.1 , 0.2 ) # Perform a one-sample t-test to test the null hypothesis that # the sample comes from a distribution with mean \u03bc0 OneSampleTTest ( uv , 1000 , \u03bc0 = 2.1 ) Which gives the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Which results in One sample t - test ----------------- Population details : parameter of interest : Mean value under h_0 : 2.1 point estimate : 2.1031909275381566 95 % confidence interval : ( 2.091 , 2.1154 ) Test summary : outcome with 95 % confidence : fail to reject h_0 two - sided p - value : 0.6089 Details : number of observations : 1000 t - statistic : 0.5117722099885472 degrees of freedom : 999 empirical standard error : 0.00623505433839 Thus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample does in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.","title":"One-sample t-test"},{"location":"hypothesistests/one_sample_t_test/#pooled-one-sample-t-test","text":"# UncertainData.UncertainStatistics.OneSampleTTestPooled \u2014 Function . 1 2 3 OneSampleTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > OneSampleTTest First, sample n draws of each uncertain value in each dataset, pooling the draws from the elements of d1 and the draws from the elements of d2 separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in d1 and d2 come from a distribution with mean \u03bc0 against the alternative hypothesis that the distribution does not have mean \u03bc0 . source","title":"Pooled one-sample t-test"},{"location":"hypothesistests/one_sample_t_test/#element-wise-one-sample-t-test","text":"# UncertainData.UncertainStatistics.OneSampleTTestElementWise \u2014 Function . 1 2 3 OneSampleTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { OneSampleTTest } Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \u03bc0 against the alternative hypothesis that its distribution does not have mean \u03bc0 for uncertain value in d . n indicates the number of draws during resampling. source","title":"Element-wise one-sample t-test"},{"location":"hypothesistests/unequal_variance_t_test/","text":"Unequal variance t-test # HypothesisTests.UnequalVarianceTTest \u2014 Type . 1 2 UnequalVarianceTTest ( d1 :: AbstractUncertainValue , d2 :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > UnequalVarianceTTest Consider two samples s1 and s2 , each consisting of n random draws from the distributions furnishing d1 and d2 , respectively. Perform an unequal variance two-sample t-test of the null hypothesis that s1 and s2 come from distributions with equal means against the alternative hypothesis that the distributions have different means. source Pooled unequal variance t-test # UncertainData.UncertainStatistics.UnequalVarianceTTestPooled \u2014 Function . 1 2 UnequalVarianceTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > UnequalVarianceTTest Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. Gather all s1[i] in a pooled sample S1 , and all s2[i] in a pooled sample S2 . This function performs an unequal variance two-sample t-test of the null hypothesis that S1 and S2 come from distributions with equal means against the alternative hypothesis that the distributions have different means. source Element-wise unequal variance t-test # UncertainData.UncertainStatistics.UnequalVarianceTTestElementWise \u2014 Function . 1 2 UnequalVarianceTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { UnequalVarianceTTest } Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. This function performs an elementwise EqualVarianceTTest on the pairs (s1[i], s2[i]) . Specifically: Performs an pairwise unequal variance two-sample t-test of the null hypothesis that s1[i] and s2[i] come from distributions with equal means against the alternative hypothesis that the distributions have different means. This test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation: \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n \\frac{(k_i s_i^2)^2}{\u03bd_i}} \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n \\frac{(k_i s_i^2)^2}{\u03bd_i}} source","title":"Unequal variance t-test"},{"location":"hypothesistests/unequal_variance_t_test/#unequal-variance-t-test","text":"# HypothesisTests.UnequalVarianceTTest \u2014 Type . 1 2 UnequalVarianceTTest ( d1 :: AbstractUncertainValue , d2 :: AbstractUncertainValue , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > UnequalVarianceTTest Consider two samples s1 and s2 , each consisting of n random draws from the distributions furnishing d1 and d2 , respectively. Perform an unequal variance two-sample t-test of the null hypothesis that s1 and s2 come from distributions with equal means against the alternative hypothesis that the distributions have different means. source","title":"Unequal variance t-test"},{"location":"hypothesistests/unequal_variance_t_test/#pooled-unequal-variance-t-test","text":"# UncertainData.UncertainStatistics.UnequalVarianceTTestPooled \u2014 Function . 1 2 UnequalVarianceTTestPooled ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > UnequalVarianceTTest Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. Gather all s1[i] in a pooled sample S1 , and all s2[i] in a pooled sample S2 . This function performs an unequal variance two-sample t-test of the null hypothesis that S1 and S2 come from distributions with equal means against the alternative hypothesis that the distributions have different means. source","title":"Pooled unequal variance t-test"},{"location":"hypothesistests/unequal_variance_t_test/#element-wise-unequal-variance-t-test","text":"# UncertainData.UncertainStatistics.UnequalVarianceTTestElementWise \u2014 Function . 1 2 UnequalVarianceTTestElementWise ( d1 :: UncertainDataset , d2 :: UncertainDataset , n :: Int = 1000 ; \u03bc0 :: Real = 0 ) - > Vector { UnequalVarianceTTest } Consider two samples s1[i] and s2[i] , each consisting of n random draws from the distributions furnishing the uncertain values d1[i] and d2[i] , respectively. This function performs an elementwise EqualVarianceTTest on the pairs (s1[i], s2[i]) . Specifically: Performs an pairwise unequal variance two-sample t-test of the null hypothesis that s1[i] and s2[i] come from distributions with equal means against the alternative hypothesis that the distributions have different means. This test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation: \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n \\frac{(k_i s_i^2)^2}{\u03bd_i}} \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n \\frac{(k_i s_i^2)^2}{\u03bd_i}} source","title":"Element-wise unequal variance t-test"}]}