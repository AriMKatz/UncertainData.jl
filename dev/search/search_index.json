{
    "docs": [
        {
            "location": "/", 
            "text": "UncertainData.jl\n\n\n\n\nMotivation\n\n\nUncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data significantly easier.\n\n\n\n\nProbabilistic representation of uncertain observations\n\n\nWay too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean).\n\n\n\n\nUncertain values and datasets of uncertain values\n\n\nIn this package, data values are stored as probability distributions. Individual uncertain observations may be collected in \nUncertainDatasets\n, which can be sampled according to user-provided sampling constraints.\n\n\nLikewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values.\n\n\n\n\nBasic workflow\n\n\n\n\nCreating uncertain values\n\n\nUncertain values are created by using the \nUncertainValue\n constructor.\n\n\nThere are currently three ways to construct uncertain values:\n\n\n\n\nEstimating the distribution of your data using kernel density estimation.\n\n\nFitting a distribution to empirical data (if you know roughly what type  of distribution is appropriate).\n\n\nSpecifying a probability distribution with known parameters (if you want  to represent data found in the literature, for example normally distributed  values with some standard deviation).\n\n\n\n\n\n\nResampling\n\n\nUncertain values may be resampled using the \nresample(uv::UncertainValue)\n function, which has methods for all the different types of uncertain values.", 
            "title": "Home"
        }, 
        {
            "location": "/#uncertaindatajl", 
            "text": "", 
            "title": "UncertainData.jl"
        }, 
        {
            "location": "/#motivation", 
            "text": "UncertainData.jl was born to systematically deal with uncertain data, and to sample uncertain dataset more rigorously. It makes workflows involving uncertain data significantly easier.", 
            "title": "Motivation"
        }, 
        {
            "location": "/#probabilistic-representation-of-uncertain-observations", 
            "text": "Way too often in data analysis the uncertainties in observational data are ignored or not dealt with in a systematic manner. The core concept of the package is that uncertain data should live in the probability domain, not as single value representations of the data (e.g. the mean).", 
            "title": "Probabilistic representation of uncertain observations"
        }, 
        {
            "location": "/#uncertain-values-and-datasets-of-uncertain-values", 
            "text": "In this package, data values are stored as probability distributions. Individual uncertain observations may be collected in  UncertainDatasets , which can be sampled according to user-provided sampling constraints.  Likewise, indices (e.g. time, depth or any other index) of observations are also represented as probability distributions. Indices may also be sampled using constraints, for example enforcing strictly increasing values.", 
            "title": "Uncertain values and datasets of uncertain values"
        }, 
        {
            "location": "/#basic-workflow", 
            "text": "", 
            "title": "Basic workflow"
        }, 
        {
            "location": "/#creating-uncertain-values", 
            "text": "Uncertain values are created by using the  UncertainValue  constructor.  There are currently three ways to construct uncertain values:   Estimating the distribution of your data using kernel density estimation.  Fitting a distribution to empirical data (if you know roughly what type  of distribution is appropriate).  Specifying a probability distribution with known parameters (if you want  to represent data found in the literature, for example normally distributed  values with some standard deviation).", 
            "title": "Creating uncertain values"
        }, 
        {
            "location": "/#resampling", 
            "text": "Uncertain values may be resampled using the  resample(uv::UncertainValue)  function, which has methods for all the different types of uncertain values.", 
            "title": "Resampling"
        }, 
        {
            "location": "/ensemble_statistics/", 
            "text": "Uncertain statistics\n\n\n\n\nCore statistics\n\n\nThis package implements most of the statistical algorithms in \nStatsBase\n for uncertain values and uncertain datasets.\n\n\nThe syntax for calling the algorithms is the same as in \nStatsBase\n, but the functions here accept an additional positional argument \nn\n, which controls how many times the uncertain values are resampled to compute the statistics. The default number of times to resample is \nn = 1000\n.\n\n\n\n\nStatistics of single uncertain values\n\n\n\n\nmean(d::AbstractUncertainValue, n::Int = 1000)\n. Computes the mean of an uncertain value.\n\n\nmedian(d::AbstractUncertainValue, n::Int = 1000)\n. Computes the median of an uncertain value.\n\n\nmiddle(d::AbstractUncertainValue, n::Int = 1000)\n. Computes the middle of an uncertain value.\n\n\nstd(d::AbstractUncertainValue, n::Int = 1000)\n. Computes the standard deviation of an uncertain value.\n\n\nvar(d::AbstractUncertainValue, n::Int = 1000)\n. Computes the variance of an uncertain value.\n\n\nquantile(d::AbstractUncertainValue, p, n::Int = 1000)\n. Computes the \np\n-th quantile(s) of an uncertain value.\n\n\n\n\n\n\nStatistics on datasets of uncertain values\n\n\nThe following statistics are available for uncertain datasets (collections of uncertain values).\n\n\n\n\nmean(d::UncertainDataset\n). Computes the element-wise mean of a dataset of uncertain values.\n\n\nmedian(d::UncertainDataset\n). Computes the element-wise median of a dataset of uncertain values.\n\n\nmiddle(d::UncertainDataset\n). Computes the element-wise middle of a dataset of uncertain values.\n\n\nstd(d::UncertainDataset\n). Computes the element-wise standard deviation of a dataset of uncertain values.\n\n\nvar(d::UncertainDataset\n). Computes the element-wise variance of a dataset of uncertain values.\n\n\nquantile(d::UncertainDataset, p, n::Int = 1000)\n. Computes the element-wise \np\n-th quantile(s) of a dataset of uncertain values.\n\n\ncor(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000)\n. Compute the correlation between two datasets consisting of uncertain values.\n\n\ncov(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000)\n. Compute the correlation between two datasets consisting of uncertain values.", 
            "title": "Ensemble statistics"
        }, 
        {
            "location": "/ensemble_statistics/#uncertain-statistics", 
            "text": "", 
            "title": "Uncertain statistics"
        }, 
        {
            "location": "/ensemble_statistics/#core-statistics", 
            "text": "This package implements most of the statistical algorithms in  StatsBase  for uncertain values and uncertain datasets.  The syntax for calling the algorithms is the same as in  StatsBase , but the functions here accept an additional positional argument  n , which controls how many times the uncertain values are resampled to compute the statistics. The default number of times to resample is  n = 1000 .", 
            "title": "Core statistics"
        }, 
        {
            "location": "/ensemble_statistics/#statistics-of-single-uncertain-values", 
            "text": "mean(d::AbstractUncertainValue, n::Int = 1000) . Computes the mean of an uncertain value.  median(d::AbstractUncertainValue, n::Int = 1000) . Computes the median of an uncertain value.  middle(d::AbstractUncertainValue, n::Int = 1000) . Computes the middle of an uncertain value.  std(d::AbstractUncertainValue, n::Int = 1000) . Computes the standard deviation of an uncertain value.  var(d::AbstractUncertainValue, n::Int = 1000) . Computes the variance of an uncertain value.  quantile(d::AbstractUncertainValue, p, n::Int = 1000) . Computes the  p -th quantile(s) of an uncertain value.", 
            "title": "Statistics of single uncertain values"
        }, 
        {
            "location": "/ensemble_statistics/#statistics-on-datasets-of-uncertain-values", 
            "text": "The following statistics are available for uncertain datasets (collections of uncertain values).   mean(d::UncertainDataset ). Computes the element-wise mean of a dataset of uncertain values.  median(d::UncertainDataset ). Computes the element-wise median of a dataset of uncertain values.  middle(d::UncertainDataset ). Computes the element-wise middle of a dataset of uncertain values.  std(d::UncertainDataset ). Computes the element-wise standard deviation of a dataset of uncertain values.  var(d::UncertainDataset ). Computes the element-wise variance of a dataset of uncertain values.  quantile(d::UncertainDataset, p, n::Int = 1000) . Computes the element-wise  p -th quantile(s) of a dataset of uncertain values.  cor(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values.  cov(d1::UncertainDataset, d2::UncertainDataset, n::Int = 1000) . Compute the correlation between two datasets consisting of uncertain values.", 
            "title": "Statistics on datasets of uncertain values"
        }, 
        {
            "location": "/implementing_algorithms_for_uncertaindata/", 
            "text": "Extending existing algorithms for uncertain data types\n\n\nDo you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the \nAbstractUncertainValue\n and \nAbstractUncertainDataset\n types, along with a \nSamplingConstraints\n specifying how the uncertain values are should be resampled.\n\n\nA basic function skeleton could be\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n# Some algorithm computing a statistic for a scalar-valued vector\n\n\nfunction\n \nmyalgorithm\n(\ndataset\n::\nVector\n{\nT\n};\n \nkwargs\n...\n)\n \nwhere\n \nT\n\n    \n# some algorithm returning a single-valued statistic\n\n\nend\n\n\n\n# Applying the algorithm to an ensemble of realisations from\n\n\n# an uncertain dataset, given a sampling constraint.\n\n\nfunction\n \nmyalgorithm\n(\nd\n::\nUncertainDataset\n,\n \nconstraint\n::\nC\n;\n\n        \nn_ensemble_realisations\n \n=\n \n100\n,\n \nkwargs\n...\n)\n\n        \nwhere\n \n{\nC\n \n:\n \nSamplingConstraint\n}\n\n\n    \nensemble_stats\n \n=\n \nzeros\n(\nn_ensemble_realisations\n)\n\n\n    \nfor\n \ni\n \nin\n \n1\n:\nn_ensemble_realisations\n\n        \nensemble_stats\n[\ni\n]\n \n=\n \nmyalgorithm\n(\nresample\n(\nd\n,\n \nconstraint\n);\n \nkwargs\n...\n)\n\n    \nend\n\n\n    \nreturn\n \nensemble_stats\n\n\nend", 
            "title": "Implementing algorithms for uncertaindata"
        }, 
        {
            "location": "/implementing_algorithms_for_uncertaindata/#extending-existing-algorithms-for-uncertain-data-types", 
            "text": "Do you already have an algorithm computing some statistic that you want to obtain uncertainty estimates for? Simply use Julia's multiple dispatch and create a version of the algorithm function that accepts the  AbstractUncertainValue  and  AbstractUncertainDataset  types, along with a  SamplingConstraints  specifying how the uncertain values are should be resampled.  A basic function skeleton could be   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19 # Some algorithm computing a statistic for a scalar-valued vector  function   myalgorithm ( dataset :: Vector { T };   kwargs ... )   where   T \n     # some algorithm returning a single-valued statistic  end  # Applying the algorithm to an ensemble of realisations from  # an uncertain dataset, given a sampling constraint.  function   myalgorithm ( d :: UncertainDataset ,   constraint :: C ; \n         n_ensemble_realisations   =   100 ,   kwargs ... ) \n         where   { C   :   SamplingConstraint } \n\n     ensemble_stats   =   zeros ( n_ensemble_realisations ) \n\n     for   i   in   1 : n_ensemble_realisations \n         ensemble_stats [ i ]   =   myalgorithm ( resample ( d ,   constraint );   kwargs ... ) \n     end \n\n     return   ensemble_stats  end", 
            "title": "Extending existing algorithms for uncertain data types"
        }, 
        {
            "location": "/resampling/", 
            "text": "Resampling\n\n\n\n\nWithout constraints\n\n\nRegular resampling is done by drawing random number from the entire probability distributions furnishing the uncertain values.\n\n\n\n\nWith constraints\n\n\nThe following syntax is used to resample uncertain values.\n\n\n\n\nresample(uv::AbstractUncertainValue, constraint::SamplingConstraint)\n. Resample the uncertain value once within the restrictions imposed by the sampling constraint.\n\n\nresample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int)\n. Resample the uncertain value \nn\n times within the restrictions imposed by the sampling constraint.\n\n\n\n\n\n\nSampling constraints\n\n\nThe following sampling constraints are available:\n\n\n\n\nTruncateStd(n\u03c3::Int)\n. Truncate the distribution furnishing the uncertain data point(s) at n times the standard deviation of the distribution.\n\n\nTruncateMinimum(min\n:Number)\n. Truncate the distribution furnishing the uncertain data point(s) at some minimum value.\n\n\nTruncateMaximum(max\n:Number)\n. Truncate the distribution furnishing the uncertain data point(s) at some maximum value.\n\n\nTruncateRange(min\n:Number, max\n:Number)\n. Truncate the distribution furnishing the uncertain data point(s) at some range.\n\n\nTruncateLowerQuantile(lower_quantile::Float64)\n. Truncate the distribution furnishing the uncertain data point(s) at some lower quantile of the distribution.\n\n\nTruncateUpperQuantile(upper_quantile::Float64)\n. Truncate the distribution furnishing the uncertain data point(s) at some upper quantile of the distribution.\n\n\nTruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64)\n. Truncate the distribution furnishing the uncertain data point(s) at a \nlower_quantile\n\n\n\n\nand an \nupper_quantile\n of the distribution.\n\n\n\n\nExamples\n\n\nLet \nuv = UncertainValue(Normal, 1, 0.2)\n. One may, for example, impose the following sampling constraints:\n\n\n\n\nresample(uv, TruncateLowerQuantile(0.2))\n. Resamples \nuv\n 100 times, drawing values strictly larger than the 0.2-th quantile of the distribution furnishing the uncertain data point.\n\n\nresample(uv, TruncateStd(1), 100)\n. Resamples \nuv\n 100 times, drawing values falling within one standard deviation of the distribution furnishing the uncertain value.\n\n\nresample(uv, TruncateRange(-0.5, 1), 100)\n. Resamples \nuv\n 100 times, drawing values from the distribution furnishing the uncertain value within the interval \n[-0.5, 1]\n.", 
            "title": "Resampling"
        }, 
        {
            "location": "/resampling/#resampling", 
            "text": "", 
            "title": "Resampling"
        }, 
        {
            "location": "/resampling/#without-constraints", 
            "text": "Regular resampling is done by drawing random number from the entire probability distributions furnishing the uncertain values.", 
            "title": "Without constraints"
        }, 
        {
            "location": "/resampling/#with-constraints", 
            "text": "The following syntax is used to resample uncertain values.   resample(uv::AbstractUncertainValue, constraint::SamplingConstraint) . Resample the uncertain value once within the restrictions imposed by the sampling constraint.  resample(uv::AbstractUncertainValue, constraint::SamplingConstraint, n::Int) . Resample the uncertain value  n  times within the restrictions imposed by the sampling constraint.", 
            "title": "With constraints"
        }, 
        {
            "location": "/resampling/#sampling-constraints", 
            "text": "The following sampling constraints are available:   TruncateStd(n\u03c3::Int) . Truncate the distribution furnishing the uncertain data point(s) at n times the standard deviation of the distribution.  TruncateMinimum(min :Number) . Truncate the distribution furnishing the uncertain data point(s) at some minimum value.  TruncateMaximum(max :Number) . Truncate the distribution furnishing the uncertain data point(s) at some maximum value.  TruncateRange(min :Number, max :Number) . Truncate the distribution furnishing the uncertain data point(s) at some range.  TruncateLowerQuantile(lower_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some lower quantile of the distribution.  TruncateUpperQuantile(upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at some upper quantile of the distribution.  TruncateQuantiles(lower_quantile::Float64, upper_quantile::Float64) . Truncate the distribution furnishing the uncertain data point(s) at a  lower_quantile   and an  upper_quantile  of the distribution.", 
            "title": "Sampling constraints"
        }, 
        {
            "location": "/resampling/#examples", 
            "text": "Let  uv = UncertainValue(Normal, 1, 0.2) . One may, for example, impose the following sampling constraints:   resample(uv, TruncateLowerQuantile(0.2)) . Resamples  uv  100 times, drawing values strictly larger than the 0.2-th quantile of the distribution furnishing the uncertain data point.  resample(uv, TruncateStd(1), 100) . Resamples  uv  100 times, drawing values falling within one standard deviation of the distribution furnishing the uncertain value.  resample(uv, TruncateRange(-0.5, 1), 100) . Resamples  uv  100 times, drawing values from the distribution furnishing the uncertain value within the interval  [-0.5, 1] .", 
            "title": "Examples"
        }, 
        {
            "location": "/uncertainvalues_fitted/", 
            "text": "Uncertain values from fitted distributions\n\n\nFor data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution.\n\n\n\n\nExamples\n\n\nIn the following examples, we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits.\n\n\n\n\n\n\nUniform\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nUniform\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Define an uncertain value by fitting a uniform distribution to the sample.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted normal distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted gamma distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\n\n\nSupported distributions\n\n\nSupported distributions are \nUniform\n, \nNormal\n, \nGamma\n, \nBeta\n, \nBetaPrime\n, \nFrechet\n, \nBinomial\n, \nBetaBinomial\n.\n\n\n\n\nBeware: fitting distributions may lead to nonsensical results!\n\n\nIn a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,\n\n\n# \u03b8 = 5.2.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(\n2.1\n,\n \n5.2\n),\n \n1000\n)\n\n\n\n# Represent the uncertain value by a fitted beta distribution.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\nThis is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.\n\n\nIf the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.\n\n\n\n\nConstructor\n\n\nTo construct uncertain values represented by empirical distributions, use the following constructor.\n\n\n1\n2\nUncertainValue\n(\nd\n::\nType\n{\nD\n},\n \nempiricaldata\n)\n \nwhere\n\n    \n{\nD\n:\nDistributions\n.\nDistribution\n}\n\n\n\n\n\n\n\nThis will fit a distribution of type \nd\n to the data and keep that as the representation of the empirical distribution. Calls \nDistributions.fit\n behind the scenes.", 
            "title": "Uncertainvalues fitted"
        }, 
        {
            "location": "/uncertainvalues_fitted/#uncertain-values-from-fitted-distributions", 
            "text": "For data values with histograms close to some known distribution, the user may choose to represent the data by fitting a theoretical distribution to the values. This will only work well if the histogram closely resembles a theoretical distribution.", 
            "title": "Uncertain values from fitted distributions"
        }, 
        {
            "location": "/uncertainvalues_fitted/#examples", 
            "text": "In the following examples, we're trying to fit the same distribution to our sample as the distribution from which we draw the sample. Thus, we will get good fits.    Uniform   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Uniform ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Define an uncertain value by fitting a uniform distribution to the sample.  uv   =   UncertainValue ( Uniform ,   some_sample )     Normal   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Represent the uncertain value by a fitted normal distribution.  uv   =   UncertainValue ( Normal ,   some_sample )     Gamma  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted gamma distribution.  uv   =   UncertainValue ( Gamma ,   some_sample )", 
            "title": "Examples"
        }, 
        {
            "location": "/uncertainvalues_fitted/#supported-distributions", 
            "text": "Supported distributions are  Uniform ,  Normal ,  Gamma ,  Beta ,  BetaPrime ,  Frechet ,  Binomial ,  BetaBinomial .", 
            "title": "Supported distributions"
        }, 
        {
            "location": "/uncertainvalues_fitted/#beware-fitting-distributions-may-lead-to-nonsensical-results", 
            "text": "In a less contrived example, we may try to fit a beta distribution to a sample generated from a gamma distribution.  1\n2\n3\n4\n5\n6\n7\n8 using   Distributions ,   UncertainData  # Generate 1000 values from a gamma distribution with parameters \u03b1 = 2.1,  # \u03b8 = 5.2.  some_sample   =   rand ( Gamma ( 2.1 ,   5.2 ),   1000 )  # Represent the uncertain value by a fitted beta distribution.  uv   =   UncertainValue ( Beta ,   some_sample )    This is obviously not a good idea. Always visualise your distribution before deciding on which distribution to fit! You won't get any error messages if you try to fit a distribution that does not match your data.  If the data do not follow an obvious theoretical distribution, it is better to use kernel density estimation to define the uncertain value.", 
            "title": "Beware: fitting distributions may lead to nonsensical results!"
        }, 
        {
            "location": "/uncertainvalues_fitted/#constructor", 
            "text": "To construct uncertain values represented by empirical distributions, use the following constructor.  1\n2 UncertainValue ( d :: Type { D },   empiricaldata )   where \n     { D : Distributions . Distribution }    This will fit a distribution of type  d  to the data and keep that as the representation of the empirical distribution. Calls  Distributions.fit  behind the scenes.", 
            "title": "Constructor"
        }, 
        {
            "location": "/uncertainvalues_kde/", 
            "text": "Uncertain value from KDE estimate\n\n\n1\nUncertainValue(::UnivariateKDE, ::Vector)\n\n\n\n\n\n\nRepresenting uncertain values by a kernel density estimate is appropriate when data have an empirical distribution that doesn't follow any obvious theoretical distribution.\n\n\nTo visualize this, let's create a bimodal distribution, then sample 10000 values from it.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\nusing\n \nDistributions\n\n\n\nn1\n \n=\n \nNormal\n(\n-\n3.0\n,\n \n1.2\n)\n\n\nn2\n \n=\n \nNormal\n(\n8.0\n,\n \n1.2\n)\n\n\nn3\n \n=\n \nNormal\n(\n0.0\n,\n \n2.5\n)\n\n\n\n# Use a mixture model to create a bimodal distribution\n\n\nM\n \n=\n \nMixtureModel\n([\nn1\n,\n \nn2\n,\n \nn3\n])\n\n\n\n# Sample the mixture model.\n\n\nsamples_empirical\n \n=\n \nrand\n(\nM\n,\n \nInt\n(\n1e4\n));\n\n\n\n\n\n\n\n\n\nIt is not obvious which distribution to fit to such data.\n\n\nA kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.\n\n\nTo create a kernel density estimate, simply call the \nUncertainValue(v::Vector{Number})\n constructor with a vector containing the sample:\n\n\n1\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\n\n\n\n\n\nThe plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.\n\n\n1\n2\n3\n4\n5\n6\n7\nusing\n \nPlots\n,\n \nStatPlots\n,\n \nUncertainData\n\n\nuv\n \n=\n \nUncertainValue\n(\nsamples_empirical\n)\n\n\ndensity\n(\nmvals\n,\n \nlabel\n \n=\n \n10000 mixture model (M) samples\n)\n\n\ndensity!\n(\nrand\n(\nuv\n,\n \nInt\n(\n1e4\n)),\n\n    \nlabel\n \n=\n \n10000 samples from KDE estimate to M\n)\n\n\nxlabel!\n(\ndata value\n)\n\n\nylabel!\n(\nprobability density\n)\n\n\n\n\n\n\n\n\n\n\n\nAdditional keyword arguments and examples\n\n\nIf the only argument to the \nUncertainValue\n constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e. \nUncertainValue(data)\n. Gaussian kernels are used by default. The syntax \nUncertainValue(UnivariateKDE, data)\n will also work if \nKernelDensity.jl\n is loaded.\n\n\n\n\n\n\nImplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the implicit KDE constructor to create the uncertain value\n\n\nuv\n \n=\n \nUncertainValue\n(\nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nExplicit KDE constructor\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value.\n\n\n# This constructor follows the same convention as when fitting distributions\n\n\n# to empirical data, so this is the recommended way to construct KDE estimates.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n)\n\n\n\n\n\n\n\n\nChanging the kernel\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# that we want to use normal distributions as the kernel. The kernel can be\n\n\n# any valid kernel from Distributions.jl, and the default is to use normal\n\n\n# distributions.\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nkernel\n \n=\n \nNormal\n)\n\n\n\n\n\n\n\n\nAdjusting number of points\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nusing\n \nDistributions\n,\n \nUncertainData\n,\n \nKernelDensity\n\n\n\n# Create a normal distribution\n\n\nd\n \n=\n \nNormal\n()\n\n\n\n# Draw a 1000-point sample from the distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nd\n,\n \n1000\n)\n\n\n\n# Use the explicit KDE constructor to create the uncertain value, specifying\n\n\n# the number of points we want to use for the kernel density estimate. Fast\n\n\n# Fourier transforms are used behind the scenes, so the number of points\n\n\n# should be a power of 2 (the default is 2048 points).\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nv\n::\nVector\n;\n \nnpoints\n \n=\n \n1024\n)", 
            "title": "Uncertainvalues kde"
        }, 
        {
            "location": "/uncertainvalues_kde/#uncertain-value-from-kde-estimate", 
            "text": "1 UncertainValue(::UnivariateKDE, ::Vector)   Representing uncertain values by a kernel density estimate is appropriate when data have an empirical distribution that doesn't follow any obvious theoretical distribution.  To visualize this, let's create a bimodal distribution, then sample 10000 values from it.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 using   Distributions  n1   =   Normal ( - 3.0 ,   1.2 )  n2   =   Normal ( 8.0 ,   1.2 )  n3   =   Normal ( 0.0 ,   2.5 )  # Use a mixture model to create a bimodal distribution  M   =   MixtureModel ([ n1 ,   n2 ,   n3 ])  # Sample the mixture model.  samples_empirical   =   rand ( M ,   Int ( 1e4 ));     It is not obvious which distribution to fit to such data.  A kernel density estimate, however, will always be a decent representation of the data, because it doesn't follow a specific distribution and adapts to the data values.  To create a kernel density estimate, simply call the  UncertainValue(v::Vector{Number})  constructor with a vector containing the sample:  1 uv   =   UncertainValue ( samples_empirical )    The plot below compares the empirical histogram (here represented as a density plot) with our kernel density estimate.  1\n2\n3\n4\n5\n6\n7 using   Plots ,   StatPlots ,   UncertainData  uv   =   UncertainValue ( samples_empirical )  density ( mvals ,   label   =   10000 mixture model (M) samples )  density! ( rand ( uv ,   Int ( 1e4 )), \n     label   =   10000 samples from KDE estimate to M )  xlabel! ( data value )  ylabel! ( probability density )", 
            "title": "Uncertain value from KDE estimate"
        }, 
        {
            "location": "/uncertainvalues_kde/#additional-keyword-arguments-and-examples", 
            "text": "If the only argument to the  UncertainValue  constructor is a vector of values, the default behaviour is to represent the distribution by a kernel density estimate (KDE), i.e.  UncertainValue(data) . Gaussian kernels are used by default. The syntax  UncertainValue(UnivariateKDE, data)  will also work if  KernelDensity.jl  is loaded.    Implicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 using   Distributions ,   UncertainData  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the implicit KDE constructor to create the uncertain value  uv   =   UncertainValue ( v :: Vector )     Explicit KDE constructor   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value.  # This constructor follows the same convention as when fitting distributions  # to empirical data, so this is the recommended way to construct KDE estimates.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector )     Changing the kernel   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # that we want to use normal distributions as the kernel. The kernel can be  # any valid kernel from Distributions.jl, and the default is to use normal  # distributions.  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   kernel   =   Normal )     Adjusting number of points   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 using   Distributions ,   UncertainData ,   KernelDensity  # Create a normal distribution  d   =   Normal ()  # Draw a 1000-point sample from the distribution.  some_sample   =   rand ( d ,   1000 )  # Use the explicit KDE constructor to create the uncertain value, specifying  # the number of points we want to use for the kernel density estimate. Fast  # Fourier transforms are used behind the scenes, so the number of points  # should be a power of 2 (the default is 2048 points).  uv   =   UncertainValue ( UnivariateKDE ,   v :: Vector ;   npoints   =   1024 )", 
            "title": "Additional keyword arguments and examples"
        }, 
        {
            "location": "/uncertainvalues_overview/", 
            "text": "Uncertain value representations\n\n\nUncertain values may be constructed in three different ways, depending on what information you have available.\n\n\n\n\nKernel density estimates to the observed data\n\n\nIf the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.\n\n\nThe \nUncertainValue(empiricaldata::Vector)\n constructor returns an uncertain value represented by a kernel density estimate to the empirical distribution.\n\n\n\n\n\n\nKernel density estimate of empirical distribution\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a kernel density estimate\n\n\nuv\n \n=\n \nUncertainValue\n(\nsome_sample\n)\n\n\n\n# The following is equivalent\n\n\nusing\n \nKernelDensity\n \n# needed to get access to the UnivarateKDE type\n\n\nuv\n \n=\n \nUncertainValue\n(\nUnivariateKDE\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\n\n\nTheoretical distributions with fitted parameters\n\n\nIf your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.\n\n\n\n\nThe \nUncertainValue(d::Type{D}, empiricaldata::Vector) where {D \n: Distribution}\n constructor fits a distribution of type \nd\n to \nempiricaldata\n.\n\n\n\n\n\n\n\n\nExample 1: fitting a normal distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a normal distribution, so that we get a\n\n\n# histogram resembling a normal distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nNormal\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\nExample 2: fitting a gamma distribution\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\nusing\n \nDistributions\n,\n \nUncertainData\n\n\n\n# Generate some random data from a gamma distribution, so that we get a\n\n\n# histogram resembling a gamma distribution.\n\n\nsome_sample\n \n=\n \nrand\n(\nGamma\n(),\n \n1000\n)\n\n\n\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# parameters fitted to the data.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \nsome_sample\n)\n\n\n\n\n\n\n\n\n\n\nTheoretical distributions with known parameters\n\n\nIt is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean \n\u03bc = 0\n and standard deviation \n\u03c3 = 0.3\n.\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical normal distribution with\n\n\n# known parameters \u03bc = 0 and \u03c3 = 0.3\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n0\n,\n \n0.3\n)\n\n\n\n\n\n\n\n\n\nGeneric two-parameter constructor\n\n\nThe generic two-parameter constructor returns an uncertain value represented by a distribution of type \nd\n with parameters \na\n and \nb\n (which, of course, have different meanings depending on which distribution is provided). Valid distributions are \nNormal\n, \nUniform\n, \nBeta\n, \nBetaPrime\n, \nGamma\n, \nFrechet\n and \nBinomial\n.\n\n\n1\nUncertainValue\n(\nd\n::\nType\n{\nD\n},\n \na\n:\nNumber\n,\n \nb\n:\nNumber\n)\n\n\n\n\n\n\n\nFor example,\n\n\n\n\n\n\nExample 1\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical gamma distribution with\n\n\n# known parameters \u03b1 = 2.1 and \u03b8 = 3.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.1\n,\n \n3.1\n)\n\n\n\n\n\n\n\n\nExample 2\n\n\n1\n2\n3\n# Uncertain value represented by a theoretical binomial distribution with\n\n\n# known parameters p = 32 and p = 0.13\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n32\n,\n \n0.13\n)\n\n\n\n\n\n\n\n\nCombined with a valid two-parameter distribution, the \na\n and \nb\n parameter syntax translates into:\n\n\n\n\nUncertainValue(Normal, \u03bc, \u03c3)\n\n\nUncertainValue(Uniform, lower, upper)\n\n\nUncertainValue(Beta, \u03b1, \u03b2)\n\n\nUncertainValue(BetaPrime, \u03b1, \u03b2)\n\n\nUncertainValue(Gamma, \u03b1, \u03b8)\n\n\nUncertainValue(Frechet, \u03b1, \u03b8)\n\n\nUncertainValue(Binomial, n, p)\n\n\n\n\n\n\nGeneric three-parameter constructor\n\n\nThe three-parameter constructor works similarly for three-parameter distributions:\n\n\n1\nUncertainValue(d::Type{D}, a\n:Number, b\n:Number, c\n:Number)\n\n\n\n\n\n\nCombined with a valid two-parameter distribution, the \na\n, \nb\n and \nc\n parameter syntax translates into:\n\n\n\n\nUncertainValue(BetaBinomial, n, \u03b1, \u03b2)", 
            "title": "Uncertainvalues overview"
        }, 
        {
            "location": "/uncertainvalues_overview/#uncertain-value-representations", 
            "text": "Uncertain values may be constructed in three different ways, depending on what information you have available.", 
            "title": "Uncertain value representations"
        }, 
        {
            "location": "/uncertainvalues_overview/#kernel-density-estimates-to-the-observed-data", 
            "text": "If the data doesn't follow an obvious theoretical distribution, the recommended course of action is to represent the uncertain value with a kernel density estimate of the distribution.  The  UncertainValue(empiricaldata::Vector)  constructor returns an uncertain value represented by a kernel density estimate to the empirical distribution.    Kernel density estimate of empirical distribution   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a kernel density estimate  uv   =   UncertainValue ( some_sample )  # The following is equivalent  using   KernelDensity   # needed to get access to the UnivarateKDE type  uv   =   UncertainValue ( UnivariateKDE ,   some_sample )", 
            "title": "Kernel density estimates to the observed data"
        }, 
        {
            "location": "/uncertainvalues_overview/#theoretical-distributions-with-fitted-parameters", 
            "text": "If your data has a histogram closely resembling some theoretical distribution, the uncertain value may be represented by fitting such a distribution to the data.   The  UncertainValue(d::Type{D}, empiricaldata::Vector) where {D  : Distribution}  constructor fits a distribution of type  d  to  empiricaldata .     Example 1: fitting a normal distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a normal distribution, so that we get a  # histogram resembling a normal distribution.  some_sample   =   rand ( Normal (),   1000 )  # Uncertain value represented by a theoretical normal distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Normal ,   some_sample )     Example 2: fitting a gamma distribution  1\n2\n3\n4\n5\n6\n7\n8\n9 using   Distributions ,   UncertainData  # Generate some random data from a gamma distribution, so that we get a  # histogram resembling a gamma distribution.  some_sample   =   rand ( Gamma (),   1000 )  # Uncertain value represented by a theoretical gamma distribution with  # parameters fitted to the data.  uv   =   UncertainValue ( Gamma ,   some_sample )", 
            "title": "Theoretical distributions with fitted parameters"
        }, 
        {
            "location": "/uncertainvalues_overview/#theoretical-distributions-with-known-parameters", 
            "text": "It is common when working with uncertain data found in the scientific literature that data value are stated to follow a distribution with given parameters. For example, a data value may be given as normal distribution with a given mean  \u03bc = 0  and standard deviation  \u03c3 = 0.3 .  1\n2\n3 # Uncertain value represented by a theoretical normal distribution with  # known parameters \u03bc = 0 and \u03c3 = 0.3  uv   =   UncertainValue ( Normal ,   0 ,   0.3 )", 
            "title": "Theoretical distributions with known parameters"
        }, 
        {
            "location": "/uncertainvalues_overview/#generic-two-parameter-constructor", 
            "text": "The generic two-parameter constructor returns an uncertain value represented by a distribution of type  d  with parameters  a  and  b  (which, of course, have different meanings depending on which distribution is provided). Valid distributions are  Normal ,  Uniform ,  Beta ,  BetaPrime ,  Gamma ,  Frechet  and  Binomial .  1 UncertainValue ( d :: Type { D },   a : Number ,   b : Number )    For example,    Example 1  1\n2\n3 # Uncertain value represented by a theoretical gamma distribution with  # known parameters \u03b1 = 2.1 and \u03b8 = 3.1  uv   =   UncertainValue ( Gamma ,   2.1 ,   3.1 )     Example 2  1\n2\n3 # Uncertain value represented by a theoretical binomial distribution with  # known parameters p = 32 and p = 0.13  uv   =   UncertainValue ( Binomial ,   32 ,   0.13 )     Combined with a valid two-parameter distribution, the  a  and  b  parameter syntax translates into:   UncertainValue(Normal, \u03bc, \u03c3)  UncertainValue(Uniform, lower, upper)  UncertainValue(Beta, \u03b1, \u03b2)  UncertainValue(BetaPrime, \u03b1, \u03b2)  UncertainValue(Gamma, \u03b1, \u03b8)  UncertainValue(Frechet, \u03b1, \u03b8)  UncertainValue(Binomial, n, p)", 
            "title": "Generic two-parameter constructor"
        }, 
        {
            "location": "/uncertainvalues_overview/#generic-three-parameter-constructor", 
            "text": "The three-parameter constructor works similarly for three-parameter distributions:  1 UncertainValue(d::Type{D}, a :Number, b :Number, c :Number)   Combined with a valid two-parameter distribution, the  a ,  b  and  c  parameter syntax translates into:   UncertainValue(BetaBinomial, n, \u03b1, \u03b2)", 
            "title": "Generic three-parameter constructor"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/", 
            "text": "Uncertain values from theoretical distributions\n\n\nIt is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. Perhaps the authors report the mean and standard deviation of a value stated to follow a normal distribution. \nUncertainData\n makes it easy to represent such values!\n\n\n\n\nSupported distributions\n\n\nUncertain values may be constructed from theoretical distribution using any of the following distributions (more distributions will be added in the future!).\n\n\n\n\n\n\nUniform\n\n\n1\n2\n# Uncertain value generated by a uniform distribution on [-5.0, 5.1].\n\n\nuv\n \n=\n \nUncertainValue\n(\nUniform\n,\n \n-\n5.0\n,\n \n5.1\n)\n\n\n\n\n\n\n\n\nNormal\n\n\n1\n2\n3\n# Uncertain value generated by a normal distribution with parameters \u03bc = -2 and\n\n\n# \u03c3 = 0.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n-\n2\n,\n \n0.5\n)\n\n\n\n\n\n\n\n\nGamma\n\n\n1\n2\n3\n# Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2\n\n\n# and \u03b8 = 3.\n\n\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2.2\n,\n \n3\n)\n\n\n\n\n\n\n\n\nBeta\n\n\n1\n2\n3\n# Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5\n\n\n# and \u03b2 = 3.5\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.5\n,\n \n3.5\n)\n\n\n\n\n\n\n\n\nBetaPrime\n\n\n1\n2\n3\n# Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7\n\n\n# and \u03b2 = 3.2\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n1.7\n,\n \n3.2\n)\n\n\n\n\n\n\n\n\nFr\u00e9chet\n\n\n1\n2\n3\n# Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1\n\n\n# and \u03b8 = 4\n\n\nuv\n \n=\n \nUncertainValue\n(\nBeta\n,\n \n2.1\n,\n \n4\n)\n\n\n\n\n\n\n\n\nBinomial\n\n\n1\n2\n3\n# Uncertain value generated by binomial distribution with n = 28 trials and\n\n\n# probability p = 0.2 of success in individual trials.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBinomial\n,\n \n28\n,\n \n0.2\n)\n\n\n\n\n\n\n\n\nBetaBinomial\n\n\n1\n2\n3\n# Creates an uncertain value generated by a beta-binomial distribution with\n\n\n# n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.\n\n\nuv\n \n=\n \nUncertainValue\n(\nBetaBinomial\n,\n \n28\n,\n \n3.3\n,\n \n4.4\n)\n\n\n\n\n\n\n\n\n\n\nConstructors\n\n\nIn this package, there are two constructors that creates uncertain values represented by theoretical distributions. The order the parameters are provided to the constructor is the same as for constructing the equivalent distributions in \nDistributions.jl\n.\n\n\n\n\nTwo-parameter distributions\n\n\n1\n2\nUncertainValue\n(\nd\n::\nType\n{\nD\n},\n \na\n:\nNumber\n,\n \nb\n:\nNumber\n)\n\n    \nwhere\n \n{\nD\n:\nDistributions\n.\nDistribution\n}\n\n\n\n\n\n\n\nCreates an uncertain value consisting of a two-parameter distribution of type \nd\n with parameters \na\n and \nb\n. Precisely what  \na\n and \nb\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue(Normal, \u03bc, \u03c3)\n creates an \nUncertainScalarNormallyDistributed\n instance.\n\n\nUncertainValue(Uniform, lower, upper)\n creates an \nUncertainScalarUniformlyDistributed\n instance.\n\n\nUncertainValue(Beta, \u03b1, \u03b2)\n creates an \nUncertainScalarBetaDistributed\n instance.\n\n\nUncertainValue(BetaPrime, \u03b1, \u03b2)\n creates an \nUncertainScalarBetaPrimeDistributed\n instance.\n\n\nUncertainValue(Gamma, \u03b1, \u03b8)\n creates an \nUncertainScalarGammaDistributed\n instance.\n\n\nUncertainValue(Frechet, \u03b1, \u03b8)\n creates an \nUncertainScalarFrechetDistributed\n instance.\n\n\nUncertainValue(Binomial, n, p)\n creates an \nUncertainScalarBinomialDistributed\n instance.\n\n\n\n\n\n\nThree-parameter distributions\n\n\n1\n2\nUncertainValue\n(\nd\n::\nType\n{\nD\n},\n \na\n:\nNumber\n,\n \nb\n:\nNumber\n,\n \nc\n:\nNumber\n)\n\n    \nwhere\n \n{\nD\n:\nDistributions\n.\nDistribution\n}\n\n\n\n\n\n\n\nCreates an uncertain value consisting of a three-parameter distribution of type \nd\n with parameters \na\n, \nb\n and \nc\n. Precisely what \na\n, \nb\n and \nc\n are depends on which distribution is provided.\n\n\n\n\nUncertainValue(BetaBinomial, n, \u03b1, \u03b2)\n creates an \nUncertainScalarBetaBinomialDistributed\n instance.", 
            "title": "Uncertainvalues theoreticaldistributions"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/#uncertain-values-from-theoretical-distributions", 
            "text": "It is common in the scientific literature to encounter uncertain data values which are reported as following a specific distribution. Perhaps the authors report the mean and standard deviation of a value stated to follow a normal distribution.  UncertainData  makes it easy to represent such values!", 
            "title": "Uncertain values from theoretical distributions"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/#supported-distributions", 
            "text": "Uncertain values may be constructed from theoretical distribution using any of the following distributions (more distributions will be added in the future!).    Uniform  1\n2 # Uncertain value generated by a uniform distribution on [-5.0, 5.1].  uv   =   UncertainValue ( Uniform ,   - 5.0 ,   5.1 )     Normal  1\n2\n3 # Uncertain value generated by a normal distribution with parameters \u03bc = -2 and  # \u03c3 = 0.5.  uv   =   UncertainValue ( Normal ,   - 2 ,   0.5 )     Gamma  1\n2\n3 # Uncertain value generated by a gamma distribution with parameters \u03b1 = 2.2  # and \u03b8 = 3.  uv   =   UncertainValue ( Gamma ,   2.2 ,   3 )     Beta  1\n2\n3 # Uncertain value generated by a beta distribution with parameters \u03b1 = 1.5  # and \u03b2 = 3.5  uv   =   UncertainValue ( Beta ,   1.5 ,   3.5 )     BetaPrime  1\n2\n3 # Uncertain value generated by a beta prime distribution with parameters \u03b1 = 1.7  # and \u03b2 = 3.2  uv   =   UncertainValue ( Beta ,   1.7 ,   3.2 )     Fr\u00e9chet  1\n2\n3 # Uncertain value generated by a Fr\u00e9chet distribution with parameters \u03b1 = 2.1  # and \u03b8 = 4  uv   =   UncertainValue ( Beta ,   2.1 ,   4 )     Binomial  1\n2\n3 # Uncertain value generated by binomial distribution with n = 28 trials and  # probability p = 0.2 of success in individual trials.  uv   =   UncertainValue ( Binomial ,   28 ,   0.2 )     BetaBinomial  1\n2\n3 # Creates an uncertain value generated by a beta-binomial distribution with  # n = 28 trials, and parameters \u03b1 = 1.5 and \u03b2 = 3.5.  uv   =   UncertainValue ( BetaBinomial ,   28 ,   3.3 ,   4.4 )", 
            "title": "Supported distributions"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/#constructors", 
            "text": "In this package, there are two constructors that creates uncertain values represented by theoretical distributions. The order the parameters are provided to the constructor is the same as for constructing the equivalent distributions in  Distributions.jl .", 
            "title": "Constructors"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/#two-parameter-distributions", 
            "text": "1\n2 UncertainValue ( d :: Type { D },   a : Number ,   b : Number ) \n     where   { D : Distributions . Distribution }    Creates an uncertain value consisting of a two-parameter distribution of type  d  with parameters  a  and  b . Precisely what   a  and  b  are depends on which distribution is provided.   UncertainValue(Normal, \u03bc, \u03c3)  creates an  UncertainScalarNormallyDistributed  instance.  UncertainValue(Uniform, lower, upper)  creates an  UncertainScalarUniformlyDistributed  instance.  UncertainValue(Beta, \u03b1, \u03b2)  creates an  UncertainScalarBetaDistributed  instance.  UncertainValue(BetaPrime, \u03b1, \u03b2)  creates an  UncertainScalarBetaPrimeDistributed  instance.  UncertainValue(Gamma, \u03b1, \u03b8)  creates an  UncertainScalarGammaDistributed  instance.  UncertainValue(Frechet, \u03b1, \u03b8)  creates an  UncertainScalarFrechetDistributed  instance.  UncertainValue(Binomial, n, p)  creates an  UncertainScalarBinomialDistributed  instance.", 
            "title": "Two-parameter distributions"
        }, 
        {
            "location": "/uncertainvalues_theoreticaldistributions/#three-parameter-distributions", 
            "text": "1\n2 UncertainValue ( d :: Type { D },   a : Number ,   b : Number ,   c : Number ) \n     where   { D : Distributions . Distribution }    Creates an uncertain value consisting of a three-parameter distribution of type  d  with parameters  a ,  b  and  c . Precisely what  a ,  b  and  c  are depends on which distribution is provided.   UncertainValue(BetaBinomial, n, \u03b1, \u03b2)  creates an  UncertainScalarBetaBinomialDistributed  instance.", 
            "title": "Three-parameter distributions"
        }, 
        {
            "location": "/hypothesistests/anderson_darling_test/", 
            "text": "One-sample Anderson-Darling test\n\n\n#\n\n\nHypothesisTests.OneSampleADTest\n \n \nType\n.\n\n\n1\nOneSampleADTest(uv::UncertainValue, d::UnivariateDistribution) -\n OneSampleADTest\n\n\n\n\n\n\nPerform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource", 
            "title": "Anderson darling test"
        }, 
        {
            "location": "/hypothesistests/anderson_darling_test/#one-sample-anderson-darling-test", 
            "text": "#  HypothesisTests.OneSampleADTest     Type .  1 OneSampleADTest(uv::UncertainValue, d::UnivariateDistribution) -  OneSampleADTest   Perform a one-sample Anderson\u2013Darling test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "One-sample Anderson-Darling test"
        }, 
        {
            "location": "/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/", 
            "text": "Pooled approximate two-sample Kolmogorov-Smirnov test\n\n\n#\n\n\nUncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled\n \n \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestPooled(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -\n ApproximateTwoSampleKSTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nd1\n, then separately draw \nn\n realisations of each uncertain value in \nd2\n. Then, pool all realisations for \nd1\n together and all realisations of \nd2\n together.\n\n\nOn the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the \nd1\n value pool represents the same distribution as the distribution furnishing the \nd2\n value pool, against the alternative hypothesis that the furnishing distributions are different.\n\n\nsource\n\n\n\n\nElement-wise approximate two-sample Kolmogorov-Smirnov test\n\n\n#\n\n\nUncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nApproximateTwoSampleKSTestElementWise(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -\n Vector{ApproximateTwoSampleKSTest}\n\n\n\n\n\n\nAssuming \nd1\n and \nd2\n contain the same number of uncertain observations, draw \nn\n realisations of each uncertain value in \nd1\n, then separately and separately draw \nn\n realisations of each uncertain value in \nd2\n.\n\n\nThen, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in \nd1\n and \nd2\n come from the same distribution against the alternative hypothesis that the (element-wise) values in  \nd1\n and \nd2\n come from different distributions.\n\n\nThe test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with \nn\n draws for the \ni\ni\n-ith pair of uncertain values.\n\n\nsource", 
            "title": "Approximate twosample kolmogorov smirnov test"
        }, 
        {
            "location": "/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#pooled-approximate-two-sample-kolmogorov-smirnov-test", 
            "text": "#  UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestPooled     Function .  1\n2 ApproximateTwoSampleKSTestPooled(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -  ApproximateTwoSampleKSTest   First, draw  n  realisations of each uncertain value in  d1 , then separately draw  n  realisations of each uncertain value in  d2 . Then, pool all realisations for  d1  together and all realisations of  d2  together.  On the pooled realisations, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the distribution furnishing the  d1  value pool represents the same distribution as the distribution furnishing the  d2  value pool, against the alternative hypothesis that the furnishing distributions are different.  source", 
            "title": "Pooled approximate two-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/#element-wise-approximate-two-sample-kolmogorov-smirnov-test", 
            "text": "#  UncertainData.UncertainStatistics.ApproximateTwoSampleKSTestElementWise     Function .  1\n2 ApproximateTwoSampleKSTestElementWise(d1::UncertainDataset,\n    d2::UncertainDataset, n::Int = 1000) -  Vector{ApproximateTwoSampleKSTest}   Assuming  d1  and  d2  contain the same number of uncertain observations, draw  n  realisations of each uncertain value in  d1 , then separately and separately draw  n  realisations of each uncertain value in  d2 .  Then, perform an asymptotic two-sample Kolmogorov\u2013Smirnov-test of the null hypothesis that the uncertain values in  d1  and  d2  come from the same distribution against the alternative hypothesis that the (element-wise) values in   d1  and  d2  come from different distributions.  The test is performed pairwise, i.e. ApproximateTwoSampleKSTest(d1[i], d2[i]) with  n  draws for the  i i -ith pair of uncertain values.  source", 
            "title": "Element-wise approximate two-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/hypothesistests/equal_variance_t_test/", 
            "text": "Equal variance t-test\n\n\n#\n\n\nHypothesisTests.EqualVarianceTTest\n \n \nType\n.\n\n\n1\n2\nEqualVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nThis function performs a two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\nExample\n\n\nLet's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.\n\n\nWe expect the test to reject this null-hypothesis, because we've created two very different distributions.\n\n\n1\n2\n3\n4\n5\nuv1\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n1.2\n,\n \n0.3\n)\n\n\nuv2\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n3\n)\n\n\n\n# EqualVarianceTTest on 1000 draws for each variable\n\n\nEqualVarianceTTest\n(\nuv1\n,\n \nuv2\n,\n \n1000\n)\n\n\n\n\n\n\n\nThe output is:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\nTwo\n \nsample\n \nt\n-\ntest\n \n(\nequal\n \nvariance\n)\n\n\n----------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n \ndifference\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0\n\n    \npoint\n \nestimate\n:\n          \n-\n4.782470406651697\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n-\n5.0428\n,\n \n-\n4.5222\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n1e-99\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n[\n1000\n,\n1000\n]\n\n    \nt\n-\nstatistic\n:\n              \n-\n36.03293014520585\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n1998\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.1327249931487462\n\n\n\n\n\n\n\nThe test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.\n\n\n\n\nPooled equal variance t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.EqualVarianceTTestPooled\n \n \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nEqualVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. Gather all \ns1[i]\n in a pooled sample \nS1\n, and all \ns2[i]\n in a pooled sample \nS2\n.\n\n\nPerform a two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource\n\n\n\n\nElement-wise equal variance t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.EqualVarianceTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nEqualVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nEqualVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(s1[i], s2[i])\n. Specifically:\n\n\nPerforms an pairwise two-sample t-test of the null hypothesis that \ns1[i]\n and \ns2[i]\n come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.\n\n\nsource", 
            "title": "Equal variance t test"
        }, 
        {
            "location": "/hypothesistests/equal_variance_t_test/#equal-variance-t-test", 
            "text": "#  HypothesisTests.EqualVarianceTTest     Type .  1\n2 EqualVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   EqualVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  This function performs a two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source  Example  Let's create two uncertain values furnished by distributions of different types. We'll perform the equal variance t-test to check if there is support for the null-hypothesis that the distributions furnishing the uncertain values come from distributions with equal means and variances.  We expect the test to reject this null-hypothesis, because we've created two very different distributions.  1\n2\n3\n4\n5 uv1   =   UncertainValue ( Normal ,   1.2 ,   0.3 )  uv2   =   UncertainValue ( Gamma ,   2 ,   3 )  # EqualVarianceTTest on 1000 draws for each variable  EqualVarianceTTest ( uv1 ,   uv2 ,   1000 )    The output is:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17 Two   sample   t - test   ( equal   variance )  ----------------------------------  Population   details : \n     parameter   of   interest :     Mean   difference \n     value   under   h_0 :           0 \n     point   estimate :            - 4.782470406651697 \n     95 %   confidence   interval :   ( - 5.0428 ,   - 4.5222 )  Test   summary : \n     outcome   with   95 %   confidence :   reject   h_0 \n     two - sided   p - value :             1e-99  Details : \n     number   of   observations :     [ 1000 , 1000 ] \n     t - statistic :                - 36.03293014520585 \n     degrees   of   freedom :         1998 \n     empirical   standard   error :   0.1327249931487462    The test rejects the null-hypothesis, so we accept the alternative hypothesis that the samples come from distributions with different means and variances.", 
            "title": "Equal variance t-test"
        }, 
        {
            "location": "/hypothesistests/equal_variance_t_test/#pooled-equal-variance-t-test", 
            "text": "#  UncertainData.UncertainStatistics.EqualVarianceTTestPooled     Function .  1\n2 EqualVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   EqualVarianceTTest    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. Gather all  s1[i]  in a pooled sample  S1 , and all  s2[i]  in a pooled sample  S2 .  Perform a two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source", 
            "title": "Pooled equal variance t-test"
        }, 
        {
            "location": "/hypothesistests/equal_variance_t_test/#element-wise-equal-variance-t-test", 
            "text": "#  UncertainData.UncertainStatistics.EqualVarianceTTestElementWise     Function .  1\n2 EqualVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   Vector { EqualVarianceTTest }    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  (s1[i], s2[i]) . Specifically:  Performs an pairwise two-sample t-test of the null hypothesis that  s1[i]  and  s2[i]  come from distributions with equal means and variances against the alternative hypothesis that the distributions have different means but equal variances.  source", 
            "title": "Element-wise equal variance t-test"
        }, 
        {
            "location": "/hypothesistests/exact_kolmogorov_smirnov_test/", 
            "text": "Exact one-sample Kolmogorov-Smirnov test\n\n\n#\n\n\nHypothesisTests.ExactOneSampleKSTest\n \n \nType\n.\n\n\n1\n2\nExactOneSampleKSTest(uv::AbstractUncertainValue,\n    d::UnivariateDistribution, n::Int = 1000) -\n ExactOneSampleKSTest\n\n\n\n\n\n\nPerform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of \nn\n realisations of the uncertain value \nuv\n comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\nExample\n\n\nWe'll test whether the uncertain value \nuv = UncertainValue(Gamma, 2, 4)\n comes from the theoretical distribution \nGamma(2, 4)\n. Of course, we expect the test to confirm this, because we're using the exact same distribution.\n\n\n1\n2\n3\n4\n5\nuv\n \n=\n \nUncertainValue\n(\nGamma\n,\n \n2\n,\n \n4\n)\n\n\n\n# Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the\n\n\n# uncertain value.\n\n\nExactOneSampleKSTest\n(\nuv\n,\n \nGamma\n(\n2\n,\n \n4\n),\n \n1000\n)\n\n\n\n\n\n\n\nThat gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\nExact\n \none\n \nsample\n \nKolmogorov\n-\nSmirnov\n \ntest\n\n\n----------------------------------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nSupremum\n \nof\n \nCDF\n \ndifferences\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n0.0\n\n    \npoint\n \nestimate\n:\n          \n0.0228345021301449\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6655\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n\n\n\n\n\n\nAs expected, the test can't reject the hypothesis that the uncertain value \nuv\n comes from the theoretical distribution \nGamma(2, 4)\n, precisely because it does.\n\n\n\n\nPooled exact one-sample Kolmogorov-Smirnov test\n\n\n#\n\n\nUncertainData.UncertainStatistics.ExactOneSampleKSTestPooled\n \n \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestPooled(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -\n ExactOneSampleKSTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource\n\n\n\n\nElement-wise exact one-sample Kolmogorov-Smirnov test\n\n\n#\n\n\nUncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nExactOneSampleKSTestElementWise(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -\n Vector{ExactOneSampleKSTest}\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution \nd\n against the alternative hypothesis that the sample is not drawn from \nd\n.\n\n\nsource", 
            "title": "Exact kolmogorov smirnov test"
        }, 
        {
            "location": "/hypothesistests/exact_kolmogorov_smirnov_test/#exact-one-sample-kolmogorov-smirnov-test", 
            "text": "#  HypothesisTests.ExactOneSampleKSTest     Type .  1\n2 ExactOneSampleKSTest(uv::AbstractUncertainValue,\n    d::UnivariateDistribution, n::Int = 1000) -  ExactOneSampleKSTest   Perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that a draw of  n  realisations of the uncertain value  uv  comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source  Example  We'll test whether the uncertain value  uv = UncertainValue(Gamma, 2, 4)  comes from the theoretical distribution  Gamma(2, 4) . Of course, we expect the test to confirm this, because we're using the exact same distribution.  1\n2\n3\n4\n5 uv   =   UncertainValue ( Gamma ,   2 ,   4 )  # Perform the Kolgomorov-Smirnov test by drawing 1000 samples from the  # uncertain value.  ExactOneSampleKSTest ( uv ,   Gamma ( 2 ,   4 ),   1000 )    That gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 Exact   one   sample   Kolmogorov - Smirnov   test  ----------------------------------------  Population   details : \n     parameter   of   interest :     Supremum   of   CDF   differences \n     value   under   h_0 :           0.0 \n     point   estimate :            0.0228345021301449  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6655  Details : \n     number   of   observations :     1000    As expected, the test can't reject the hypothesis that the uncertain value  uv  comes from the theoretical distribution  Gamma(2, 4) , precisely because it does.", 
            "title": "Exact one-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/hypothesistests/exact_kolmogorov_smirnov_test/#pooled-exact-one-sample-kolmogorov-smirnov-test", 
            "text": "#  UncertainData.UncertainStatistics.ExactOneSampleKSTestPooled     Function .  1\n2 ExactOneSampleKSTestPooled(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -  ExactOneSampleKSTest   First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then perform a one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that the pooled values comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Pooled exact one-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/hypothesistests/exact_kolmogorov_smirnov_test/#element-wise-exact-one-sample-kolmogorov-smirnov-test", 
            "text": "#  UncertainData.UncertainStatistics.ExactOneSampleKSTestElementWise     Function .  1\n2 ExactOneSampleKSTestElementWise(ud::UncertainDataset,\n    d::UnivariateDistribution, n::Int = 1000) -  Vector{ExactOneSampleKSTest}   First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, perform an element-wise (pool-wise) one-sample exact Kolmogorov\u2013Smirnov test of the null hypothesis that each value pool comes from the distribution  d  against the alternative hypothesis that the sample is not drawn from  d .  source", 
            "title": "Element-wise exact one-sample Kolmogorov-Smirnov test"
        }, 
        {
            "location": "/hypothesistests/hypothesis_tests_overview/", 
            "text": "Hypothesis tests\n\n\nIn addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from \nHypothesisTests.jl\n. This allows us to perform hypothesis testing on ensemble realisations of the data.\n\n\n\n\nImplemented hypothesis tests\n\n\nThe following hypothesis tests are implemented for uncertain data types.\n\n\n\n\nOne sample t-test\n.\n\n\nEqual variance t-test\n.\n\n\nUnequal variance t-test\n.\n\n\nExact Kolmogorov-Smirnov test\n.\n\n\nApproximate two-sample Kolmogorov-Smirnov test\n.\n\n\nOne-sample Anderson\u2013Darling test\n.\n\n\nJarque-Bera test\n.\n\n\n\n\n\n\nTerminology\n\n\nPooled statistics\n are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.\n\n\nElement-wise statistics\n are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.", 
            "title": "Hypothesis tests overview"
        }, 
        {
            "location": "/hypothesistests/hypothesis_tests_overview/#hypothesis-tests", 
            "text": "In addition to providing ensemble computation of basic statistic measures, this package also wraps various hypothesis tests from  HypothesisTests.jl . This allows us to perform hypothesis testing on ensemble realisations of the data.", 
            "title": "Hypothesis tests"
        }, 
        {
            "location": "/hypothesistests/hypothesis_tests_overview/#implemented-hypothesis-tests", 
            "text": "The following hypothesis tests are implemented for uncertain data types.   One sample t-test .  Equal variance t-test .  Unequal variance t-test .  Exact Kolmogorov-Smirnov test .  Approximate two-sample Kolmogorov-Smirnov test .  One-sample Anderson\u2013Darling test .  Jarque-Bera test .", 
            "title": "Implemented hypothesis tests"
        }, 
        {
            "location": "/hypothesistests/hypothesis_tests_overview/#terminology", 
            "text": "Pooled statistics  are computed by sampling all uncertain values comprising the dataset n times, pooling the values together and treating them as one variable, then computing the statistic.  Element-wise statistics  are computed by sampling each uncertain value n times, keeping the data generated from each uncertain value separate. The statistics are the computed separately for each sample.", 
            "title": "Terminology"
        }, 
        {
            "location": "/hypothesistests/jarque_bera_test/", 
            "text": "Jarque-Bera test\n\n\n#\n\n\nHypothesisTests.JarqueBeraTest\n \n \nType\n.\n\n\n1\nJarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -\n JarqueBeraTest\n\n\n\n\n\n\nCompute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.\n\n\nsource\n\n\n\n\nPooled Jarque-Bera test\n\n\n#\n\n\nUncertainData.UncertainStatistics.JarqueBeraTestPooled\n \n \nFunction\n.\n\n\n1\nJarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -\n JarqueBeraTest\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.\n\n\nsource\n\n\n\n\nElement-wise Jarque-Bera test\n\n\n#\n\n\nUncertainData.UncertainStatistics.JarqueBeraTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nOneSampleADTestElementWise(ud::UncertainDataset,\n    n::Int = 1000) -\n Vector{JarqueBeraTest}\n\n\n\n\n\n\nFirst, draw \nn\n realisations of each uncertain value in \nud\n, keeping one pool of values for each uncertain value.\n\n\nThen, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.\n\n\nsource", 
            "title": "Jarque bera test"
        }, 
        {
            "location": "/hypothesistests/jarque_bera_test/#jarque-bera-test", 
            "text": "#  HypothesisTests.JarqueBeraTest     Type .  1 JarqueBeraTest(d::AbstractUncertainValue, n::Int = 1000) -  JarqueBeraTest   Compute the Jarque-Bera statistic to test the null hypothesis that an uncertain value is normally distributed.  source", 
            "title": "Jarque-Bera test"
        }, 
        {
            "location": "/hypothesistests/jarque_bera_test/#pooled-jarque-bera-test", 
            "text": "#  UncertainData.UncertainStatistics.JarqueBeraTestPooled     Function .  1 JarqueBeraTestPooled(ud::UncertainDataset, n::Int = 1000) -  JarqueBeraTest   First, draw  n  realisations of each uncertain value in  ud  and pool them together. Then, compute the Jarque-Bera statistic to test the null hypothesis that the values of the pool are normally distributed.  source", 
            "title": "Pooled Jarque-Bera test"
        }, 
        {
            "location": "/hypothesistests/jarque_bera_test/#element-wise-jarque-bera-test", 
            "text": "#  UncertainData.UncertainStatistics.JarqueBeraTestElementWise     Function .  1\n2 OneSampleADTestElementWise(ud::UncertainDataset,\n    n::Int = 1000) -  Vector{JarqueBeraTest}   First, draw  n  realisations of each uncertain value in  ud , keeping one pool of values for each uncertain value.  Then, compute the Jarque-Bera statistic to test the null hypothesis that each value pool is normally distributed.  source", 
            "title": "Element-wise Jarque-Bera test"
        }, 
        {
            "location": "/hypothesistests/mann_whitney_u_test/", 
            "text": "Mann-Whitney u-test\n\n\n#\n\n\nHypothesisTests.MannWhitneyUTest\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue,\n    n::Int = 1000) -\n MannWhitneyUTest\n\n\n\n\n\n\nLet \ns1\n and \ns2\n be samples of \nn\n realisations from the distributions furnishing the uncertain values \nd1\n and \nd2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns1\n is greater than an observation drawn from the same population as \ns2\n is equal to the probability that an observation drawn from the same population as \ns2\n is greater than an observation drawn from the same population as \ns1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nPooled Mann-Whitney u-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.MannWhitneyUTestPooled\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -\n MannWhitneyUTest\n\n\n\n\n\n\nLet \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1[i]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n.  Next, gather the samples for all \ns_{1_{i}}\ns_{1_{i}}\n in a pooled sample \nS_1\nS_1\n.  Do the same for the second uncertain dataset \nd2\n, yielding the pooled sample  \nS_2\nS_2\n.\n\n\nPerform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \nS_1\nS_1\n is greater than an observation drawn from the same population as \nS_2\nS_2\n is equal to the probability that an observation drawn from the same population as \nS_2\nS_2\n is greater than an observation drawn from the same population as \nS_1\nS_1\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource\n\n\n\n\nElement-wise Mann-Whitney u-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.MannWhitneyUTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nMannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -\n Vector{MannWhitneyUTest}\n\n\n\n\n\n\nAssume \nd1\n and \nd2\n consist of the same number of uncertain values. Let \ns_{1_{i}}\ns_{1_{i}}\n be a sample of \nn\n realisations of the distribution furnishing the uncertain value \nd1[i]\n, where \ni \\in [1, 2, \\ldots, N]\ni \\in [1, 2, \\ldots, N]\n and \nN\nN\n is the number of uncertain values in \nd1\n. Let \ns_{2_{i}}\ns_{2_{i}}\n be the corresponding sample for \nd2[i]\n. This function\n\n\nPerform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n is greater than an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is equal to the probability that an observation drawn from the same population as \ns_{2_{i}}\ns_{2_{i}}\n is greater than an observation drawn from the same population as \ns_{1_{i}}\ns_{1_{i}}\n against the alternative hypothesis that these probabilities are not equal.\n\n\nThe Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples, \nMannWhitneyUTest\n performs an exact Mann-Whitney U test. In all other cases, \nMannWhitneyUTest\n performs an approximate Mann-Whitney U test.\n\n\nsource", 
            "title": "Mann whitney u test"
        }, 
        {
            "location": "/hypothesistests/mann_whitney_u_test/#mann-whitney-u-test", 
            "text": "#  HypothesisTests.MannWhitneyUTest     Function .  1\n2 MannWhitneyUTest(d1::AbstractUncertainValue, d2::AbstractUncertainValue,\n    n::Int = 1000) -  MannWhitneyUTest   Let  s1  and  s2  be samples of  n  realisations from the distributions furnishing the uncertain values  d1  and  d2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s1  is greater than an observation drawn from the same population as  s2  is equal to the probability that an observation drawn from the same population as  s2  is greater than an observation drawn from the same population as  s1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Mann-Whitney u-test"
        }, 
        {
            "location": "/hypothesistests/mann_whitney_u_test/#pooled-mann-whitney-u-test", 
            "text": "#  UncertainData.UncertainStatistics.MannWhitneyUTestPooled     Function .  1\n2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -  MannWhitneyUTest   Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1[i] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 .  Next, gather the samples for all  s_{1_{i}} s_{1_{i}}  in a pooled sample  S_1 S_1 .  Do the same for the second uncertain dataset  d2 , yielding the pooled sample   S_2 S_2 .  Perform a Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  S_1 S_1  is greater than an observation drawn from the same population as  S_2 S_2  is equal to the probability that an observation drawn from the same population as  S_2 S_2  is greater than an observation drawn from the same population as  S_1 S_1  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Pooled Mann-Whitney u-test"
        }, 
        {
            "location": "/hypothesistests/mann_whitney_u_test/#element-wise-mann-whitney-u-test", 
            "text": "#  UncertainData.UncertainStatistics.MannWhitneyUTestElementWise     Function .  1\n2 MannWhitneyUTest(d1::UncertainDataset, d2::UncertainDataset,\n    n::Int = 1000) -  Vector{MannWhitneyUTest}   Assume  d1  and  d2  consist of the same number of uncertain values. Let  s_{1_{i}} s_{1_{i}}  be a sample of  n  realisations of the distribution furnishing the uncertain value  d1[i] , where  i \\in [1, 2, \\ldots, N] i \\in [1, 2, \\ldots, N]  and  N N  is the number of uncertain values in  d1 . Let  s_{2_{i}} s_{2_{i}}  be the corresponding sample for  d2[i] . This function  Perform an element-wise Mann-Whitney U test of the null hypothesis that the probability that an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  is greater than an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is equal to the probability that an observation drawn from the same population as  s_{2_{i}} s_{2_{i}}  is greater than an observation drawn from the same population as  s_{1_{i}} s_{1_{i}}  against the alternative hypothesis that these probabilities are not equal.  The Mann-Whitney U test is sometimes known as the Wilcoxon rank-sum test. When there are no tied ranks and \u226450 samples, or tied ranks and \u226410 samples,  MannWhitneyUTest  performs an exact Mann-Whitney U test. In all other cases,  MannWhitneyUTest  performs an approximate Mann-Whitney U test.  source", 
            "title": "Element-wise Mann-Whitney u-test"
        }, 
        {
            "location": "/hypothesistests/one_sample_t_test/", 
            "text": "One-sample t-test\n\n\n#\n\n\nHypothesisTests.OneSampleTTest\n \n \nType\n.\n\n\n1\n2\nOneSampleTTest\n(\nd\n::\nAbstractUncertainValue\n,\n \nn\n::\nInt\n \n=\n \n1000\n;\n\n    \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nOneSampleTTest\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc0\n. \nn\n indicates the number of draws during resampling.\n\n\nsource\n\n\nExample:\n\n\n1\n2\n3\n4\n5\n6\n# Normally distributed uncertain observation with mean = 2.1\n\n\nuv\n \n=\n \nUncertainValue\n(\nNormal\n,\n \n2.1\n,\n \n0.2\n)\n\n\n\n# Perform a one-sample t-test to test the null hypothesis that\n\n\n# the sample comes from a distribution with mean \u03bc0\n\n\nOneSampleTTest\n(\nuv\n,\n \n1000\n,\n \n\u03bc0\n \n=\n \n2.1\n)\n\n\n\n\n\n\n\nWhich gives the following output:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n# Which results in\n\n\nOne\n \nsample\n \nt\n-\ntest\n\n\n-----------------\n\n\nPopulation\n \ndetails\n:\n\n    \nparameter\n \nof\n \ninterest\n:\n   \nMean\n\n    \nvalue\n \nunder\n \nh_0\n:\n         \n2.1\n\n    \npoint\n \nestimate\n:\n          \n2.1031909275381566\n\n    \n95\n%\n \nconfidence\n \ninterval\n:\n \n(\n2.091\n,\n \n2.1154\n)\n\n\n\nTest\n \nsummary\n:\n\n    \noutcome\n \nwith\n \n95\n%\n \nconfidence\n:\n \nfail\n \nto\n \nreject\n \nh_0\n\n    \ntwo\n-\nsided\n \np\n-\nvalue\n:\n           \n0.6089\n\n\n\nDetails\n:\n\n    \nnumber\n \nof\n \nobservations\n:\n   \n1000\n\n    \nt\n-\nstatistic\n:\n              \n0.5117722099885472\n\n    \ndegrees\n \nof\n \nfreedom\n:\n       \n999\n\n    \nempirical\n \nstandard\n \nerror\n:\n \n0.00623505433839\n\n\n\n\n\n\n\nThus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample \ndoes\n in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.\n\n\n\n\nPooled one-sample t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleTTestPooled\n \n \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nOneSampleTTest\n\n\n\n\n\n\n\nFirst, sample \nn\n draws of each uncertain value in each dataset, pooling the draws from the elements of \nd1\n and the draws from the elements of \nd2\n separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in \nd1\n and \nd2\n come from a distribution with mean \n\u03bc0\n against the alternative hypothesis that the distribution does not have mean \n\u03bc0\n.\n\n\nsource\n\n\n\n\nElement-wise one-sample t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.OneSampleTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\n3\nOneSampleTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n\n    \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nOneSampleTTest\n}\n\n\n\n\n\n\n\nPerform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean \n\u03bc0\n against the alternative hypothesis that its distribution does not have mean \n\u03bc0\n for uncertain value in \nd\n.\n\n\nn\n indicates the number of draws during resampling.\n\n\nsource", 
            "title": "One sample t test"
        }, 
        {
            "location": "/hypothesistests/one_sample_t_test/#one-sample-t-test", 
            "text": "#  HypothesisTests.OneSampleTTest     Type .  1\n2 OneSampleTTest ( d :: AbstractUncertainValue ,   n :: Int   =   1000 ; \n     \u03bc 0 :: Real   =   0 )   -   OneSampleTTest    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc0  against the alternative hypothesis that its distribution does not have mean  \u03bc0 .  n  indicates the number of draws during resampling.  source  Example:  1\n2\n3\n4\n5\n6 # Normally distributed uncertain observation with mean = 2.1  uv   =   UncertainValue ( Normal ,   2.1 ,   0.2 )  # Perform a one-sample t-test to test the null hypothesis that  # the sample comes from a distribution with mean \u03bc0  OneSampleTTest ( uv ,   1000 ,   \u03bc0   =   2.1 )    Which gives the following output:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18 # Which results in  One   sample   t - test  -----------------  Population   details : \n     parameter   of   interest :     Mean \n     value   under   h_0 :           2.1 \n     point   estimate :            2.1031909275381566 \n     95 %   confidence   interval :   ( 2.091 ,   2.1154 )  Test   summary : \n     outcome   with   95 %   confidence :   fail   to   reject   h_0 \n     two - sided   p - value :             0.6089  Details : \n     number   of   observations :     1000 \n     t - statistic :                0.5117722099885472 \n     degrees   of   freedom :         999 \n     empirical   standard   error :   0.00623505433839    Thus, we cannot reject the null-hypothesis that the sample comes from a distribution with mean = 2.1. Therefore, we accept the alternative hypothesis that our sample  does  in fact come from such a distribution. This is of course true, because we defined the uncertain value as a normal distribution with mean 2.1.", 
            "title": "One-sample t-test"
        }, 
        {
            "location": "/hypothesistests/one_sample_t_test/#pooled-one-sample-t-test", 
            "text": "#  UncertainData.UncertainStatistics.OneSampleTTestPooled     Function .  1\n2\n3 OneSampleTTestPooled ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   OneSampleTTest    First, sample  n  draws of each uncertain value in each dataset, pooling the draws from the elements of  d1  and the draws from the elements of  d2  separately. Then, perform a paired sample t-test of the null hypothesis that the differences between pairs of uncertain values in  d1  and  d2  come from a distribution with mean  \u03bc0  against the alternative hypothesis that the distribution does not have mean  \u03bc0 .  source", 
            "title": "Pooled one-sample t-test"
        }, 
        {
            "location": "/hypothesistests/one_sample_t_test/#element-wise-one-sample-t-test", 
            "text": "#  UncertainData.UncertainStatistics.OneSampleTTestElementWise     Function .  1\n2\n3 OneSampleTTestElementWise ( d1 :: UncertainDataset , \n     d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   Vector { OneSampleTTest }    Perform a one sample t-test of the null hypothesis that the uncertain value has a distribution with mean  \u03bc0  against the alternative hypothesis that its distribution does not have mean  \u03bc0  for uncertain value in  d .  n  indicates the number of draws during resampling.  source", 
            "title": "Element-wise one-sample t-test"
        }, 
        {
            "location": "/hypothesistests/unequal_variance_t_test/", 
            "text": "Unequal variance t-test\n\n\n#\n\n\nHypothesisTests.UnequalVarianceTTest\n \n \nType\n.\n\n\n1\n2\nUnequalVarianceTTest\n(\nd1\n::\nAbstractUncertainValue\n,\n \nd2\n::\nAbstractUncertainValue\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1\n and \ns2\n, each consisting of \nn\n random draws from the distributions furnishing \nd1\n and \nd2\n, respectively.\n\n\nPerform an unequal variance two-sample t-test of the null hypothesis that \ns1\n and \ns2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nPooled unequal variance t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.UnequalVarianceTTestPooled\n \n \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestPooled\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nUnequalVarianceTTest\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. Gather all \ns1[i]\n in a pooled sample \nS1\n, and all \ns2[i]\n in a pooled sample \nS2\n.\n\n\nThis function performs an unequal variance two-sample t-test of the null hypothesis that \nS1\n and \nS2\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nsource\n\n\n\n\nElement-wise unequal variance t-test\n\n\n#\n\n\nUncertainData.UncertainStatistics.UnequalVarianceTTestElementWise\n \n \nFunction\n.\n\n\n1\n2\nUnequalVarianceTTestElementWise\n(\nd1\n::\nUncertainDataset\n,\n \nd2\n::\nUncertainDataset\n,\n\n    \nn\n::\nInt\n \n=\n \n1000\n;\n \n\u03bc\n0\n::\nReal\n \n=\n \n0\n)\n \n-\n \nVector\n{\nUnequalVarianceTTest\n}\n\n\n\n\n\n\n\nConsider two samples \ns1[i]\n and \ns2[i]\n, each consisting of \nn\n random draws from the distributions furnishing the uncertain values \nd1[i]\n and \nd2[i]\n, respectively. This function performs an elementwise \nEqualVarianceTTest\n on the pairs \n(s1[i], s2[i])\n. Specifically:\n\n\nPerforms an pairwise unequal variance two-sample t-test of the null hypothesis that \ns1[i]\n and \ns2[i]\n come from distributions with equal means against the alternative hypothesis that the distributions have different means.\n\n\nThis test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:\n\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}\n\n\n\n\n\nsource", 
            "title": "Unequal variance t test"
        }, 
        {
            "location": "/hypothesistests/unequal_variance_t_test/#unequal-variance-t-test", 
            "text": "#  HypothesisTests.UnequalVarianceTTest     Type .  1\n2 UnequalVarianceTTest ( d1 :: AbstractUncertainValue ,   d2 :: AbstractUncertainValue , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   UnequalVarianceTTest    Consider two samples  s1  and  s2 , each consisting of  n  random draws from the distributions furnishing  d1  and  d2 , respectively.  Perform an unequal variance two-sample t-test of the null hypothesis that  s1  and  s2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source", 
            "title": "Unequal variance t-test"
        }, 
        {
            "location": "/hypothesistests/unequal_variance_t_test/#pooled-unequal-variance-t-test", 
            "text": "#  UncertainData.UncertainStatistics.UnequalVarianceTTestPooled     Function .  1\n2 UnequalVarianceTTestPooled ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   UnequalVarianceTTest    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. Gather all  s1[i]  in a pooled sample  S1 , and all  s2[i]  in a pooled sample  S2 .  This function performs an unequal variance two-sample t-test of the null hypothesis that  S1  and  S2  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  source", 
            "title": "Pooled unequal variance t-test"
        }, 
        {
            "location": "/hypothesistests/unequal_variance_t_test/#element-wise-unequal-variance-t-test", 
            "text": "#  UncertainData.UncertainStatistics.UnequalVarianceTTestElementWise     Function .  1\n2 UnequalVarianceTTestElementWise ( d1 :: UncertainDataset ,   d2 :: UncertainDataset , \n     n :: Int   =   1000 ;   \u03bc 0 :: Real   =   0 )   -   Vector { UnequalVarianceTTest }    Consider two samples  s1[i]  and  s2[i] , each consisting of  n  random draws from the distributions furnishing the uncertain values  d1[i]  and  d2[i] , respectively. This function performs an elementwise  EqualVarianceTTest  on the pairs  (s1[i], s2[i]) . Specifically:  Performs an pairwise unequal variance two-sample t-test of the null hypothesis that  s1[i]  and  s2[i]  come from distributions with equal means against the alternative hypothesis that the distributions have different means.  This test is sometimes known as Welch's t-test. It differs from the equal variance t-test in that it computes the number of degrees of freedom of the test using the Welch-Satterthwaite equation:   \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}  \n    \u03bd_{\u03c7'} \u2248 \\frac{\\left(\\sum_{i=1}^n k_i s_i^2\\right)^2}{\\sum_{i=1}^n\n        \\frac{(k_i s_i^2)^2}{\u03bd_i}}   source", 
            "title": "Element-wise unequal variance t-test"
        }
    ]
}